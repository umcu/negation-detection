{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MetaCAT - BiLSTM for negations of Dutch Clinical Corpus\n",
    "\n",
    "Based on https://colab.research.google.com/drive/1rxzBZCTDcqsIjRXZ3u4yRZFOkUCCuwyy#scrollTo=dukwUnN1TPCg\n",
    "and https://colab.research.google.com/drive/1zzV3XzFJ9ihhCJ680DaQV2QZ5XnHa06X#scrollTo=Sj29auXV8iPZ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from medcat.cat import CAT\n",
    "from medcat.vocab import Vocab\n",
    "from medcat.cdb import CDB\n",
    "from medcat.config import Config\n",
    "from medcat.meta_cat import MetaCAT\n",
    "from medcat.preprocessing.tokenizers import TokenizerWrapperBPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "data_dir = os.path.join('..', 'data')\n",
    "cdb_file = os.path.join(data_dir, 'cdb.dat')\n",
    "vocab_file = os.path.join(data_dir, 'vocab.dat')\n",
    "json_file_all = os.path.join(data_dir, 'emc-dcc_ann.json')\n",
    "text_file = os.path.join(data_dir, 'data.txt')\n",
    "\n",
    "# Output\n",
    "output_dir = 'output'\n",
    "\n",
    "# Hardware for training, 'cpu' or 'cuda'\n",
    "device = 'cuda'\n",
    "\n",
    "# Name should contain 'bbpe' for ByteLevelBPETokenizer or 'bert' for BertTokenizerFast\n",
    "# This name is saved in the model_config dict and subssequently in vars.dat on disk.\n",
    "tokenizer_name = 'bbpe_dutch-wikipedia'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create, train and save the tokenizer\n",
    "tokenizer = ByteLevelBPETokenizer(add_prefix_space=True)\n",
    "tokenizer.train(text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output\\\\bbpe_dutch-wikipedia-vocab.json',\n",
       " 'output\\\\bbpe_dutch-wikipedia-merges.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the tokenizer\n",
    "tokenizer.save_model(output_dir, tokenizer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tokenize text and train with Word2Vec\n",
    "text_data = []\n",
    "with open(text_file, encoding='utf-8') as text:\n",
    "    for line in text:\n",
    "        text_data.append(tokenizer.encode(line).tokens)\n",
    "w2v = Word2Vec(text_data, size=300, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ġkortademigheid', 0.9212014675140381),\n",
       " ('Ġdiarree', 0.9084370136260986),\n",
       " ('Ġbraken', 0.898695170879364),\n",
       " ('Ġmisselijkheid', 0.8878295421600342),\n",
       " ('Ġjeuk', 0.8811523914337158),\n",
       " ('Ġbenauwdheid', 0.8811056613922119),\n",
       " ('Ġvermoeidheid', 0.8810759782791138),\n",
       " ('Ġbuikpijn', 0.8754057884216309),\n",
       " ('Ġconstipatie', 0.872384786605835),\n",
       " ('Ġhoofdpijn', 0.8706159591674805)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check trained word2vec model\n",
    "# Ġ denotes start of word (a space)\n",
    "w2v.wv.most_similar('Ġhoesten')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings matrix\n",
    "embeddings = []\n",
    "for i in range(tokenizer.get_vocab_size()):\n",
    "    word = tokenizer.id_to_token(i)\n",
    "    if word in w2v.wv:\n",
    "        embeddings.append(w2v.wv[word])\n",
    "    else:\n",
    "        # Assign a random vector if the word was not frequent enough to receive an embedding\n",
    "        embeddings.append(np.random.rand(300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the embeddings\n",
    "embeddings_file = os.path.join(output_dir, \"embeddings.npy\")\n",
    "np.save(open(embeddings_file, 'wb'), np.array(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change tokenizer to MedCAT's TokenizerWrapperBPE\n",
    "tokenizer = TokenizerWrapperBPE(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MetaCAT on all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.69      0.76      1591\n",
      "           1       0.95      0.98      0.97      9758\n",
      "\n",
      "    accuracy                           0.94     11349\n",
      "   macro avg       0.90      0.84      0.86     11349\n",
      "weighted avg       0.94      0.94      0.94     11349\n",
      "\n",
      "Epoch: 0 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.74      0.82       182\n",
      "           1       0.96      0.99      0.97      1080\n",
      "\n",
      "    accuracy                           0.95      1262\n",
      "   macro avg       0.94      0.86      0.90      1262\n",
      "weighted avg       0.95      0.95      0.95      1262\n",
      "\n",
      "Train Loss: 0.204156841223561\n",
      "Test Loss:  0.17391254243557341\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 0 and f1: 0.9509975383104231\n",
      "[[ 134   48]\n",
      " [  11 1069]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 1 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.96     11349\n",
      "   macro avg       0.94      0.89      0.91     11349\n",
      "weighted avg       0.96      0.96      0.96     11349\n",
      "\n",
      "Epoch: 1 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.77      0.84       182\n",
      "           1       0.96      0.99      0.98      1080\n",
      "\n",
      "    accuracy                           0.96      1262\n",
      "   macro avg       0.94      0.88      0.91      1262\n",
      "weighted avg       0.96      0.96      0.96      1262\n",
      "\n",
      "Train Loss: 0.1547114661907856\n",
      "Test Loss:  0.15319585433462635\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 1 and f1: 0.9557016806844422\n",
      "[[ 141   41]\n",
      " [  13 1067]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 2 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.86      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.96     11349\n",
      "   macro avg       0.95      0.89      0.92     11349\n",
      "weighted avg       0.96      0.96      0.96     11349\n",
      "\n",
      "Epoch: 2 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.76      0.82       182\n",
      "           1       0.96      0.99      0.97      1080\n",
      "\n",
      "    accuracy                           0.95      1262\n",
      "   macro avg       0.93      0.87      0.90      1262\n",
      "weighted avg       0.95      0.95      0.95      1262\n",
      "\n",
      "Train Loss: 0.1424440608432018\n",
      "Test Loss:  0.17728632372745778\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 3 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.80      0.86      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.96     11349\n",
      "   macro avg       0.95      0.90      0.92     11349\n",
      "weighted avg       0.96      0.96      0.96     11349\n",
      "\n",
      "Epoch: 3 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.76      0.84       182\n",
      "           1       0.96      0.99      0.98      1080\n",
      "\n",
      "    accuracy                           0.96      1262\n",
      "   macro avg       0.96      0.88      0.91      1262\n",
      "weighted avg       0.96      0.96      0.96      1262\n",
      "\n",
      "Train Loss: 0.13374612618788656\n",
      "Test Loss:  0.1749009426421253\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 3 and f1: 0.9576419398954502\n",
      "[[ 138   44]\n",
      " [   7 1073]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 4 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.97     11349\n",
      "   macro avg       0.95      0.90      0.93     11349\n",
      "weighted avg       0.97      0.97      0.97     11349\n",
      "\n",
      "Epoch: 4 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.76      0.83       182\n",
      "           1       0.96      0.99      0.97      1080\n",
      "\n",
      "    accuracy                           0.96      1262\n",
      "   macro avg       0.94      0.88      0.90      1262\n",
      "weighted avg       0.96      0.96      0.95      1262\n",
      "\n",
      "Train Loss: 0.12710447281125184\n",
      "Test Loss:  0.16057418851414695\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 5 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.97     11349\n",
      "   macro avg       0.95      0.91      0.93     11349\n",
      "weighted avg       0.97      0.97      0.97     11349\n",
      "\n",
      "Epoch: 5 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.77      0.84       182\n",
      "           1       0.96      0.99      0.97      1080\n",
      "\n",
      "    accuracy                           0.96      1262\n",
      "   macro avg       0.94      0.88      0.91      1262\n",
      "weighted avg       0.96      0.96      0.95      1262\n",
      "\n",
      "Train Loss: 0.12313807802110859\n",
      "Test Loss:  0.16541198678896762\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 6 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.83      0.88      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.97     11349\n",
      "   macro avg       0.95      0.91      0.93     11349\n",
      "weighted avg       0.97      0.97      0.97     11349\n",
      "\n",
      "Epoch: 6 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.77      0.83       182\n",
      "           1       0.96      0.99      0.97      1080\n",
      "\n",
      "    accuracy                           0.95      1262\n",
      "   macro avg       0.93      0.88      0.90      1262\n",
      "weighted avg       0.95      0.95      0.95      1262\n",
      "\n",
      "Train Loss: 0.1217881201202391\n",
      "Test Loss:  0.17331609752727672\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 7 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.97     11349\n",
      "   macro avg       0.95      0.90      0.92     11349\n",
      "weighted avg       0.96      0.97      0.96     11349\n",
      "\n",
      "Epoch: 7 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.77      0.83       182\n",
      "           1       0.96      0.99      0.97      1080\n",
      "\n",
      "    accuracy                           0.96      1262\n",
      "   macro avg       0.93      0.88      0.90      1262\n",
      "weighted avg       0.95      0.96      0.95      1262\n",
      "\n",
      "Train Loss: 0.1277949068462476\n",
      "Test Loss:  0.1610417535994202\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 8 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.83      0.88      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.97     11349\n",
      "   macro avg       0.95      0.91      0.93     11349\n",
      "weighted avg       0.97      0.97      0.97     11349\n",
      "\n",
      "Epoch: 8 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.78      0.84       182\n",
      "           1       0.96      0.99      0.98      1080\n",
      "\n",
      "    accuracy                           0.96      1262\n",
      "   macro avg       0.94      0.88      0.91      1262\n",
      "weighted avg       0.96      0.96      0.96      1262\n",
      "\n",
      "Train Loss: 0.12156265960763615\n",
      "Test Loss:  0.17114094307180494\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 9 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.83      0.87      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.97     11349\n",
      "   macro avg       0.95      0.91      0.93     11349\n",
      "weighted avg       0.97      0.97      0.97     11349\n",
      "\n",
      "Epoch: 9 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.80      0.86       182\n",
      "           1       0.97      0.99      0.98      1080\n",
      "\n",
      "    accuracy                           0.96      1262\n",
      "   macro avg       0.95      0.90      0.92      1262\n",
      "weighted avg       0.96      0.96      0.96      1262\n",
      "\n",
      "Train Loss: 0.11763644604193552\n",
      "Test Loss:  0.15712264977628365\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 9 and f1: 0.9615973378529737\n",
      "[[ 146   36]\n",
      " [  11 1069]]\n",
      "\n",
      "\n",
      "\n",
      "Best/Average scores: F1: 0.9615973378529737, P: 0.9620149661500167, R: 0.9627575277337559\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.9615973378529737,\n",
       " 'p': 0.9620149661500167,\n",
       " 'r': 0.9627575277337559,\n",
       " 'cls_report': {'0': {'precision': 0.9299363057324841,\n",
       "   'recall': 0.8021978021978022,\n",
       "   'f1-score': 0.8613569321533924,\n",
       "   'support': 182},\n",
       "  '1': {'precision': 0.967420814479638,\n",
       "   'recall': 0.9898148148148148,\n",
       "   'f1-score': 0.9784897025171624,\n",
       "   'support': 1080},\n",
       "  'accuracy': 0.9627575277337559,\n",
       "  'macro avg': {'precision': 0.948678560106061,\n",
       "   'recall': 0.8960063085063086,\n",
       "   'f1-score': 0.9199233173352774,\n",
       "   'support': 1262},\n",
       "  'weighted avg': {'precision': 0.9620149661500167,\n",
       "   'recall': 0.9627575277337559,\n",
       "   'f1-score': 0.9615973378529737,\n",
       "   'support': 1262}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate MetaCAT\n",
    "mc_negation = MetaCAT(tokenizer=tokenizer,\n",
    "                      embeddings=embeddings,\n",
    "                      pad_id=len(embeddings)-1,\n",
    "                      save_dir=output_dir,\n",
    "                      device=device)\n",
    "\n",
    "# Train model\n",
    "mc_negation.train(json_file_all, \n",
    "                  'Negation',\n",
    "                  model_config={'tokenizer_name': tokenizer_name},\n",
    "                  nepochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model config\n",
    "mc_negation.save(full_save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cdb and vocab \n",
    "config = Config()\n",
    "\n",
    "vocab = Vocab.load(vocab_file)\n",
    "cdb = CDB.load(cdb_file)\n",
    "\n",
    "# Create MedCAT pipeline\n",
    "cat = CAT(cdb=cdb, vocab=vocab, config=config, meta_cats=[mc_negation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: heup\n",
      "Meta Annotations: {'Negation': {'value': 'not negated', 'confidence': 0.9724897, 'name': 'Negation'}}\n",
      "\n",
      "\n",
      "Entity: heupdysplasie\n",
      "Meta Annotations: {'Negation': {'value': 'negated', 'confidence': 0.9999876, 'name': 'Negation'}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test on DL1114 from DCC with negation\n",
    "text = 'Echo- en rontgenonderzoek van de heup toont geen evidente heupdysplasie.'\n",
    "doc = cat(text)\n",
    "for ent in doc.ents:\n",
    "    print(\"Entity: \" + ent.text)\n",
    "    print(\"Meta Annotations: \" + str(ent._.meta_anns))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: heup\n",
      "Meta Annotations: {'Negation': {'value': 'not negated', 'confidence': 0.99853075, 'name': 'Negation'}}\n",
      "\n",
      "\n",
      "Entity: heupdysplasie\n",
      "Meta Annotations: {'Negation': {'value': 'not negated', 'confidence': 0.9968718, 'name': 'Negation'}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test on DL1114 from DCC without negation\n",
    "text = 'Echo- en rontgenonderzoek van de heup toont evidente heupdysplasie.'\n",
    "doc = cat(text)\n",
    "for ent in doc.ents:\n",
    "    print(\"Entity: \" + ent.text)\n",
    "    print(\"Meta Annotations: \" + str(ent._.meta_anns))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional testing and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More tests and evaluation can be found in the evaluation notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
