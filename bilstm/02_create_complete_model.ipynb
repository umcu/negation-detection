{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test using the complete DCC\n",
    "In this notebook we'll first train a biLSTM using the complete DCC. We'll use MetaCAT's eval() function to evaluate the model on the complete DCC again, and we'll also use a custom evaluation function to process every example seperately and save those results in a result dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from medcat.meta_cat import MetaCAT\n",
    "from medcat.config_meta_cat import ConfigMetaCAT\n",
    "from medcat.tokenizers.meta_cat_tokenizers import TokenizerWrapperBPE\n",
    "from utils import evaluate_per_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input & output\n",
    "data_dir = Path.cwd().parents[0] / 'data'\n",
    "annotation_file = data_dir / 'emc-dcc_ann.json'\n",
    "model_dir = Path.cwd().parents[0] / 'models' / 'bilstm'\n",
    "embeddings_file = model_dir / 'embeddings.npy'\n",
    "result_dir = Path.cwd().parents[0] / 'results'\n",
    "bilstm_result_file = result_dir / 'bilstm_predictions.csv.gz'\n",
    "\n",
    "# Config\n",
    "config_metacat = ConfigMetaCAT()\n",
    "config_metacat.general['category_name'] = 'Negation'\n",
    "config_metacat.train['nepochs'] = 10\n",
    "config_metacat.train['score_average'] = 'binary'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load tokenizer and embeddings matrix\n",
    "Load a project-wide tokenizer and embeddings matrix which are created in `01_tokenizer_embeddings.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TokenizerWrapperBPE.load(model_dir)\n",
    "embeddings = np.load(embeddings_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train biLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate MetaCAT\n",
    "meta_cat = MetaCAT(tokenizer=tokenizer, embeddings=embeddings, config=config_metacat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97      9709\n",
      "           1       0.85      0.70      0.77      1587\n",
      "\n",
      "    accuracy                           0.94     11296\n",
      "   macro avg       0.90      0.84      0.87     11296\n",
      "weighted avg       0.94      0.94      0.94     11296\n",
      "\n",
      "Epoch: 0 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1082\n",
      "           1       0.88      0.91      0.89       173\n",
      "\n",
      "    accuracy                           0.97      1255\n",
      "   macro avg       0.93      0.94      0.94      1255\n",
      "weighted avg       0.97      0.97      0.97      1255\n",
      "\n",
      "\n",
      "##### Model saved to /Users/stan3/Data/negation-detection/models/bilstm/model.dat at epoch: 0 and f1: 0.969937081231062 #####\n",
      "\n",
      "Epoch: 1 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      9709\n",
      "           1       0.95      0.89      0.92      1587\n",
      "\n",
      "    accuracy                           0.98     11296\n",
      "   macro avg       0.97      0.94      0.95     11296\n",
      "weighted avg       0.98      0.98      0.98     11296\n",
      "\n",
      "Epoch: 1 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      1082\n",
      "           1       0.94      0.89      0.91       173\n",
      "\n",
      "    accuracy                           0.98      1255\n",
      "   macro avg       0.96      0.94      0.95      1255\n",
      "weighted avg       0.98      0.98      0.98      1255\n",
      "\n",
      "\n",
      "##### Model saved to /Users/stan3/Data/negation-detection/models/bilstm/model.dat at epoch: 1 and f1: 0.9766317249937135 #####\n",
      "\n",
      "Epoch: 2 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      9709\n",
      "           1       0.95      0.94      0.94      1587\n",
      "\n",
      "    accuracy                           0.98     11296\n",
      "   macro avg       0.97      0.97      0.97     11296\n",
      "weighted avg       0.98      0.98      0.98     11296\n",
      "\n",
      "Epoch: 2 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      1082\n",
      "           1       0.89      0.95      0.92       173\n",
      "\n",
      "    accuracy                           0.98      1255\n",
      "   macro avg       0.94      0.96      0.95      1255\n",
      "weighted avg       0.98      0.98      0.98      1255\n",
      "\n",
      "Epoch: 3 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      9709\n",
      "           1       0.97      0.96      0.97      1587\n",
      "\n",
      "    accuracy                           0.99     11296\n",
      "   macro avg       0.98      0.98      0.98     11296\n",
      "weighted avg       0.99      0.99      0.99     11296\n",
      "\n",
      "Epoch: 3 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1082\n",
      "           1       0.86      0.94      0.90       173\n",
      "\n",
      "    accuracy                           0.97      1255\n",
      "   macro avg       0.92      0.96      0.94      1255\n",
      "weighted avg       0.97      0.97      0.97      1255\n",
      "\n",
      "Epoch: 4 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9709\n",
      "           1       0.98      0.97      0.97      1587\n",
      "\n",
      "    accuracy                           0.99     11296\n",
      "   macro avg       0.99      0.98      0.98     11296\n",
      "weighted avg       0.99      0.99      0.99     11296\n",
      "\n",
      "Epoch: 4 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1082\n",
      "           1       0.92      0.87      0.89       173\n",
      "\n",
      "    accuracy                           0.97      1255\n",
      "   macro avg       0.95      0.93      0.94      1255\n",
      "weighted avg       0.97      0.97      0.97      1255\n",
      "\n",
      "Epoch: 5 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9709\n",
      "           1       0.99      0.98      0.98      1587\n",
      "\n",
      "    accuracy                           0.99     11296\n",
      "   macro avg       0.99      0.99      0.99     11296\n",
      "weighted avg       0.99      0.99      0.99     11296\n",
      "\n",
      "Epoch: 5 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1082\n",
      "           1       0.93      0.93      0.93       173\n",
      "\n",
      "    accuracy                           0.98      1255\n",
      "   macro avg       0.96      0.96      0.96      1255\n",
      "weighted avg       0.98      0.98      0.98      1255\n",
      "\n",
      "\n",
      "##### Model saved to /Users/stan3/Data/negation-detection/models/bilstm/model.dat at epoch: 5 and f1: 0.9808764940239044 #####\n",
      "\n",
      "Epoch: 6 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9709\n",
      "           1       0.98      0.98      0.98      1587\n",
      "\n",
      "    accuracy                           0.99     11296\n",
      "   macro avg       0.99      0.99      0.99     11296\n",
      "weighted avg       0.99      0.99      0.99     11296\n",
      "\n",
      "Epoch: 6 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      1082\n",
      "           1       0.94      0.89      0.92       173\n",
      "\n",
      "    accuracy                           0.98      1255\n",
      "   macro avg       0.96      0.94      0.95      1255\n",
      "weighted avg       0.98      0.98      0.98      1255\n",
      "\n",
      "Epoch: 7 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9709\n",
      "           1       0.99      0.98      0.99      1587\n",
      "\n",
      "    accuracy                           1.00     11296\n",
      "   macro avg       0.99      0.99      0.99     11296\n",
      "weighted avg       1.00      1.00      1.00     11296\n",
      "\n",
      "Epoch: 7 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1082\n",
      "           1       0.87      0.89      0.88       173\n",
      "\n",
      "    accuracy                           0.97      1255\n",
      "   macro avg       0.93      0.93      0.93      1255\n",
      "weighted avg       0.97      0.97      0.97      1255\n",
      "\n",
      "Epoch: 8 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9709\n",
      "           1       0.99      0.99      0.99      1587\n",
      "\n",
      "    accuracy                           1.00     11296\n",
      "   macro avg       0.99      0.99      0.99     11296\n",
      "weighted avg       1.00      1.00      1.00     11296\n",
      "\n",
      "Epoch: 8 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      1082\n",
      "           1       0.95      0.89      0.92       173\n",
      "\n",
      "    accuracy                           0.98      1255\n",
      "   macro avg       0.97      0.94      0.95      1255\n",
      "weighted avg       0.98      0.98      0.98      1255\n",
      "\n",
      "Epoch: 9 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9709\n",
      "           1       0.99      0.99      0.99      1587\n",
      "\n",
      "    accuracy                           1.00     11296\n",
      "   macro avg       0.99      1.00      0.99     11296\n",
      "weighted avg       1.00      1.00      1.00     11296\n",
      "\n",
      "Epoch: 9 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      1082\n",
      "           1       0.95      0.88      0.91       173\n",
      "\n",
      "    accuracy                           0.98      1255\n",
      "   macro avg       0.97      0.94      0.95      1255\n",
      "weighted avg       0.98      0.98      0.98      1255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "results = meta_cat.train(json_path=annotation_file, save_dir_path=str(model_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cat.save(save_dir_path=str(model_dir))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple evaluation with MetaCAT's eval()\n",
    "MetaCAT's eval() function does not return the example ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 **************************************************  Eval\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     10791\n",
      "           1       0.97      0.99      0.98      1760\n",
      "\n",
      "    accuracy                           1.00     12551\n",
      "   macro avg       0.99      0.99      0.99     12551\n",
      "weighted avg       1.00      1.00      1.00     12551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load biLSTM\n",
    "meta_cat = MetaCAT.load(model_dir)\n",
    "\n",
    "# Evalate with MetaCAT's eval()\n",
    "results = meta_cat.eval(json_path=annotation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.9950764380466066\n"
     ]
    }
   ],
   "source": [
    "# Print full F1 score to check for changes in result\n",
    "print(f'F1: {results[\"f1\"]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom evaluation per example\n",
    "In this project we are interested per example whether a negation has been identified or not. MetaCAT does not have such functionality, it only returns the scores, predictions and examples.\n",
    "\n",
    "In this part we iterate through all annotations in a an anntation file (MedCAT Trainer format), create an ID for every example (based on `exampleID=documentID_start_end`), and collect the prediction per example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_id</th>\n",
       "      <th>bilstm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DL1111_32_46</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DL1111_272_280</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DL1111_363_377</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DL1112_22_28</td>\n",
       "      <td>negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DL1113_59_67</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12546</th>\n",
       "      <td>SP2118_862_876</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12547</th>\n",
       "      <td>SP2119_23_45</td>\n",
       "      <td>negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12548</th>\n",
       "      <td>SP2120_3_23</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12549</th>\n",
       "      <td>SP2121_73_85</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12550</th>\n",
       "      <td>SP2122_0_19</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12551 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            entity_id       bilstm\n",
       "0        DL1111_32_46  not negated\n",
       "1      DL1111_272_280  not negated\n",
       "2      DL1111_363_377  not negated\n",
       "3        DL1112_22_28      negated\n",
       "4        DL1113_59_67  not negated\n",
       "...               ...          ...\n",
       "12546  SP2118_862_876  not negated\n",
       "12547    SP2119_23_45      negated\n",
       "12548     SP2120_3_23  not negated\n",
       "12549    SP2121_73_85  not negated\n",
       "12550     SP2122_0_19  not negated\n",
       "\n",
       "[12551 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilstm_predictions = evaluate_per_example(annotation_file, meta_cat, f'bilstm')\n",
    "bilstm_predictions.to_csv(bilstm_result_file, index=False, compression='gzip', line_terminator='\\n')\n",
    "bilstm_predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
