{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and testing using cross-validation\n",
    "This notebook uses predefined subsets of examples to train and test models.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import evaluate_per_example\n",
    "from medcat.tokenizers.meta_cat_tokenizers import TokenizerWrapperBPE\n",
    "from medcat.config_meta_cat import ConfigMetaCAT\n",
    "from medcat.meta_cat import MetaCAT\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "data_dir = Path.cwd().parents[0] / 'data'\n",
    "annotation_file = data_dir / 'emc-dcc_ann.json'\n",
    "split_list_file = data_dir / 'split_list.json'\n",
    "model_dir = Path.cwd().parents[0] / 'models' / 'bilstm'\n",
    "embeddings_file = model_dir / 'embeddings.npy'\n",
    "\n",
    "# Output\n",
    "annotations_split_dir = data_dir / 'annotations_split'\n",
    "models_split_dir = model_dir / 'model_splits'\n",
    "result_dir = Path.cwd().parents[0] / 'results'\n",
    "score_result_file = result_dir / 'bilstm_scores_cv.csv.gz'\n",
    "predictions_result_file = result_dir / 'bilstm_predictions_cv.csv.gz'\n",
    "\n",
    "# Create output dirs\n",
    "annotations_split_dir.mkdir(exist_ok=True)\n",
    "models_split_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Configure MetaCAT\n",
    "config_metacat = ConfigMetaCAT()\n",
    "config_metacat.general['category_name'] = 'Negation'\n",
    "config_metacat.train['nepochs'] = 10\n",
    "config_metacat.train['score_average'] = 'binary'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load tokenizer and embeddings matrix\n",
    "Load a project-wide tokenizer and embeddings matrix which are created in `01_tokenizer_embeddings.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TokenizerWrapperBPE.load(model_dir)\n",
    "embeddings = np.load(embeddings_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split DCC file into smaller train and test files\n",
    "Using the code in `utils/dcc_splitter.py` we split the data into 10 different folds. These splits are saved in `data/split_list.json`.\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load complete DCC data, which is in the MedCAT Trainer annotation format\n",
    "with open(annotation_file) as f:\n",
    "    annotations = json.load(f)\n",
    "    \n",
    "# Load the splits\n",
    "with open(split_list_file) as f:\n",
    "    split_lists = json.load(f)\n",
    "\n",
    "# For each split, create train and test file\n",
    "for split_list in split_lists:\n",
    "    train_annotations = []\n",
    "    test_annotations = []\n",
    "\n",
    "    for document in annotations['projects'][0]['documents']:\n",
    "        if document['name'] in split_list['train']:\n",
    "            train_annotations.append(document)\n",
    "        elif document['name'] in split_list['test']:\n",
    "            test_annotations.append(document)\n",
    "    #     else:\n",
    "    #         print(f'{document[\"name\"]} not found in either train or test')\n",
    "\n",
    "    # Create an annotation file for the split following MetaCAT's annotation format\n",
    "    project_train_annotations = {'projects': [{'documents': train_annotations}]}\n",
    "    project_test_annotations = {'projects': [{'documents': test_annotations}]}\n",
    "\n",
    "    # Write output files\n",
    "    train_output_file = annotations_split_dir / f'train_annotations_{split_list[\"split_id\"]}.json'\n",
    "    with open(train_output_file, \"w\") as fp:\n",
    "        json.dump(project_train_annotations, fp)\n",
    "\n",
    "    test_output_file = annotations_split_dir / f'test_annotations_{split_list[\"split_id\"]}.json'\n",
    "    with open(test_output_file, \"w\") as fp:\n",
    "        json.dump(project_test_annotations, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test on folds\n",
    "Per fold, a MetaCAT model is trained and tested. Testing is done using MetaCAT's eval() function, which contains functionality to evaluate the model on a testset and returns a dictionary with scores and examples, but does not include the example ID, which we use to compare examples between different methods. Therefor we use a different evaluation function later in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Repositories\\negation-detection\\data\\annotations_split\\train_annotations_0.json\n",
      "Epoch: 0 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.67      0.74      1422\n",
      "           1       0.95      0.98      0.96      8702\n",
      "\n",
      "    accuracy                           0.93     10124\n",
      "   macro avg       0.88      0.82      0.85     10124\n",
      "weighted avg       0.93      0.93      0.93     10124\n",
      "\n",
      "Epoch: 0 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.85      0.89       149\n",
      "           1       0.98      0.99      0.98       975\n",
      "\n",
      "    accuracy                           0.97      1124\n",
      "   macro avg       0.96      0.92      0.94      1124\n",
      "weighted avg       0.97      0.97      0.97      1124\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\0\\model.dat at epoch: 0 and f1: 0.9837067209775968 #####\n",
      "\n",
      "Epoch: 1 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91      1422\n",
      "           1       0.98      0.99      0.99      8702\n",
      "\n",
      "    accuracy                           0.98     10124\n",
      "   macro avg       0.96      0.94      0.95     10124\n",
      "weighted avg       0.98      0.98      0.98     10124\n",
      "\n",
      "Epoch: 1 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93       149\n",
      "           1       0.98      1.00      0.99       975\n",
      "\n",
      "    accuracy                           0.98      1124\n",
      "   macro avg       0.98      0.94      0.96      1124\n",
      "weighted avg       0.98      0.98      0.98      1124\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\0\\model.dat at epoch: 1 and f1: 0.9898270600203458 #####\n",
      "\n",
      "Epoch: 2 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94      1422\n",
      "           1       0.99      0.99      0.99      8702\n",
      "\n",
      "    accuracy                           0.98     10124\n",
      "   macro avg       0.97      0.96      0.97     10124\n",
      "weighted avg       0.98      0.98      0.98     10124\n",
      "\n",
      "Epoch: 2 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94       149\n",
      "           1       0.98      1.00      0.99       975\n",
      "\n",
      "    accuracy                           0.98      1124\n",
      "   macro avg       0.98      0.95      0.96      1124\n",
      "weighted avg       0.98      0.98      0.98      1124\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\0\\model.dat at epoch: 2 and f1: 0.9908256880733944 #####\n",
      "\n",
      "Epoch: 3 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1422\n",
      "           1       0.99      0.99      0.99      8702\n",
      "\n",
      "    accuracy                           0.99     10124\n",
      "   macro avg       0.98      0.97      0.98     10124\n",
      "weighted avg       0.99      0.99      0.99     10124\n",
      "\n",
      "Epoch: 3 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       149\n",
      "           1       0.99      0.97      0.98       975\n",
      "\n",
      "    accuracy                           0.96      1124\n",
      "   macro avg       0.90      0.96      0.93      1124\n",
      "weighted avg       0.97      0.96      0.97      1124\n",
      "\n",
      "Epoch: 4 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1422\n",
      "           1       1.00      1.00      1.00      8702\n",
      "\n",
      "    accuracy                           0.99     10124\n",
      "   macro avg       0.98      0.98      0.98     10124\n",
      "weighted avg       0.99      0.99      0.99     10124\n",
      "\n",
      "Epoch: 4 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93       149\n",
      "           1       0.99      0.99      0.99       975\n",
      "\n",
      "    accuracy                           0.98      1124\n",
      "   macro avg       0.98      0.95      0.96      1124\n",
      "weighted avg       0.98      0.98      0.98      1124\n",
      "\n",
      "Epoch: 5 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      1422\n",
      "           1       1.00      0.99      1.00      8702\n",
      "\n",
      "    accuracy                           0.99     10124\n",
      "   macro avg       0.98      0.99      0.98     10124\n",
      "weighted avg       0.99      0.99      0.99     10124\n",
      "\n",
      "Epoch: 5 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92       149\n",
      "           1       0.98      1.00      0.99       975\n",
      "\n",
      "    accuracy                           0.98      1124\n",
      "   macro avg       0.99      0.93      0.95      1124\n",
      "weighted avg       0.98      0.98      0.98      1124\n",
      "\n",
      "Epoch: 6 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1422\n",
      "           1       0.99      1.00      1.00      8702\n",
      "\n",
      "    accuracy                           0.99     10124\n",
      "   macro avg       0.99      0.98      0.98     10124\n",
      "weighted avg       0.99      0.99      0.99     10124\n",
      "\n",
      "Epoch: 6 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       149\n",
      "           1       0.99      0.99      0.99       975\n",
      "\n",
      "    accuracy                           0.98      1124\n",
      "   macro avg       0.95      0.96      0.96      1124\n",
      "weighted avg       0.98      0.98      0.98      1124\n",
      "\n",
      "Epoch: 7 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1422\n",
      "           1       1.00      1.00      1.00      8702\n",
      "\n",
      "    accuracy                           1.00     10124\n",
      "   macro avg       0.99      0.99      0.99     10124\n",
      "weighted avg       1.00      1.00      1.00     10124\n",
      "\n",
      "Epoch: 7 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93       149\n",
      "           1       0.99      0.99      0.99       975\n",
      "\n",
      "    accuracy                           0.98      1124\n",
      "   macro avg       0.98      0.95      0.96      1124\n",
      "weighted avg       0.98      0.98      0.98      1124\n",
      "\n",
      "Epoch: 8 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1422\n",
      "           1       1.00      1.00      1.00      8702\n",
      "\n",
      "    accuracy                           1.00     10124\n",
      "   macro avg       0.99      0.99      0.99     10124\n",
      "weighted avg       1.00      1.00      1.00     10124\n",
      "\n",
      "Epoch: 8 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93       149\n",
      "           1       0.98      1.00      0.99       975\n",
      "\n",
      "    accuracy                           0.98      1124\n",
      "   macro avg       0.98      0.94      0.96      1124\n",
      "weighted avg       0.98      0.98      0.98      1124\n",
      "\n",
      "Epoch: 9 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1422\n",
      "           1       1.00      1.00      1.00      8702\n",
      "\n",
      "    accuracy                           1.00     10124\n",
      "   macro avg       0.99      0.99      0.99     10124\n",
      "weighted avg       1.00      1.00      1.00     10124\n",
      "\n",
      "Epoch: 9 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93       149\n",
      "           1       0.98      1.00      0.99       975\n",
      "\n",
      "    accuracy                           0.98      1124\n",
      "   macro avg       0.98      0.94      0.96      1124\n",
      "weighted avg       0.98      0.98      0.98      1124\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 **************************************************  Eval\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90       189\n",
      "           1       0.98      0.99      0.98      1114\n",
      "\n",
      "    accuracy                           0.97      1303\n",
      "   macro avg       0.95      0.93      0.94      1303\n",
      "weighted avg       0.97      0.97      0.97      1303\n",
      "\n",
      "D:\\Repositories\\negation-detection\\data\\annotations_split\\train_annotations_1.json\n",
      "Epoch: 0 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.69      0.76      1413\n",
      "           1       0.95      0.98      0.97      8738\n",
      "\n",
      "    accuracy                           0.94     10151\n",
      "   macro avg       0.90      0.84      0.86     10151\n",
      "weighted avg       0.94      0.94      0.94     10151\n",
      "\n",
      "Epoch: 0 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       173\n",
      "           1       0.99      0.98      0.98       954\n",
      "\n",
      "    accuracy                           0.97      1127\n",
      "   macro avg       0.94      0.95      0.95      1127\n",
      "weighted avg       0.97      0.97      0.97      1127\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\1\\model.dat at epoch: 0 and f1: 0.9831932773109244 #####\n",
      "\n",
      "Epoch: 1 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92      1413\n",
      "           1       0.98      0.99      0.99      8738\n",
      "\n",
      "    accuracy                           0.98     10151\n",
      "   macro avg       0.96      0.95      0.95     10151\n",
      "weighted avg       0.98      0.98      0.98     10151\n",
      "\n",
      "Epoch: 1 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91       173\n",
      "           1       0.97      1.00      0.98       954\n",
      "\n",
      "    accuracy                           0.97      1127\n",
      "   macro avg       0.98      0.92      0.95      1127\n",
      "weighted avg       0.97      0.97      0.97      1127\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\1\\model.dat at epoch: 1 and f1: 0.984488107549121 #####\n",
      "\n",
      "Epoch: 2 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95      1413\n",
      "           1       0.99      0.99      0.99      8738\n",
      "\n",
      "    accuracy                           0.98     10151\n",
      "   macro avg       0.97      0.97      0.97     10151\n",
      "weighted avg       0.98      0.98      0.98     10151\n",
      "\n",
      "Epoch: 2 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       173\n",
      "           1       0.99      0.99      0.99       954\n",
      "\n",
      "    accuracy                           0.98      1127\n",
      "   macro avg       0.96      0.97      0.96      1127\n",
      "weighted avg       0.98      0.98      0.98      1127\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\1\\model.dat at epoch: 2 and f1: 0.9889647924330004 #####\n",
      "\n",
      "Epoch: 3 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1413\n",
      "           1       0.99      0.99      0.99      8738\n",
      "\n",
      "    accuracy                           0.99     10151\n",
      "   macro avg       0.98      0.97      0.98     10151\n",
      "weighted avg       0.99      0.99      0.99     10151\n",
      "\n",
      "Epoch: 3 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89       173\n",
      "           1       0.98      0.98      0.98       954\n",
      "\n",
      "    accuracy                           0.96      1127\n",
      "   macro avg       0.93      0.93      0.93      1127\n",
      "weighted avg       0.96      0.96      0.96      1127\n",
      "\n",
      "Epoch: 4 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1413\n",
      "           1       0.99      1.00      0.99      8738\n",
      "\n",
      "    accuracy                           0.99     10151\n",
      "   macro avg       0.98      0.98      0.98     10151\n",
      "weighted avg       0.99      0.99      0.99     10151\n",
      "\n",
      "Epoch: 4 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.92       173\n",
      "           1       0.99      0.98      0.98       954\n",
      "\n",
      "    accuracy                           0.97      1127\n",
      "   macro avg       0.94      0.97      0.95      1127\n",
      "weighted avg       0.97      0.97      0.97      1127\n",
      "\n",
      "Epoch: 5 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      1413\n",
      "           1       1.00      1.00      1.00      8738\n",
      "\n",
      "    accuracy                           0.99     10151\n",
      "   macro avg       0.98      0.99      0.99     10151\n",
      "weighted avg       0.99      0.99      0.99     10151\n",
      "\n",
      "Epoch: 5 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89       173\n",
      "           1       0.97      0.99      0.98       954\n",
      "\n",
      "    accuracy                           0.97      1127\n",
      "   macro avg       0.97      0.91      0.94      1127\n",
      "weighted avg       0.97      0.97      0.97      1127\n",
      "\n",
      "Epoch: 6 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      1413\n",
      "           1       1.00      1.00      1.00      8738\n",
      "\n",
      "    accuracy                           1.00     10151\n",
      "   macro avg       0.99      0.99      0.99     10151\n",
      "weighted avg       1.00      1.00      1.00     10151\n",
      "\n",
      "Epoch: 6 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.90       173\n",
      "           1       0.98      0.99      0.98       954\n",
      "\n",
      "    accuracy                           0.97      1127\n",
      "   macro avg       0.96      0.93      0.94      1127\n",
      "weighted avg       0.97      0.97      0.97      1127\n",
      "\n",
      "Epoch: 7 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1413\n",
      "           1       1.00      1.00      1.00      8738\n",
      "\n",
      "    accuracy                           1.00     10151\n",
      "   macro avg       0.99      0.99      0.99     10151\n",
      "weighted avg       1.00      1.00      1.00     10151\n",
      "\n",
      "Epoch: 7 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.89       173\n",
      "           1       0.97      1.00      0.98       954\n",
      "\n",
      "    accuracy                           0.97      1127\n",
      "   macro avg       0.98      0.90      0.93      1127\n",
      "weighted avg       0.97      0.97      0.97      1127\n",
      "\n",
      "Epoch: 8 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      1413\n",
      "           1       1.00      1.00      1.00      8738\n",
      "\n",
      "    accuracy                           1.00     10151\n",
      "   macro avg       0.99      0.99      0.99     10151\n",
      "weighted avg       1.00      1.00      1.00     10151\n",
      "\n",
      "Epoch: 8 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93       173\n",
      "           1       0.99      0.99      0.99       954\n",
      "\n",
      "    accuracy                           0.98      1127\n",
      "   macro avg       0.96      0.97      0.96      1127\n",
      "weighted avg       0.98      0.98      0.98      1127\n",
      "\n",
      "Epoch: 9 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1413\n",
      "           1       1.00      1.00      1.00      8738\n",
      "\n",
      "    accuracy                           1.00     10151\n",
      "   macro avg       0.99      1.00      0.99     10151\n",
      "weighted avg       1.00      1.00      1.00     10151\n",
      "\n",
      "Epoch: 9 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91       173\n",
      "           1       0.99      0.98      0.98       954\n",
      "\n",
      "    accuracy                           0.97      1127\n",
      "   macro avg       0.94      0.95      0.95      1127\n",
      "weighted avg       0.97      0.97      0.97      1127\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 **************************************************  Eval\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       174\n",
      "           1       0.99      0.99      0.99      1099\n",
      "\n",
      "    accuracy                           0.98      1273\n",
      "   macro avg       0.95      0.96      0.95      1273\n",
      "weighted avg       0.98      0.98      0.98      1273\n",
      "\n",
      "D:\\Repositories\\negation-detection\\data\\annotations_split\\train_annotations_2.json\n",
      "Epoch: 0 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.69      0.76      1434\n",
      "           1       0.95      0.98      0.96      8829\n",
      "\n",
      "    accuracy                           0.94     10263\n",
      "   macro avg       0.89      0.83      0.86     10263\n",
      "weighted avg       0.93      0.94      0.94     10263\n",
      "\n",
      "Epoch: 0 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       151\n",
      "           1       0.98      1.00      0.99       989\n",
      "\n",
      "    accuracy                           0.98      1140\n",
      "   macro avg       0.97      0.92      0.95      1140\n",
      "weighted avg       0.98      0.98      0.98      1140\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\2\\model.dat at epoch: 0 and f1: 0.9864797195793691 #####\n",
      "\n",
      "Epoch: 1 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91      1434\n",
      "           1       0.98      0.99      0.99      8829\n",
      "\n",
      "    accuracy                           0.98     10263\n",
      "   macro avg       0.96      0.94      0.95     10263\n",
      "weighted avg       0.98      0.98      0.98     10263\n",
      "\n",
      "Epoch: 1 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.87      0.91       151\n",
      "           1       0.98      0.99      0.99       989\n",
      "\n",
      "    accuracy                           0.98      1140\n",
      "   macro avg       0.97      0.93      0.95      1140\n",
      "weighted avg       0.98      0.98      0.98      1140\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\2\\model.dat at epoch: 1 and f1: 0.9869346733668342 #####\n",
      "\n",
      "Epoch: 2 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      1434\n",
      "           1       0.99      0.99      0.99      8829\n",
      "\n",
      "    accuracy                           0.98     10263\n",
      "   macro avg       0.97      0.96      0.96     10263\n",
      "weighted avg       0.98      0.98      0.98     10263\n",
      "\n",
      "Epoch: 2 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.78      0.87       151\n",
      "           1       0.97      1.00      0.98       989\n",
      "\n",
      "    accuracy                           0.97      1140\n",
      "   macro avg       0.98      0.89      0.93      1140\n",
      "weighted avg       0.97      0.97      0.97      1140\n",
      "\n",
      "Epoch: 3 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1434\n",
      "           1       0.99      0.99      0.99      8829\n",
      "\n",
      "    accuracy                           0.99     10263\n",
      "   macro avg       0.98      0.98      0.98     10263\n",
      "weighted avg       0.99      0.99      0.99     10263\n",
      "\n",
      "Epoch: 3 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90       151\n",
      "           1       0.99      0.98      0.98       989\n",
      "\n",
      "    accuracy                           0.97      1140\n",
      "   macro avg       0.93      0.96      0.94      1140\n",
      "weighted avg       0.97      0.97      0.97      1140\n",
      "\n",
      "Epoch: 4 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1434\n",
      "           1       1.00      0.99      0.99      8829\n",
      "\n",
      "    accuracy                           0.99     10263\n",
      "   macro avg       0.98      0.98      0.98     10263\n",
      "weighted avg       0.99      0.99      0.99     10263\n",
      "\n",
      "Epoch: 4 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90       151\n",
      "           1       0.98      0.99      0.99       989\n",
      "\n",
      "    accuracy                           0.97      1140\n",
      "   macro avg       0.95      0.94      0.94      1140\n",
      "weighted avg       0.97      0.97      0.97      1140\n",
      "\n",
      "Epoch: 5 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      1434\n",
      "           1       1.00      1.00      1.00      8829\n",
      "\n",
      "    accuracy                           0.99     10263\n",
      "   macro avg       0.99      0.99      0.99     10263\n",
      "weighted avg       0.99      0.99      0.99     10263\n",
      "\n",
      "Epoch: 5 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90       151\n",
      "           1       0.99      0.98      0.99       989\n",
      "\n",
      "    accuracy                           0.97      1140\n",
      "   macro avg       0.94      0.95      0.94      1140\n",
      "weighted avg       0.97      0.97      0.97      1140\n",
      "\n",
      "Epoch: 6 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1434\n",
      "           1       1.00      1.00      1.00      8829\n",
      "\n",
      "    accuracy                           1.00     10263\n",
      "   macro avg       0.99      0.99      0.99     10263\n",
      "weighted avg       1.00      1.00      1.00     10263\n",
      "\n",
      "Epoch: 6 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89       151\n",
      "           1       0.99      0.98      0.98       989\n",
      "\n",
      "    accuracy                           0.97      1140\n",
      "   macro avg       0.92      0.95      0.94      1140\n",
      "weighted avg       0.97      0.97      0.97      1140\n",
      "\n",
      "Epoch: 7 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1434\n",
      "           1       1.00      0.99      1.00      8829\n",
      "\n",
      "    accuracy                           0.99     10263\n",
      "   macro avg       0.98      0.99      0.99     10263\n",
      "weighted avg       0.99      0.99      0.99     10263\n",
      "\n",
      "Epoch: 7 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.81      0.88       151\n",
      "           1       0.97      1.00      0.98       989\n",
      "\n",
      "    accuracy                           0.97      1140\n",
      "   macro avg       0.97      0.90      0.93      1140\n",
      "weighted avg       0.97      0.97      0.97      1140\n",
      "\n",
      "Epoch: 8 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1434\n",
      "           1       1.00      1.00      1.00      8829\n",
      "\n",
      "    accuracy                           1.00     10263\n",
      "   macro avg       0.99      0.99      0.99     10263\n",
      "weighted avg       1.00      1.00      1.00     10263\n",
      "\n",
      "Epoch: 8 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       151\n",
      "           1       0.98      0.99      0.99       989\n",
      "\n",
      "    accuracy                           0.97      1140\n",
      "   macro avg       0.95      0.94      0.94      1140\n",
      "weighted avg       0.97      0.97      0.97      1140\n",
      "\n",
      "Epoch: 9 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      1434\n",
      "           1       1.00      1.00      1.00      8829\n",
      "\n",
      "    accuracy                           1.00     10263\n",
      "   macro avg       0.99      1.00      0.99     10263\n",
      "weighted avg       1.00      1.00      1.00     10263\n",
      "\n",
      "Epoch: 9 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.85      0.89       151\n",
      "           1       0.98      0.99      0.98       989\n",
      "\n",
      "    accuracy                           0.97      1140\n",
      "   macro avg       0.95      0.92      0.94      1140\n",
      "weighted avg       0.97      0.97      0.97      1140\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 **************************************************  Eval\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94       175\n",
      "           1       0.99      0.99      0.99       973\n",
      "\n",
      "    accuracy                           0.98      1148\n",
      "   macro avg       0.97      0.96      0.96      1148\n",
      "weighted avg       0.98      0.98      0.98      1148\n",
      "\n",
      "D:\\Repositories\\negation-detection\\data\\annotations_split\\train_annotations_3.json\n",
      "Epoch: 0 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.69      0.76      1412\n",
      "           1       0.95      0.98      0.97      8755\n",
      "\n",
      "    accuracy                           0.94     10167\n",
      "   macro avg       0.90      0.84      0.86     10167\n",
      "weighted avg       0.94      0.94      0.94     10167\n",
      "\n",
      "Epoch: 0 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.82      0.88       181\n",
      "           1       0.97      0.99      0.98       948\n",
      "\n",
      "    accuracy                           0.96      1129\n",
      "   macro avg       0.95      0.91      0.93      1129\n",
      "weighted avg       0.96      0.96      0.96      1129\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\3\\model.dat at epoch: 0 and f1: 0.9781021897810219 #####\n",
      "\n",
      "Epoch: 1 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.90      1412\n",
      "           1       0.98      0.99      0.99      8755\n",
      "\n",
      "    accuracy                           0.97     10167\n",
      "   macro avg       0.95      0.94      0.94     10167\n",
      "weighted avg       0.97      0.97      0.97     10167\n",
      "\n",
      "Epoch: 1 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94       181\n",
      "           1       1.00      0.98      0.99       948\n",
      "\n",
      "    accuracy                           0.98      1129\n",
      "   macro avg       0.95      0.98      0.96      1129\n",
      "weighted avg       0.98      0.98      0.98      1129\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\3\\model.dat at epoch: 1 and f1: 0.9872340425531914 #####\n",
      "\n",
      "Epoch: 2 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      1412\n",
      "           1       0.99      0.99      0.99      8755\n",
      "\n",
      "    accuracy                           0.98     10167\n",
      "   macro avg       0.97      0.96      0.97     10167\n",
      "weighted avg       0.98      0.98      0.98     10167\n",
      "\n",
      "Epoch: 2 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91       181\n",
      "           1       0.97      1.00      0.98       948\n",
      "\n",
      "    accuracy                           0.97      1129\n",
      "   macro avg       0.98      0.92      0.95      1129\n",
      "weighted avg       0.97      0.97      0.97      1129\n",
      "\n",
      "Epoch: 3 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      1412\n",
      "           1       0.99      0.99      0.99      8755\n",
      "\n",
      "    accuracy                           0.99     10167\n",
      "   macro avg       0.98      0.98      0.98     10167\n",
      "weighted avg       0.99      0.99      0.99     10167\n",
      "\n",
      "Epoch: 3 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92       181\n",
      "           1       0.98      0.99      0.99       948\n",
      "\n",
      "    accuracy                           0.98      1129\n",
      "   macro avg       0.96      0.95      0.95      1129\n",
      "weighted avg       0.97      0.98      0.97      1129\n",
      "\n",
      "Epoch: 4 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1412\n",
      "           1       0.99      0.99      0.99      8755\n",
      "\n",
      "    accuracy                           0.99     10167\n",
      "   macro avg       0.98      0.98      0.98     10167\n",
      "weighted avg       0.99      0.99      0.99     10167\n",
      "\n",
      "Epoch: 4 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.93       181\n",
      "           1       0.98      0.99      0.99       948\n",
      "\n",
      "    accuracy                           0.98      1129\n",
      "   macro avg       0.97      0.94      0.96      1129\n",
      "weighted avg       0.98      0.98      0.98      1129\n",
      "\n",
      "Epoch: 5 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1412\n",
      "           1       1.00      1.00      1.00      8755\n",
      "\n",
      "    accuracy                           0.99     10167\n",
      "   macro avg       0.99      0.99      0.99     10167\n",
      "weighted avg       0.99      0.99      0.99     10167\n",
      "\n",
      "Epoch: 5 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92       181\n",
      "           1       0.98      0.99      0.99       948\n",
      "\n",
      "    accuracy                           0.98      1129\n",
      "   macro avg       0.96      0.95      0.95      1129\n",
      "weighted avg       0.97      0.98      0.97      1129\n",
      "\n",
      "Epoch: 6 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1412\n",
      "           1       1.00      1.00      1.00      8755\n",
      "\n",
      "    accuracy                           0.99     10167\n",
      "   macro avg       0.99      0.99      0.99     10167\n",
      "weighted avg       0.99      0.99      0.99     10167\n",
      "\n",
      "Epoch: 6 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       181\n",
      "           1       0.99      0.99      0.99       948\n",
      "\n",
      "    accuracy                           0.98      1129\n",
      "   macro avg       0.95      0.95      0.95      1129\n",
      "weighted avg       0.98      0.98      0.98      1129\n",
      "\n",
      "Epoch: 7 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1412\n",
      "           1       1.00      1.00      1.00      8755\n",
      "\n",
      "    accuracy                           1.00     10167\n",
      "   macro avg       0.99      0.99      0.99     10167\n",
      "weighted avg       1.00      1.00      1.00     10167\n",
      "\n",
      "Epoch: 7 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93       181\n",
      "           1       0.99      0.98      0.99       948\n",
      "\n",
      "    accuracy                           0.98      1129\n",
      "   macro avg       0.95      0.96      0.96      1129\n",
      "weighted avg       0.98      0.98      0.98      1129\n",
      "\n",
      "Epoch: 8 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1412\n",
      "           1       1.00      1.00      1.00      8755\n",
      "\n",
      "    accuracy                           1.00     10167\n",
      "   macro avg       0.99      0.99      0.99     10167\n",
      "weighted avg       1.00      1.00      1.00     10167\n",
      "\n",
      "Epoch: 8 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89       181\n",
      "           1       0.98      0.98      0.98       948\n",
      "\n",
      "    accuracy                           0.97      1129\n",
      "   macro avg       0.94      0.93      0.94      1129\n",
      "weighted avg       0.97      0.97      0.97      1129\n",
      "\n",
      "Epoch: 9 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      1412\n",
      "           1       1.00      1.00      1.00      8755\n",
      "\n",
      "    accuracy                           1.00     10167\n",
      "   macro avg       0.99      0.99      0.99     10167\n",
      "weighted avg       1.00      1.00      1.00     10167\n",
      "\n",
      "Epoch: 9 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       181\n",
      "           1       0.99      0.98      0.98       948\n",
      "\n",
      "    accuracy                           0.97      1129\n",
      "   macro avg       0.95      0.96      0.95      1129\n",
      "weighted avg       0.97      0.97      0.97      1129\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 **************************************************  Eval\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.90       167\n",
      "           1       0.99      0.98      0.98      1088\n",
      "\n",
      "    accuracy                           0.97      1255\n",
      "   macro avg       0.93      0.95      0.94      1255\n",
      "weighted avg       0.97      0.97      0.97      1255\n",
      "\n",
      "D:\\Repositories\\negation-detection\\data\\annotations_split\\train_annotations_4.json\n",
      "Epoch: 0 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.71      0.78      1416\n",
      "           1       0.95      0.98      0.97      8712\n",
      "\n",
      "    accuracy                           0.94     10128\n",
      "   macro avg       0.91      0.85      0.87     10128\n",
      "weighted avg       0.94      0.94      0.94     10128\n",
      "\n",
      "Epoch: 0 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87       170\n",
      "           1       0.97      0.99      0.98       955\n",
      "\n",
      "    accuracy                           0.96      1125\n",
      "   macro avg       0.95      0.90      0.93      1125\n",
      "weighted avg       0.96      0.96      0.96      1125\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\4\\model.dat at epoch: 0 and f1: 0.9787674779906784 #####\n",
      "\n",
      "Epoch: 1 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      1416\n",
      "           1       0.98      0.99      0.99      8712\n",
      "\n",
      "    accuracy                           0.98     10128\n",
      "   macro avg       0.96      0.95      0.96     10128\n",
      "weighted avg       0.98      0.98      0.98     10128\n",
      "\n",
      "Epoch: 1 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89       170\n",
      "           1       0.98      0.98      0.98       955\n",
      "\n",
      "    accuracy                           0.97      1125\n",
      "   macro avg       0.94      0.93      0.94      1125\n",
      "weighted avg       0.97      0.97      0.97      1125\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\4\\model.dat at epoch: 1 and f1: 0.9811912225705328 #####\n",
      "\n",
      "Epoch: 2 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      1416\n",
      "           1       0.99      0.99      0.99      8712\n",
      "\n",
      "    accuracy                           0.98     10128\n",
      "   macro avg       0.97      0.96      0.97     10128\n",
      "weighted avg       0.98      0.98      0.98     10128\n",
      "\n",
      "Epoch: 2 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.88       170\n",
      "           1       0.97      0.99      0.98       955\n",
      "\n",
      "    accuracy                           0.97      1125\n",
      "   macro avg       0.95      0.91      0.93      1125\n",
      "weighted avg       0.97      0.97      0.97      1125\n",
      "\n",
      "Epoch: 3 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      1416\n",
      "           1       0.99      1.00      0.99      8712\n",
      "\n",
      "    accuracy                           0.99     10128\n",
      "   macro avg       0.98      0.98      0.98     10128\n",
      "weighted avg       0.99      0.99      0.99     10128\n",
      "\n",
      "Epoch: 3 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       170\n",
      "           1       0.99      0.98      0.98       955\n",
      "\n",
      "    accuracy                           0.97      1125\n",
      "   macro avg       0.93      0.95      0.94      1125\n",
      "weighted avg       0.97      0.97      0.97      1125\n",
      "\n",
      "Epoch: 4 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1416\n",
      "           1       0.99      1.00      1.00      8712\n",
      "\n",
      "    accuracy                           0.99     10128\n",
      "   macro avg       0.99      0.98      0.98     10128\n",
      "weighted avg       0.99      0.99      0.99     10128\n",
      "\n",
      "Epoch: 4 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90       170\n",
      "           1       0.98      0.99      0.98       955\n",
      "\n",
      "    accuracy                           0.97      1125\n",
      "   macro avg       0.96      0.92      0.94      1125\n",
      "weighted avg       0.97      0.97      0.97      1125\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\4\\model.dat at epoch: 4 and f1: 0.9823284823284824 #####\n",
      "\n",
      "Epoch: 5 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1416\n",
      "           1       1.00      1.00      1.00      8712\n",
      "\n",
      "    accuracy                           1.00     10128\n",
      "   macro avg       0.99      0.99      0.99     10128\n",
      "weighted avg       1.00      1.00      1.00     10128\n",
      "\n",
      "Epoch: 5 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       170\n",
      "           1       0.98      0.99      0.98       955\n",
      "\n",
      "    accuracy                           0.97      1125\n",
      "   macro avg       0.95      0.93      0.94      1125\n",
      "weighted avg       0.97      0.97      0.97      1125\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\4\\model.dat at epoch: 5 and f1: 0.9833333333333334 #####\n",
      "\n",
      "Epoch: 6 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1416\n",
      "           1       1.00      1.00      1.00      8712\n",
      "\n",
      "    accuracy                           1.00     10128\n",
      "   macro avg       0.99      0.99      0.99     10128\n",
      "weighted avg       1.00      1.00      1.00     10128\n",
      "\n",
      "Epoch: 6 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.90       170\n",
      "           1       0.98      0.99      0.98       955\n",
      "\n",
      "    accuracy                           0.97      1125\n",
      "   macro avg       0.95      0.94      0.94      1125\n",
      "weighted avg       0.97      0.97      0.97      1125\n",
      "\n",
      "Epoch: 7 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1416\n",
      "           1       1.00      1.00      1.00      8712\n",
      "\n",
      "    accuracy                           1.00     10128\n",
      "   macro avg       0.99      0.99      0.99     10128\n",
      "weighted avg       1.00      1.00      1.00     10128\n",
      "\n",
      "Epoch: 7 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.93       170\n",
      "           1       0.98      0.99      0.99       955\n",
      "\n",
      "    accuracy                           0.98      1125\n",
      "   macro avg       0.97      0.94      0.96      1125\n",
      "weighted avg       0.98      0.98      0.98      1125\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\4\\model.dat at epoch: 7 and f1: 0.9875130072840791 #####\n",
      "\n",
      "Epoch: 8 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      1416\n",
      "           1       1.00      1.00      1.00      8712\n",
      "\n",
      "    accuracy                           1.00     10128\n",
      "   macro avg       0.99      0.99      0.99     10128\n",
      "weighted avg       1.00      1.00      1.00     10128\n",
      "\n",
      "Epoch: 8 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92       170\n",
      "           1       0.98      0.99      0.99       955\n",
      "\n",
      "    accuracy                           0.98      1125\n",
      "   macro avg       0.97      0.94      0.95      1125\n",
      "weighted avg       0.98      0.98      0.98      1125\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1416\n",
      "           1       1.00      1.00      1.00      8712\n",
      "\n",
      "    accuracy                           1.00     10128\n",
      "   macro avg       0.99      0.99      0.99     10128\n",
      "weighted avg       1.00      1.00      1.00     10128\n",
      "\n",
      "Epoch: 9 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       170\n",
      "           1       0.98      0.99      0.98       955\n",
      "\n",
      "    accuracy                           0.97      1125\n",
      "   macro avg       0.95      0.94      0.95      1125\n",
      "weighted avg       0.97      0.97      0.97      1125\n",
      "\n",
      "Epoch: 0 **************************************************  Eval\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93       174\n",
      "           1       0.98      0.99      0.99      1124\n",
      "\n",
      "    accuracy                           0.98      1298\n",
      "   macro avg       0.97      0.95      0.96      1298\n",
      "weighted avg       0.98      0.98      0.98      1298\n",
      "\n",
      "D:\\Repositories\\negation-detection\\data\\annotations_split\\train_annotations_5.json\n",
      "Epoch: 0 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.69      0.75      1406\n",
      "           1       0.95      0.98      0.96      8707\n",
      "\n",
      "    accuracy                           0.94     10113\n",
      "   macro avg       0.89      0.83      0.86     10113\n",
      "weighted avg       0.93      0.94      0.93     10113\n",
      "\n",
      "Epoch: 0 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.89       170\n",
      "           1       0.97      0.99      0.98       953\n",
      "\n",
      "    accuracy                           0.97      1123\n",
      "   macro avg       0.95      0.92      0.93      1123\n",
      "weighted avg       0.97      0.97      0.97      1123\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\5\\model.dat at epoch: 0 and f1: 0.9807592303692148 #####\n",
      "\n",
      "Epoch: 1 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91      1406\n",
      "           1       0.98      0.99      0.99      8707\n",
      "\n",
      "    accuracy                           0.98     10113\n",
      "   macro avg       0.96      0.94      0.95     10113\n",
      "weighted avg       0.98      0.98      0.98     10113\n",
      "\n",
      "Epoch: 1 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92       170\n",
      "           1       0.98      0.99      0.99       953\n",
      "\n",
      "    accuracy                           0.98      1123\n",
      "   macro avg       0.96      0.94      0.95      1123\n",
      "weighted avg       0.98      0.98      0.98      1123\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\5\\model.dat at epoch: 1 and f1: 0.9859007832898172 #####\n",
      "\n",
      "Epoch: 2 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94      1406\n",
      "           1       0.99      0.99      0.99      8707\n",
      "\n",
      "    accuracy                           0.98     10113\n",
      "   macro avg       0.97      0.96      0.96     10113\n",
      "weighted avg       0.98      0.98      0.98     10113\n",
      "\n",
      "Epoch: 2 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93       170\n",
      "           1       0.99      0.99      0.99       953\n",
      "\n",
      "    accuracy                           0.98      1123\n",
      "   macro avg       0.96      0.96      0.96      1123\n",
      "weighted avg       0.98      0.98      0.98      1123\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\5\\model.dat at epoch: 2 and f1: 0.9868904037755637 #####\n",
      "\n",
      "Epoch: 3 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1406\n",
      "           1       0.99      0.99      0.99      8707\n",
      "\n",
      "    accuracy                           0.99     10113\n",
      "   macro avg       0.98      0.98      0.98     10113\n",
      "weighted avg       0.99      0.99      0.99     10113\n",
      "\n",
      "Epoch: 3 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.76      0.86       170\n",
      "           1       0.96      1.00      0.98       953\n",
      "\n",
      "    accuracy                           0.96      1123\n",
      "   macro avg       0.98      0.88      0.92      1123\n",
      "weighted avg       0.96      0.96      0.96      1123\n",
      "\n",
      "Epoch: 4 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1406\n",
      "           1       1.00      0.99      1.00      8707\n",
      "\n",
      "    accuracy                           0.99     10113\n",
      "   macro avg       0.98      0.98      0.98     10113\n",
      "weighted avg       0.99      0.99      0.99     10113\n",
      "\n",
      "Epoch: 4 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94       170\n",
      "           1       0.98      0.99      0.99       953\n",
      "\n",
      "    accuracy                           0.98      1123\n",
      "   macro avg       0.98      0.95      0.96      1123\n",
      "weighted avg       0.98      0.98      0.98      1123\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\5\\model.dat at epoch: 4 and f1: 0.9895615866388309 #####\n",
      "\n",
      "Epoch: 5 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      1406\n",
      "           1       1.00      1.00      1.00      8707\n",
      "\n",
      "    accuracy                           0.99     10113\n",
      "   macro avg       0.98      0.99      0.99     10113\n",
      "weighted avg       0.99      0.99      0.99     10113\n",
      "\n",
      "Epoch: 5 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.90       170\n",
      "           1       0.97      1.00      0.98       953\n",
      "\n",
      "    accuracy                           0.97      1123\n",
      "   macro avg       0.98      0.91      0.94      1123\n",
      "weighted avg       0.97      0.97      0.97      1123\n",
      "\n",
      "Epoch: 6 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      1406\n",
      "           1       0.99      1.00      1.00      8707\n",
      "\n",
      "    accuracy                           0.99     10113\n",
      "   macro avg       0.99      0.98      0.99     10113\n",
      "weighted avg       0.99      0.99      0.99     10113\n",
      "\n",
      "Epoch: 6 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90       170\n",
      "           1       0.99      0.97      0.98       953\n",
      "\n",
      "    accuracy                           0.97      1123\n",
      "   macro avg       0.92      0.97      0.94      1123\n",
      "weighted avg       0.97      0.97      0.97      1123\n",
      "\n",
      "Epoch: 7 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1406\n",
      "           1       1.00      1.00      1.00      8707\n",
      "\n",
      "    accuracy                           0.99     10113\n",
      "   macro avg       0.99      0.99      0.99     10113\n",
      "weighted avg       0.99      0.99      0.99     10113\n",
      "\n",
      "Epoch: 7 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.89       170\n",
      "           1       0.97      1.00      0.98       953\n",
      "\n",
      "    accuracy                           0.97      1123\n",
      "   macro avg       0.98      0.90      0.93      1123\n",
      "weighted avg       0.97      0.97      0.97      1123\n",
      "\n",
      "Epoch: 8 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      1406\n",
      "           1       1.00      1.00      1.00      8707\n",
      "\n",
      "    accuracy                           1.00     10113\n",
      "   macro avg       0.99      0.99      0.99     10113\n",
      "weighted avg       1.00      1.00      1.00     10113\n",
      "\n",
      "Epoch: 8 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92       170\n",
      "           1       0.99      0.98      0.99       953\n",
      "\n",
      "    accuracy                           0.98      1123\n",
      "   macro avg       0.95      0.96      0.96      1123\n",
      "weighted avg       0.98      0.98      0.98      1123\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1406\n",
      "           1       1.00      1.00      1.00      8707\n",
      "\n",
      "    accuracy                           1.00     10113\n",
      "   macro avg       0.99      0.99      0.99     10113\n",
      "weighted avg       1.00      1.00      1.00     10113\n",
      "\n",
      "Epoch: 9 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90       170\n",
      "           1       0.97      0.99      0.98       953\n",
      "\n",
      "    accuracy                           0.97      1123\n",
      "   macro avg       0.97      0.92      0.94      1123\n",
      "weighted avg       0.97      0.97      0.97      1123\n",
      "\n",
      "Epoch: 0 **************************************************  Eval\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90       184\n",
      "           1       0.98      0.99      0.98      1131\n",
      "\n",
      "    accuracy                           0.97      1315\n",
      "   macro avg       0.96      0.92      0.94      1315\n",
      "weighted avg       0.97      0.97      0.97      1315\n",
      "\n",
      "D:\\Repositories\\negation-detection\\data\\annotations_split\\train_annotations_6.json\n",
      "Epoch: 0 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.67      0.75      1485\n",
      "           1       0.95      0.98      0.96      8739\n",
      "\n",
      "    accuracy                           0.93     10224\n",
      "   macro avg       0.89      0.83      0.86     10224\n",
      "weighted avg       0.93      0.93      0.93     10224\n",
      "\n",
      "Epoch: 0 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       136\n",
      "           1       0.99      0.98      0.99       999\n",
      "\n",
      "    accuracy                           0.97      1135\n",
      "   macro avg       0.94      0.94      0.94      1135\n",
      "weighted avg       0.97      0.97      0.97      1135\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\6\\model.dat at epoch: 0 and f1: 0.9854636591478696 #####\n",
      "\n",
      "Epoch: 1 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      1485\n",
      "           1       0.98      0.99      0.99      8739\n",
      "\n",
      "    accuracy                           0.98     10224\n",
      "   macro avg       0.96      0.94      0.95     10224\n",
      "weighted avg       0.98      0.98      0.98     10224\n",
      "\n",
      "Epoch: 1 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94       136\n",
      "           1       0.99      0.99      0.99       999\n",
      "\n",
      "    accuracy                           0.99      1135\n",
      "   macro avg       0.97      0.96      0.96      1135\n",
      "weighted avg       0.98      0.99      0.98      1135\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\6\\model.dat at epoch: 1 and f1: 0.991495747873937 #####\n",
      "\n",
      "Epoch: 2 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95      1485\n",
      "           1       0.99      0.99      0.99      8739\n",
      "\n",
      "    accuracy                           0.99     10224\n",
      "   macro avg       0.97      0.97      0.97     10224\n",
      "weighted avg       0.99      0.99      0.99     10224\n",
      "\n",
      "Epoch: 2 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94       136\n",
      "           1       0.99      1.00      0.99       999\n",
      "\n",
      "    accuracy                           0.99      1135\n",
      "   macro avg       0.99      0.94      0.97      1135\n",
      "weighted avg       0.99      0.99      0.99      1135\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\6\\model.dat at epoch: 2 and f1: 0.9920477137176937 #####\n",
      "\n",
      "Epoch: 3 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1485\n",
      "           1       0.99      0.99      0.99      8739\n",
      "\n",
      "    accuracy                           0.99     10224\n",
      "   macro avg       0.98      0.98      0.98     10224\n",
      "weighted avg       0.99      0.99      0.99     10224\n",
      "\n",
      "Epoch: 3 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       136\n",
      "           1       0.99      0.99      0.99       999\n",
      "\n",
      "    accuracy                           0.98      1135\n",
      "   macro avg       0.95      0.96      0.95      1135\n",
      "weighted avg       0.98      0.98      0.98      1135\n",
      "\n",
      "Epoch: 4 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1485\n",
      "           1       0.99      1.00      0.99      8739\n",
      "\n",
      "    accuracy                           0.99     10224\n",
      "   macro avg       0.98      0.98      0.98     10224\n",
      "weighted avg       0.99      0.99      0.99     10224\n",
      "\n",
      "Epoch: 4 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94       136\n",
      "           1       0.99      1.00      0.99       999\n",
      "\n",
      "    accuracy                           0.99      1135\n",
      "   macro avg       0.98      0.95      0.97      1135\n",
      "weighted avg       0.99      0.99      0.99      1135\n",
      "\n",
      "Epoch: 5 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      1485\n",
      "           1       1.00      1.00      1.00      8739\n",
      "\n",
      "    accuracy                           0.99     10224\n",
      "   macro avg       0.99      0.98      0.99     10224\n",
      "weighted avg       0.99      0.99      0.99     10224\n",
      "\n",
      "Epoch: 5 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.82      0.89       136\n",
      "           1       0.98      1.00      0.99       999\n",
      "\n",
      "    accuracy                           0.98      1135\n",
      "   macro avg       0.98      0.91      0.94      1135\n",
      "weighted avg       0.98      0.98      0.98      1135\n",
      "\n",
      "Epoch: 6 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1485\n",
      "           1       1.00      1.00      1.00      8739\n",
      "\n",
      "    accuracy                           1.00     10224\n",
      "   macro avg       0.99      0.99      0.99     10224\n",
      "weighted avg       1.00      1.00      1.00     10224\n",
      "\n",
      "Epoch: 6 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92       136\n",
      "           1       0.99      0.99      0.99       999\n",
      "\n",
      "    accuracy                           0.98      1135\n",
      "   macro avg       0.97      0.95      0.96      1135\n",
      "weighted avg       0.98      0.98      0.98      1135\n",
      "\n",
      "Epoch: 7 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1485\n",
      "           1       1.00      1.00      1.00      8739\n",
      "\n",
      "    accuracy                           0.99     10224\n",
      "   macro avg       0.99      0.99      0.99     10224\n",
      "weighted avg       0.99      0.99      0.99     10224\n",
      "\n",
      "Epoch: 7 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91       136\n",
      "           1       0.99      0.98      0.99       999\n",
      "\n",
      "    accuracy                           0.98      1135\n",
      "   macro avg       0.94      0.96      0.95      1135\n",
      "weighted avg       0.98      0.98      0.98      1135\n",
      "\n",
      "Epoch: 8 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1485\n",
      "           1       1.00      1.00      1.00      8739\n",
      "\n",
      "    accuracy                           1.00     10224\n",
      "   macro avg       0.99      1.00      1.00     10224\n",
      "weighted avg       1.00      1.00      1.00     10224\n",
      "\n",
      "Epoch: 8 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92       136\n",
      "           1       0.99      0.99      0.99       999\n",
      "\n",
      "    accuracy                           0.98      1135\n",
      "   macro avg       0.95      0.95      0.95      1135\n",
      "weighted avg       0.98      0.98      0.98      1135\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1485\n",
      "           1       1.00      1.00      1.00      8739\n",
      "\n",
      "    accuracy                           1.00     10224\n",
      "   macro avg       1.00      1.00      1.00     10224\n",
      "weighted avg       1.00      1.00      1.00     10224\n",
      "\n",
      "Epoch: 9 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       136\n",
      "           1       0.99      0.99      0.99       999\n",
      "\n",
      "    accuracy                           0.98      1135\n",
      "   macro avg       0.95      0.95      0.95      1135\n",
      "weighted avg       0.98      0.98      0.98      1135\n",
      "\n",
      "Epoch: 0 **************************************************  Eval\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94       139\n",
      "           1       0.99      1.00      0.99      1053\n",
      "\n",
      "    accuracy                           0.99      1192\n",
      "   macro avg       0.99      0.95      0.97      1192\n",
      "weighted avg       0.99      0.99      0.99      1192\n",
      "\n",
      "D:\\Repositories\\negation-detection\\data\\annotations_split\\train_annotations_7.json\n",
      "Epoch: 0 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.69      0.76      1431\n",
      "           1       0.95      0.98      0.96      8721\n",
      "\n",
      "    accuracy                           0.94     10152\n",
      "   macro avg       0.90      0.84      0.86     10152\n",
      "weighted avg       0.94      0.94      0.94     10152\n",
      "\n",
      "Epoch: 0 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88       141\n",
      "           1       0.98      0.98      0.98       986\n",
      "\n",
      "    accuracy                           0.97      1127\n",
      "   macro avg       0.93      0.93      0.93      1127\n",
      "weighted avg       0.97      0.97      0.97      1127\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\7\\model.dat at epoch: 0 and f1: 0.9822605169792195 #####\n",
      "\n",
      "Epoch: 1 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92      1431\n",
      "           1       0.99      0.99      0.99      8721\n",
      "\n",
      "    accuracy                           0.98     10152\n",
      "   macro avg       0.96      0.95      0.95     10152\n",
      "weighted avg       0.98      0.98      0.98     10152\n",
      "\n",
      "Epoch: 1 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90       141\n",
      "           1       0.99      0.98      0.99       986\n",
      "\n",
      "    accuracy                           0.97      1127\n",
      "   macro avg       0.93      0.96      0.94      1127\n",
      "weighted avg       0.98      0.97      0.97      1127\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\7\\model.dat at epoch: 1 and f1: 0.9851814001021972 #####\n",
      "\n",
      "Epoch: 2 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      1431\n",
      "           1       0.99      0.99      0.99      8721\n",
      "\n",
      "    accuracy                           0.99     10152\n",
      "   macro avg       0.97      0.97      0.97     10152\n",
      "weighted avg       0.99      0.99      0.99     10152\n",
      "\n",
      "Epoch: 2 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89       141\n",
      "           1       0.98      0.99      0.99       986\n",
      "\n",
      "    accuracy                           0.97      1127\n",
      "   macro avg       0.97      0.91      0.94      1127\n",
      "weighted avg       0.97      0.97      0.97      1127\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\7\\model.dat at epoch: 2 and f1: 0.9854344550477148 #####\n",
      "\n",
      "Epoch: 3 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1431\n",
      "           1       0.99      0.99      0.99      8721\n",
      "\n",
      "    accuracy                           0.99     10152\n",
      "   macro avg       0.98      0.98      0.98     10152\n",
      "weighted avg       0.99      0.99      0.99     10152\n",
      "\n",
      "Epoch: 3 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91       141\n",
      "           1       0.98      0.99      0.99       986\n",
      "\n",
      "    accuracy                           0.98      1127\n",
      "   macro avg       0.96      0.94      0.95      1127\n",
      "weighted avg       0.98      0.98      0.98      1127\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\7\\model.dat at epoch: 3 and f1: 0.9878665318503539 #####\n",
      "\n",
      "Epoch: 4 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1431\n",
      "           1       1.00      1.00      1.00      8721\n",
      "\n",
      "    accuracy                           0.99     10152\n",
      "   macro avg       0.99      0.99      0.99     10152\n",
      "weighted avg       0.99      0.99      0.99     10152\n",
      "\n",
      "Epoch: 4 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.90       141\n",
      "           1       0.98      0.99      0.99       986\n",
      "\n",
      "    accuracy                           0.97      1127\n",
      "   macro avg       0.95      0.93      0.94      1127\n",
      "weighted avg       0.97      0.97      0.97      1127\n",
      "\n",
      "Epoch: 5 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1431\n",
      "           1       1.00      1.00      1.00      8721\n",
      "\n",
      "    accuracy                           0.99     10152\n",
      "   macro avg       0.99      0.99      0.99     10152\n",
      "weighted avg       0.99      0.99      0.99     10152\n",
      "\n",
      "Epoch: 5 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89       141\n",
      "           1       0.99      0.98      0.98       986\n",
      "\n",
      "    accuracy                           0.97      1127\n",
      "   macro avg       0.92      0.95      0.94      1127\n",
      "weighted avg       0.97      0.97      0.97      1127\n",
      "\n",
      "Epoch: 6 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1431\n",
      "           1       1.00      1.00      1.00      8721\n",
      "\n",
      "    accuracy                           0.99     10152\n",
      "   macro avg       0.99      0.99      0.99     10152\n",
      "weighted avg       0.99      0.99      0.99     10152\n",
      "\n",
      "Epoch: 6 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.82      0.88       141\n",
      "           1       0.97      0.99      0.98       986\n",
      "\n",
      "    accuracy                           0.97      1127\n",
      "   macro avg       0.96      0.90      0.93      1127\n",
      "weighted avg       0.97      0.97      0.97      1127\n",
      "\n",
      "Epoch: 7 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1431\n",
      "           1       1.00      1.00      1.00      8721\n",
      "\n",
      "    accuracy                           0.99     10152\n",
      "   macro avg       0.99      0.99      0.99     10152\n",
      "weighted avg       0.99      0.99      0.99     10152\n",
      "\n",
      "Epoch: 7 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89       141\n",
      "           1       1.00      0.97      0.98       986\n",
      "\n",
      "    accuracy                           0.97      1127\n",
      "   macro avg       0.91      0.97      0.93      1127\n",
      "weighted avg       0.97      0.97      0.97      1127\n",
      "\n",
      "Epoch: 8 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1431\n",
      "           1       1.00      1.00      1.00      8721\n",
      "\n",
      "    accuracy                           1.00     10152\n",
      "   macro avg       0.99      1.00      0.99     10152\n",
      "weighted avg       1.00      1.00      1.00     10152\n",
      "\n",
      "Epoch: 8 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       141\n",
      "           1       0.99      0.99      0.99       986\n",
      "\n",
      "    accuracy                           0.98      1127\n",
      "   macro avg       0.95      0.96      0.95      1127\n",
      "weighted avg       0.98      0.98      0.98      1127\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\7\\model.dat at epoch: 8 and f1: 0.9883070665988816 #####\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1431\n",
      "           1       1.00      1.00      1.00      8721\n",
      "\n",
      "    accuracy                           1.00     10152\n",
      "   macro avg       1.00      1.00      1.00     10152\n",
      "weighted avg       1.00      1.00      1.00     10152\n",
      "\n",
      "Epoch: 9 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90       141\n",
      "           1       0.99      0.98      0.99       986\n",
      "\n",
      "    accuracy                           0.98      1127\n",
      "   macro avg       0.93      0.96      0.94      1127\n",
      "weighted avg       0.98      0.98      0.98      1127\n",
      "\n",
      "Epoch: 0 **************************************************  Eval\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       188\n",
      "           1       0.99      0.97      0.98      1084\n",
      "\n",
      "    accuracy                           0.97      1272\n",
      "   macro avg       0.92      0.95      0.93      1272\n",
      "weighted avg       0.97      0.97      0.97      1272\n",
      "\n",
      "D:\\Repositories\\negation-detection\\data\\annotations_split\\train_annotations_8.json\n",
      "Epoch: 0 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.70      0.76      1414\n",
      "           1       0.95      0.98      0.96      8765\n",
      "\n",
      "    accuracy                           0.94     10179\n",
      "   macro avg       0.89      0.84      0.86     10179\n",
      "weighted avg       0.94      0.94      0.94     10179\n",
      "\n",
      "Epoch: 0 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.88       163\n",
      "           1       0.98      0.98      0.98       967\n",
      "\n",
      "    accuracy                           0.97      1130\n",
      "   macro avg       0.94      0.92      0.93      1130\n",
      "weighted avg       0.96      0.97      0.97      1130\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\8\\model.dat at epoch: 0 and f1: 0.979927946474524 #####\n",
      "\n",
      "Epoch: 1 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92      1414\n",
      "           1       0.98      0.99      0.99      8765\n",
      "\n",
      "    accuracy                           0.98     10179\n",
      "   macro avg       0.96      0.94      0.95     10179\n",
      "weighted avg       0.98      0.98      0.98     10179\n",
      "\n",
      "Epoch: 1 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.89       163\n",
      "           1       0.97      0.99      0.98       967\n",
      "\n",
      "    accuracy                           0.97      1130\n",
      "   macro avg       0.96      0.92      0.94      1130\n",
      "weighted avg       0.97      0.97      0.97      1130\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\8\\model.dat at epoch: 1 and f1: 0.9830855971296771 #####\n",
      "\n",
      "Epoch: 2 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95      1414\n",
      "           1       0.99      0.99      0.99      8765\n",
      "\n",
      "    accuracy                           0.98     10179\n",
      "   macro avg       0.97      0.97      0.97     10179\n",
      "weighted avg       0.98      0.98      0.98     10179\n",
      "\n",
      "Epoch: 2 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       163\n",
      "           1       0.99      0.99      0.99       967\n",
      "\n",
      "    accuracy                           0.98      1130\n",
      "   macro avg       0.95      0.95      0.95      1130\n",
      "weighted avg       0.98      0.98      0.98      1130\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\8\\model.dat at epoch: 2 and f1: 0.9855222337125129 #####\n",
      "\n",
      "Epoch: 3 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      1414\n",
      "           1       0.99      0.99      0.99      8765\n",
      "\n",
      "    accuracy                           0.99     10179\n",
      "   macro avg       0.98      0.97      0.97     10179\n",
      "weighted avg       0.99      0.99      0.99     10179\n",
      "\n",
      "Epoch: 3 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.91       163\n",
      "           1       0.98      0.99      0.99       967\n",
      "\n",
      "    accuracy                           0.98      1130\n",
      "   macro avg       0.97      0.93      0.95      1130\n",
      "weighted avg       0.98      0.98      0.98      1130\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\8\\model.dat at epoch: 3 and f1: 0.9861609431060996 #####\n",
      "\n",
      "Epoch: 4 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      1414\n",
      "           1       1.00      1.00      1.00      8765\n",
      "\n",
      "    accuracy                           0.99     10179\n",
      "   macro avg       0.98      0.99      0.99     10179\n",
      "weighted avg       0.99      0.99      0.99     10179\n",
      "\n",
      "Epoch: 4 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91       163\n",
      "           1       0.99      0.98      0.98       967\n",
      "\n",
      "    accuracy                           0.97      1130\n",
      "   macro avg       0.94      0.95      0.95      1130\n",
      "weighted avg       0.97      0.97      0.97      1130\n",
      "\n",
      "Epoch: 5 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      1414\n",
      "           1       1.00      1.00      1.00      8765\n",
      "\n",
      "    accuracy                           0.99     10179\n",
      "   macro avg       0.99      0.99      0.99     10179\n",
      "weighted avg       0.99      0.99      0.99     10179\n",
      "\n",
      "Epoch: 5 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       163\n",
      "           1       0.99      0.99      0.99       967\n",
      "\n",
      "    accuracy                           0.98      1130\n",
      "   macro avg       0.96      0.95      0.95      1130\n",
      "weighted avg       0.98      0.98      0.98      1130\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\8\\model.dat at epoch: 5 and f1: 0.9870934434692824 #####\n",
      "\n",
      "Epoch: 6 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      1414\n",
      "           1       1.00      1.00      1.00      8765\n",
      "\n",
      "    accuracy                           1.00     10179\n",
      "   macro avg       0.99      0.99      0.99     10179\n",
      "weighted avg       1.00      1.00      1.00     10179\n",
      "\n",
      "Epoch: 6 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91       163\n",
      "           1       0.99      0.98      0.98       967\n",
      "\n",
      "    accuracy                           0.97      1130\n",
      "   macro avg       0.94      0.95      0.95      1130\n",
      "weighted avg       0.97      0.97      0.97      1130\n",
      "\n",
      "Epoch: 7 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      1414\n",
      "           1       1.00      1.00      1.00      8765\n",
      "\n",
      "    accuracy                           1.00     10179\n",
      "   macro avg       0.99      0.99      0.99     10179\n",
      "weighted avg       1.00      1.00      1.00     10179\n",
      "\n",
      "Epoch: 7 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       163\n",
      "           1       0.99      0.98      0.98       967\n",
      "\n",
      "    accuracy                           0.97      1130\n",
      "   macro avg       0.94      0.95      0.95      1130\n",
      "weighted avg       0.97      0.97      0.97      1130\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      1414\n",
      "           1       1.00      1.00      1.00      8765\n",
      "\n",
      "    accuracy                           1.00     10179\n",
      "   macro avg       0.99      0.99      0.99     10179\n",
      "weighted avg       1.00      1.00      1.00     10179\n",
      "\n",
      "Epoch: 8 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.92       163\n",
      "           1       0.98      0.99      0.99       967\n",
      "\n",
      "    accuracy                           0.98      1130\n",
      "   macro avg       0.97      0.94      0.95      1130\n",
      "weighted avg       0.98      0.98      0.98      1130\n",
      "\n",
      "Epoch: 9 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1414\n",
      "           1       1.00      1.00      1.00      8765\n",
      "\n",
      "    accuracy                           1.00     10179\n",
      "   macro avg       0.99      0.99      0.99     10179\n",
      "weighted avg       1.00      1.00      1.00     10179\n",
      "\n",
      "Epoch: 9 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       163\n",
      "           1       0.99      0.97      0.98       967\n",
      "\n",
      "    accuracy                           0.97      1130\n",
      "   macro avg       0.92      0.95      0.93      1130\n",
      "weighted avg       0.97      0.97      0.97      1130\n",
      "\n",
      "Epoch: 0 **************************************************  Eval\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       183\n",
      "           1       0.98      0.99      0.99      1059\n",
      "\n",
      "    accuracy                           0.98      1242\n",
      "   macro avg       0.96      0.95      0.95      1242\n",
      "weighted avg       0.98      0.98      0.98      1242\n",
      "\n",
      "D:\\Repositories\\negation-detection\\data\\annotations_split\\train_annotations_9.json\n",
      "Epoch: 0 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.70      0.77      1416\n",
      "           1       0.95      0.98      0.97      8753\n",
      "\n",
      "    accuracy                           0.94     10169\n",
      "   macro avg       0.90      0.84      0.87     10169\n",
      "weighted avg       0.94      0.94      0.94     10169\n",
      "\n",
      "Epoch: 0 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.80      0.88       157\n",
      "           1       0.97      1.00      0.98       972\n",
      "\n",
      "    accuracy                           0.97      1129\n",
      "   macro avg       0.98      0.90      0.93      1129\n",
      "weighted avg       0.97      0.97      0.97      1129\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\9\\model.dat at epoch: 0 and f1: 0.9832742017232641 #####\n",
      "\n",
      "Epoch: 1 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      1416\n",
      "           1       0.98      0.99      0.99      8753\n",
      "\n",
      "    accuracy                           0.98     10169\n",
      "   macro avg       0.96      0.94      0.95     10169\n",
      "weighted avg       0.98      0.98      0.98     10169\n",
      "\n",
      "Epoch: 1 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91       157\n",
      "           1       0.98      0.99      0.99       972\n",
      "\n",
      "    accuracy                           0.98      1129\n",
      "   macro avg       0.97      0.93      0.95      1129\n",
      "weighted avg       0.98      0.98      0.98      1129\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\9\\model.dat at epoch: 1 and f1: 0.9867211440245147 #####\n",
      "\n",
      "Epoch: 2 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94      1416\n",
      "           1       0.99      0.99      0.99      8753\n",
      "\n",
      "    accuracy                           0.98     10169\n",
      "   macro avg       0.97      0.97      0.97     10169\n",
      "weighted avg       0.98      0.98      0.98     10169\n",
      "\n",
      "Epoch: 2 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86       157\n",
      "           1       0.98      0.97      0.98       972\n",
      "\n",
      "    accuracy                           0.96      1129\n",
      "   macro avg       0.90      0.94      0.92      1129\n",
      "weighted avg       0.96      0.96      0.96      1129\n",
      "\n",
      "Epoch: 3 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1416\n",
      "           1       0.99      0.99      0.99      8753\n",
      "\n",
      "    accuracy                           0.99     10169\n",
      "   macro avg       0.98      0.98      0.98     10169\n",
      "weighted avg       0.99      0.99      0.99     10169\n",
      "\n",
      "Epoch: 3 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88       157\n",
      "           1       0.99      0.97      0.98       972\n",
      "\n",
      "    accuracy                           0.96      1129\n",
      "   macro avg       0.91      0.95      0.93      1129\n",
      "weighted avg       0.97      0.96      0.96      1129\n",
      "\n",
      "Epoch: 4 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1416\n",
      "           1       0.99      1.00      0.99      8753\n",
      "\n",
      "    accuracy                           0.99     10169\n",
      "   macro avg       0.99      0.98      0.98     10169\n",
      "weighted avg       0.99      0.99      0.99     10169\n",
      "\n",
      "Epoch: 4 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.86       157\n",
      "           1       0.99      0.96      0.98       972\n",
      "\n",
      "    accuracy                           0.96      1129\n",
      "   macro avg       0.90      0.95      0.92      1129\n",
      "weighted avg       0.96      0.96      0.96      1129\n",
      "\n",
      "Epoch: 5 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      1416\n",
      "           1       1.00      1.00      1.00      8753\n",
      "\n",
      "    accuracy                           0.99     10169\n",
      "   macro avg       0.98      0.99      0.98     10169\n",
      "weighted avg       0.99      0.99      0.99     10169\n",
      "\n",
      "Epoch: 5 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.91       157\n",
      "           1       0.97      1.00      0.99       972\n",
      "\n",
      "    accuracy                           0.98      1129\n",
      "   macro avg       0.98      0.92      0.95      1129\n",
      "weighted avg       0.98      0.98      0.98      1129\n",
      "\n",
      "Epoch: 6 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1416\n",
      "           1       1.00      1.00      1.00      8753\n",
      "\n",
      "    accuracy                           0.99     10169\n",
      "   macro avg       0.99      0.99      0.99     10169\n",
      "weighted avg       0.99      0.99      0.99     10169\n",
      "\n",
      "Epoch: 6 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93       157\n",
      "           1       0.99      0.99      0.99       972\n",
      "\n",
      "    accuracy                           0.98      1129\n",
      "   macro avg       0.96      0.96      0.96      1129\n",
      "weighted avg       0.98      0.98      0.98      1129\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\9\\model.dat at epoch: 6 and f1: 0.9881748071979434 #####\n",
      "\n",
      "Epoch: 7 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      1416\n",
      "           1       1.00      1.00      1.00      8753\n",
      "\n",
      "    accuracy                           1.00     10169\n",
      "   macro avg       0.99      0.99      0.99     10169\n",
      "weighted avg       1.00      1.00      1.00     10169\n",
      "\n",
      "Epoch: 7 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93       157\n",
      "           1       0.98      1.00      0.99       972\n",
      "\n",
      "    accuracy                           0.98      1129\n",
      "   macro avg       0.98      0.94      0.96      1129\n",
      "weighted avg       0.98      0.98      0.98      1129\n",
      "\n",
      "\n",
      "##### Model saved to D:\\Repositories\\negation-detection\\models\\bilstm\\model_splits\\9\\model.dat at epoch: 7 and f1: 0.9887755102040816 #####\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      1416\n",
      "           1       1.00      1.00      1.00      8753\n",
      "\n",
      "    accuracy                           1.00     10169\n",
      "   macro avg       0.99      0.99      0.99     10169\n",
      "weighted avg       1.00      1.00      1.00     10169\n",
      "\n",
      "Epoch: 8 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87       157\n",
      "           1       0.98      0.97      0.98       972\n",
      "\n",
      "    accuracy                           0.96      1129\n",
      "   macro avg       0.91      0.94      0.93      1129\n",
      "weighted avg       0.97      0.96      0.96      1129\n",
      "\n",
      "Epoch: 9 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1416\n",
      "           1       1.00      1.00      1.00      8753\n",
      "\n",
      "    accuracy                           1.00     10169\n",
      "   macro avg       1.00      0.99      1.00     10169\n",
      "weighted avg       1.00      1.00      1.00     10169\n",
      "\n",
      "Epoch: 9 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91       157\n",
      "           1       0.98      0.99      0.99       972\n",
      "\n",
      "    accuracy                           0.98      1129\n",
      "   macro avg       0.97      0.93      0.95      1129\n",
      "weighted avg       0.98      0.98      0.98      1129\n",
      "\n",
      "Epoch: 0 **************************************************  Eval\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.86      0.90       187\n",
      "           1       0.98      0.99      0.98      1066\n",
      "\n",
      "    accuracy                           0.97      1253\n",
      "   macro avg       0.96      0.92      0.94      1253\n",
      "weighted avg       0.97      0.97      0.97      1253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List to store results of individual folds\n",
    "score_result_list = []\n",
    "\n",
    "for train_file in annotations_split_dir.rglob(\"train_annotations_*.json\"):\n",
    "    print(train_file)\n",
    "    split_id = train_file.stem.split('_')[2]\n",
    "    split_id_dir = models_split_dir / split_id\n",
    "    split_id_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Initiate MetaCAT\n",
    "    meta_cat = MetaCAT(tokenizer=tokenizer, embeddings=embeddings, config=config_metacat)\n",
    "    \n",
    "    # Train model\n",
    "    train_results = meta_cat.train(json_path=train_file, save_dir_path=str(split_id_dir))\n",
    "    \n",
    "    # Evaluate using MetaCAT's eval function\n",
    "    test_file = train_file.parent / train_file.name.replace('train_annotations_', 'test_annotations_')\n",
    "    test_results = meta_cat.eval(json_path=test_file)\n",
    "    \n",
    "    # Count positive and negatives\n",
    "    tp = 0\n",
    "    if 'negated' in test_results['examples']['TP']:\n",
    "        tp = len(test_results['examples']['TP']['negated'])\n",
    "    \n",
    "    fp = 0\n",
    "    if 'negated' in test_results['examples']['FP']:\n",
    "        tp = len(test_results['examples']['FP']['negated'])\n",
    "        \n",
    "    fn = 0\n",
    "    if 'negated' in test_results['examples']['FN']:\n",
    "        tp = len(test_results['examples']['FN']['negated'])\n",
    "    # Save test results\n",
    "    score_result_list.append([split_id,\n",
    "                              round(test_results['f1'], 2),\n",
    "                              round(test_results['precision'], 2),\n",
    "                              round(test_results['recall'], 2),\n",
    "                              tp,\n",
    "                              fp,\n",
    "                              fn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on folds\n",
    "Use this cell to test on the test data if the models are already created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 **************************************************  Eval\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90       189\n",
      "           1       0.98      0.99      0.98      1114\n",
      "\n",
      "    accuracy                           0.97      1303\n",
      "   macro avg       0.95      0.93      0.94      1303\n",
      "weighted avg       0.97      0.97      0.97      1303\n",
      "\n",
      "Epoch: 0 **************************************************  Eval\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       174\n",
      "           1       0.99      0.99      0.99      1099\n",
      "\n",
      "    accuracy                           0.98      1273\n",
      "   macro avg       0.95      0.96      0.95      1273\n",
      "weighted avg       0.98      0.98      0.98      1273\n",
      "\n",
      "Epoch: 0 **************************************************  Eval\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94       175\n",
      "           1       0.99      0.99      0.99       973\n",
      "\n",
      "    accuracy                           0.98      1148\n",
      "   macro avg       0.97      0.96      0.96      1148\n",
      "weighted avg       0.98      0.98      0.98      1148\n",
      "\n",
      "Epoch: 0 **************************************************  Eval\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.90       167\n",
      "           1       0.99      0.98      0.98      1088\n",
      "\n",
      "    accuracy                           0.97      1255\n",
      "   macro avg       0.93      0.95      0.94      1255\n",
      "weighted avg       0.97      0.97      0.97      1255\n",
      "\n",
      "Epoch: 0 **************************************************  Eval\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93       174\n",
      "           1       0.98      0.99      0.99      1124\n",
      "\n",
      "    accuracy                           0.98      1298\n",
      "   macro avg       0.97      0.95      0.96      1298\n",
      "weighted avg       0.98      0.98      0.98      1298\n",
      "\n",
      "Epoch: 0 **************************************************  Eval\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90       184\n",
      "           1       0.98      0.99      0.98      1131\n",
      "\n",
      "    accuracy                           0.97      1315\n",
      "   macro avg       0.96      0.92      0.94      1315\n",
      "weighted avg       0.97      0.97      0.97      1315\n",
      "\n",
      "Epoch: 0 **************************************************  Eval\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94       139\n",
      "           1       0.99      1.00      0.99      1053\n",
      "\n",
      "    accuracy                           0.99      1192\n",
      "   macro avg       0.99      0.95      0.97      1192\n",
      "weighted avg       0.99      0.99      0.99      1192\n",
      "\n",
      "Epoch: 0 **************************************************  Eval\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       188\n",
      "           1       0.99      0.97      0.98      1084\n",
      "\n",
      "    accuracy                           0.97      1272\n",
      "   macro avg       0.92      0.95      0.93      1272\n",
      "weighted avg       0.97      0.97      0.97      1272\n",
      "\n",
      "Epoch: 0 **************************************************  Eval\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       183\n",
      "           1       0.98      0.99      0.99      1059\n",
      "\n",
      "    accuracy                           0.98      1242\n",
      "   macro avg       0.96      0.95      0.95      1242\n",
      "weighted avg       0.98      0.98      0.98      1242\n",
      "\n",
      "Epoch: 0 **************************************************  Eval\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.86      0.90       187\n",
      "           1       0.98      0.99      0.98      1066\n",
      "\n",
      "    accuracy                           0.97      1253\n",
      "   macro avg       0.96      0.92      0.94      1253\n",
      "weighted avg       0.97      0.97      0.97      1253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List to store results of individual folds\n",
    "score_result_list = []\n",
    "\n",
    "for test_file in annotations_split_dir.rglob(\"test_annotations_*.json\"):\n",
    "    split_id = test_file.stem.split('_')[2]\n",
    "    split_id_dir = models_split_dir / split_id\n",
    "    \n",
    "    # Load biLSTM\n",
    "    meta_cat = MetaCAT.load(str(split_id_dir))\n",
    "    \n",
    "    # Evaluate using MetaCAT's eval function\n",
    "    test_results = meta_cat.eval(json_path=test_file)\n",
    "    \n",
    "    # Save test results\n",
    "    score_result_list.append([split_id,\n",
    "                              round(test_results['f1'], 2),\n",
    "                              round(test_results['precision'], 2),\n",
    "                              round(test_results['recall'], 2),\n",
    "                              len(test_results['examples']['TP']['negated']),\n",
    "                              len(test_results['examples']['FP']['negated']),\n",
    "                              len(test_results['examples']['FN']['negated'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather scores from folds\n",
    "In this section, results are gathered from the folds and saved in a single CSV.\n",
    "\n",
    "Currently, recall and precision are not returned by MetaCAT's eval() function. A future release will add this functionality (https://github.com/CogStack/MedCAT/pull/172)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split_id</th>\n",
       "      <th>weighted_f1</th>\n",
       "      <th>weighted_precision</th>\n",
       "      <th>weighted_recall</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>manual_recall</th>\n",
       "      <th>manual_precision</th>\n",
       "      <th>manual_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>165</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>161</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>161</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>154</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>156</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>158</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>173</td>\n",
       "      <td>29</td>\n",
       "      <td>15</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>167</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>160</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  split_id  weighted_f1  weighted_precision  weighted_recall   tp  fp  fn  \\\n",
       "0        0         0.98                0.98             0.99  165  13  24   \n",
       "1        1         0.99                0.99             0.99  161  15  13   \n",
       "2        2         0.99                0.99             0.99  161   8  14   \n",
       "3        3         0.98                0.99             0.98  154  23  13   \n",
       "4        4         0.99                0.98             0.99  156   7  18   \n",
       "5        5         0.98                0.98             0.99  158  10  26   \n",
       "6        6         0.99                0.99             1.00  125   2  14   \n",
       "7        7         0.98                0.99             0.97  173  29  15   \n",
       "8        8         0.99                0.98             0.99  167  13  16   \n",
       "9        9         0.98                0.98             0.99  160   8  27   \n",
       "\n",
       "   manual_recall  manual_precision  manual_f1  \n",
       "0           0.87              0.93       0.90  \n",
       "1           0.93              0.91       0.92  \n",
       "2           0.92              0.95       0.94  \n",
       "3           0.92              0.87       0.90  \n",
       "4           0.90              0.96       0.93  \n",
       "5           0.86              0.94       0.90  \n",
       "6           0.90              0.98       0.94  \n",
       "7           0.92              0.86       0.89  \n",
       "8           0.91              0.93       0.92  \n",
       "9           0.86              0.95       0.90  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_recall(row):\n",
    "    tp = row.tp\n",
    "    fp = row.fp\n",
    "    fn = row.fn\n",
    "    recall = round(tp / (tp + fn), 2)\n",
    "    return recall\n",
    "\n",
    "def calculate_precision(row):\n",
    "    tp = row.tp\n",
    "    fp = row.fp\n",
    "    fn = row.fn\n",
    "    precision = round(tp / (tp + fp), 2)\n",
    "    return precision\n",
    "\n",
    "def calculate_f1(row):\n",
    "    tp = row.tp\n",
    "    fp = row.fp\n",
    "    fn = row.fn\n",
    "    f1 = round((2*tp) / ((2*tp) + fp + fn), 2)\n",
    "    return f1\n",
    "\n",
    "score_results = pd.DataFrame(score_result_list, columns=['split_id', 'weighted_f1', 'weighted_precision', 'weighted_recall', 'tp', 'fp', 'fn'])\n",
    "score_results['manual_recall'] = score_results.apply(calculate_recall, axis=1)\n",
    "score_results['manual_precision'] = score_results.apply(calculate_precision, axis=1)\n",
    "score_results['manual_f1'] = score_results.apply(calculate_f1, axis=1)\n",
    "score_results.to_csv(score_result_file, index=False, compression='gzip')\n",
    "score_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom evaluation per example per fold\n",
    "In this project we are interested per example whether a negation has been correctly predicted or not. MetaCAT does not have such functionality; it only returns scores, predictions and examples.\n",
    "\n",
    "In this section we iterate through all annotations from an annotation file (MedCAT Trainer format), create an ID for every example (`exampleID = documentID_start_end`), collect the prediction per example and save all predictions in a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test set 0\n",
      "Evaluating test set 1\n",
      "Evaluating test set 2\n",
      "Evaluating test set 3\n",
      "Evaluating test set 4\n",
      "Evaluating test set 5\n",
      "Evaluating test set 6\n",
      "Evaluating test set 7\n",
      "Evaluating test set 8\n",
      "Evaluating test set 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_id</th>\n",
       "      <th>bilstm_cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DL1111_32_46</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DL1111_272_280</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DL1111_363_377</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DL1116_32_41</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DL1116_137_148</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12546</th>\n",
       "      <td>SP2100_201_212</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12547</th>\n",
       "      <td>SP2100_294_304</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12548</th>\n",
       "      <td>SP2107_87_92</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12549</th>\n",
       "      <td>SP2108_22_30</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12550</th>\n",
       "      <td>SP2108_57_64</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12551 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            entity_id    bilstm_cv\n",
       "0        DL1111_32_46  not negated\n",
       "1      DL1111_272_280  not negated\n",
       "2      DL1111_363_377  not negated\n",
       "3        DL1116_32_41  not negated\n",
       "4      DL1116_137_148  not negated\n",
       "...               ...          ...\n",
       "12546  SP2100_201_212  not negated\n",
       "12547  SP2100_294_304  not negated\n",
       "12548    SP2107_87_92  not negated\n",
       "12549    SP2108_22_30  not negated\n",
       "12550    SP2108_57_64  not negated\n",
       "\n",
       "[12551 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate models on their respective test sets\n",
    "predictions_on_test_list = []\n",
    "for annotation_filename in annotations_split_dir.rglob(\"test_annotations_*.json\"):\n",
    "    \n",
    "    # Extract split ID\n",
    "    split_id = annotation_filename.stem.split('_')[2]\n",
    "    split_id_dir = models_split_dir / split_id\n",
    "    print(f'Evaluating test set {split_id}')\n",
    "    \n",
    "    # Load MetaCAT model\n",
    "    meta_cat = MetaCAT.load(split_id_dir)\n",
    "    \n",
    "    # Gather the predictions on every example in the provided annotation file.\n",
    "    predictions_on_test_list.append(evaluate_per_example(annotation_filename, meta_cat, f'bilstm_cv'))\n",
    "    \n",
    "# Save al predictions in a single dataframe\n",
    "predictions_on_test_df = pd.DataFrame(columns=['entity_id', 'bilstm_cv'])\n",
    "for i in predictions_on_test_list:\n",
    "    predictions_on_test_df = predictions_on_test_df.append(i)\n",
    "\n",
    "# Save predictions in a csv\n",
    "predictions_on_test_df.reset_index(drop=True, inplace=True)\n",
    "predictions_on_test_df.to_csv(predictions_result_file, index=False, compression='gzip', line_terminator='\\n')\n",
    "predictions_on_test_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
