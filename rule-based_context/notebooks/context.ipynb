{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negation detection with ConText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.tokens import Span, Doc\n",
    "import medspacy\n",
    "from medspacy.visualization import visualize_dep\n",
    "from medspacy.context import ConTextRule, ConTextComponent\n",
    "from sklearn.metrics import classification_report\n",
    "# until bug is fixed in v6 of ipython kernel\n",
    "import warnings\n",
    "warnings.simplefilter('once')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recreate the spacy pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lcreteig/negation-detection/.venv/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(pathlib.Path('..','..','data','pipeline'))\n",
    "# Load the custom attributes set during labeling\n",
    "Doc.set_extension(\"data_type\", default=None)\n",
    "Doc.set_extension(\"doc_id\", default=None)\n",
    "Span.set_extension(\"entity_id\", default=None)\n",
    "Span.set_extension(\"negation\", default=\"NotNegated\")\n",
    "Span.set_extension(\"experiencer\", default=\"Patient\")\n",
    "Span.set_extension(\"temporality\", default=\"Recent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load texts, rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_file = pathlib.Path('..','..','data', 'DCC_docs.pickle')\n",
    "preproc_docs = pickle.loads(docs_file.read_bytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_file = pathlib.Path('..','configs','context','contextD_triggers.json') # all negation triggers in test set from ContextD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ConTextComponent(nlp, rules=\"other\", rule_list=str(context_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = pathlib.Path('..', '..', 'results', 'rule-based_predictions.csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "[example_doc] = [d for d in preproc_docs if d._.doc_id == 'DL1112']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Patient kan zich geen \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    trauma\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CONCEPT</span>\n",
       "</mark>\n",
       " herinneren.\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(example_doc, style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add ConText:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"d1eb400793494c00885f5eaee5bdc0d3-0\" class=\"displacy\" width=\"1450\" height=\"224.5\" direction=\"ltr\" style=\"max-width: none; height: 224.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Patient</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">kan</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">zich</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">geen</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">trauma</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">CONCEPT</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">herinneren</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">\n",
       "</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\"></tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d1eb400793494c00885f5eaee5bdc0d3-0-0\" stroke-width=\"2px\" d=\"M595,89.5 C595,2.0 750.0,2.0 750.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d1eb400793494c00885f5eaee5bdc0d3-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">NEGATED_EXISTENCE</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,91.5 L758.0,79.5 742.0,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run just the context component; visualize the result\n",
    "visualize_dep(context(example_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run \"ContextD on all docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 589 ms, sys: 70 Âµs, total: 589 ms\n",
      "Wall time: 587 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "docs = []\n",
    "for doc in preproc_docs:\n",
    "    docs.append(context(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table of all predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for d in docs:\n",
    "    for e in d.ents:\n",
    "        res.append({'entity_id': e._.entity_id,\n",
    "                    'annotation': 'negated' if e._.negation=='Negated' else 'not negated',\n",
    "                    'rule_based': 'negated' if e._.is_negated else 'not negated'})\n",
    "pd.DataFrame(res).to_csv(result_file, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trues = [True if e._.negation=='Negated' else False for d in docs for e in d.ents]\n",
    "preds = [e._.is_negated for d in docs for e in d.ents]\n",
    "target_names = ['not negated', 'negated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " not negated       0.98      0.97      0.98     10791\n",
      "     negated       0.82      0.89      0.86      1760\n",
      "\n",
      "    accuracy                           0.96     12551\n",
      "   macro avg       0.90      0.93      0.92     12551\n",
      "weighted avg       0.96      0.96      0.96     12551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(trues, preds, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Per document type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type: GP\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " not negated       0.97      0.95      0.96      3013\n",
      "     negated       0.67      0.80      0.73       383\n",
      "\n",
      "    accuracy                           0.93      3396\n",
      "   macro avg       0.82      0.88      0.85      3396\n",
      "weighted avg       0.94      0.93      0.94      3396\n",
      "\n",
      "Data type: SP\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " not negated       0.97      0.96      0.97      2273\n",
      "     negated       0.81      0.84      0.82       403\n",
      "\n",
      "    accuracy                           0.95      2676\n",
      "   macro avg       0.89      0.90      0.89      2676\n",
      "weighted avg       0.95      0.95      0.95      2676\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lcreteig/negation-detection/.venv/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type: RD\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " not negated       0.99      0.98      0.99      3088\n",
      "     negated       0.90      0.97      0.93       595\n",
      "\n",
      "    accuracy                           0.98      3683\n",
      "   macro avg       0.95      0.97      0.96      3683\n",
      "weighted avg       0.98      0.98      0.98      3683\n",
      "\n",
      "Data type: DL\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " not negated       0.99      0.98      0.99      2417\n",
      "     negated       0.89      0.92      0.91       379\n",
      "\n",
      "    accuracy                           0.97      2796\n",
      "   macro avg       0.94      0.95      0.95      2796\n",
      "weighted avg       0.97      0.97      0.97      2796\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_types = ['GP', 'SP', 'RD', 'DL']\n",
    "for dt in data_types:\n",
    "    trues = [True if e._.negation=='Negated' else False for d in docs if d._.data_type==dt for e in d.ents]\n",
    "    preds = [e._.is_negated for d in docs if d._.data_type==dt for e in d.ents]\n",
    "    print(f\"Data type: {dt}\")\n",
    "    print(classification_report(trues, preds, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to paper: https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-014-0373-3/tables/5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **GP**: \n",
    "    - Precision and recall much worse than in paper. Probably because we haven't added the GP-specific tweaks for the rules yet?\n",
    "    - Also here recall is higher than precision; other way around in paper (for baseline)\n",
    "- **SP**: Performance pretty similar (couple points worse)\n",
    "- **RD**: Performance almost exactly the same as in paper (for final)\n",
    "- **DL**: Performance pretty similar (bit worse)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
