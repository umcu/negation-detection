{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MetaCAT - BiLSTM for negations of Dutch Clinical Corpus\n",
    "\n",
    "Based on https://colab.research.google.com/drive/1rxzBZCTDcqsIjRXZ3u4yRZFOkUCCuwyy#scrollTo=dukwUnN1TPCg\n",
    "and https://colab.research.google.com/drive/1zzV3XzFJ9ihhCJ680DaQV2QZ5XnHa06X#scrollTo=Sj29auXV8iPZ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/myrthehemker/.conda/envs/AML_2/lib/python3.7/site-packages/medcat/cat.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from medcat.cat import CAT\n",
    "from medcat.vocab import Vocab\n",
    "from medcat.cdb import CDB\n",
    "from medcat.config import Config\n",
    "from medcat.meta_cat import MetaCAT\n",
    "from medcat.preprocessing.tokenizers import TokenizerWrapperBPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data/'\n",
    "DATA_DIR_PRIVATE = \"/Users/myrthehemker/Data/EMC_Corpus/jsonfiles/\"\n",
    "cdb_file = DATA_DIR+ 'cdb.dat'\n",
    "vocab_file = DATA_DIR+ 'vocab.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_DL = DATA_DIR_PRIVATE + \"emc-dcc_ann_DL.json\"\n",
    "json_file_GP = DATA_DIR_PRIVATE + \"emc-dcc_ann_GP.json\"\n",
    "json_file_RD = DATA_DIR_PRIVATE + \"emc-dcc_ann_RD.json\"\n",
    "json_file_SP = DATA_DIR_PRIVATE + \"emc-dcc_ann_SP.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cdb and vocab \n",
    "config = Config()\n",
    "config.general['spacy_model'] = 'nl_core_news_sm'\n",
    "\n",
    "vocab = Vocab.load(vocab_file)\n",
    "cdb = CDB.load(cdb_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MedCAT pipeline\n",
    "cat = CAT(cdb=cdb, vocab=vocab, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/output/emc_dcc-vocab.json', 'data/output/emc_dcc-merges.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create, train and save the tokenizer\n",
    "\n",
    "tokenizer = ByteLevelBPETokenizer()\n",
    "tokenizer.train(DATA_DIR + \"data.txt\")\n",
    "tokenizer.save_model(\"data/output/\", 'emc_dcc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now we tokenize all the text we have and train word2vec\n",
    "f = open(DATA_DIR + \"data.txt\", 'r')\n",
    "# Note that if you have a very large dataset, use iterators that\n",
    "#read the text line by line from the file, do not load the whole file\n",
    "#into memory.\n",
    "data = []\n",
    "for line in f:\n",
    "    data.append(tokenizer.encode(line).tokens)\n",
    "w2v = Word2Vec(data, size=300, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/myrthehemker/.conda/envs/AML_2/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Ġkortademigheid', 0.9139964580535889),\n",
       " ('Ġjeuk', 0.8930736780166626),\n",
       " ('Ġdiarree', 0.8803220987319946),\n",
       " ('Ġbraken', 0.880200982093811),\n",
       " ('Ġmisselijkheid', 0.8777583837509155),\n",
       " ('Ġniezen', 0.8665359020233154),\n",
       " ('Ġbuikpijn', 0.8609310388565063),\n",
       " ('Ġspierpijn', 0.8597644567489624),\n",
       " ('Ġvermoeidheid', 0.859038233757019),\n",
       " ('Ġademhalingsproblemen', 0.8583375215530396)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check is word2vec trained, Ġ - for this tokenizer denotes start of word (a space)\n",
    "w2v.most_similar('Ġhoesten')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we just have to create the embeddings matrix\n",
    "embeddings = []\n",
    "for i in range(tokenizer.get_vocab_size()):\n",
    "    word = tokenizer.id_to_token(i)\n",
    "    if word in w2v.wv:\n",
    "        embeddings.append(w2v.wv[word])\n",
    "    else:\n",
    "    # Assign a random vector if the word was not frequent enough to receive\n",
    "    #an embedding\n",
    "        embeddings.append(np.random.rand(300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the embeddings\n",
    "np.save(open(DATA_DIR + \"embeddings.npy\", 'wb'), np.array(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['projects'])\n",
      "dict_keys(['id', 'user', 'cui', 'value', 'start', 'end', 'validated', 'correct', 'deleted', 'alternative', 'killed', 'meta_anns'])\n"
     ]
    }
   ],
   "source": [
    "json_file_all = DATA_DIR_PRIVATE + 'emc-dcc_ann.json'\n",
    "data = json.load(open(json_file_all))\n",
    "print(data.keys())\n",
    "print(data['projects'][0]['documents'][0]['annotations'][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the required tokenizer (note that we have already downloaded the required models)\n",
    "tokenizer = TokenizerWrapperBPE(ByteLevelBPETokenizer(vocab= \"data/output/\" + \"emc_dcc-vocab.json\", merges=\"data/output/\" + \"emc_dcc-merges.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate different datatypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Project', max=1.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Document', max=4830.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The provided entity for cui <7> was empty, nothing to train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({}, {}, {}, {}, {}, {}, {}, {})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train MedCAT model on the annotated concepts\n",
    "cat.train_supervised(data_path=json_file_all, \n",
    "                     nepochs=1,\n",
    "                     reset_cui_count=False,\n",
    "                     print_stats=False,\n",
    "                     test_size = 0.1,\n",
    "                     use_filters=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.70      0.78      1591\n",
      "           1       0.95      0.98      0.97      9758\n",
      "\n",
      "    accuracy                           0.94     11349\n",
      "   macro avg       0.91      0.84      0.87     11349\n",
      "weighted avg       0.94      0.94      0.94     11349\n",
      "\n",
      "Epoch: 0 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.75      0.82       182\n",
      "           1       0.96      0.99      0.97      1080\n",
      "\n",
      "    accuracy                           0.95      1262\n",
      "   macro avg       0.94      0.87      0.90      1262\n",
      "weighted avg       0.95      0.95      0.95      1262\n",
      "\n",
      "Train Loss: 0.19262081954274063\n",
      "Test Loss:  0.169737848744262\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 0 and f1: 0.9512700672229851\n",
      "[[ 136   46]\n",
      " [  13 1067]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 1 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.77      0.84      1591\n",
      "           1       0.96      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.96     11349\n",
      "   macro avg       0.94      0.88      0.91     11349\n",
      "weighted avg       0.96      0.96      0.96     11349\n",
      "\n",
      "Epoch: 1 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.77      0.83       182\n",
      "           1       0.96      0.98      0.97      1080\n",
      "\n",
      "    accuracy                           0.95      1262\n",
      "   macro avg       0.93      0.88      0.90      1262\n",
      "weighted avg       0.95      0.95      0.95      1262\n",
      "\n",
      "Train Loss: 0.15385192067486983\n",
      "Test Loss:  0.16513859608676285\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 1 and f1: 0.9517924028367117\n",
      "[[ 140   42]\n",
      " [  17 1063]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 2 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.79      0.85      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.96     11349\n",
      "   macro avg       0.95      0.89      0.92     11349\n",
      "weighted avg       0.96      0.96      0.96     11349\n",
      "\n",
      "Epoch: 2 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.77      0.82       182\n",
      "           1       0.96      0.98      0.97      1080\n",
      "\n",
      "    accuracy                           0.95      1262\n",
      "   macro avg       0.92      0.88      0.90      1262\n",
      "weighted avg       0.95      0.95      0.95      1262\n",
      "\n",
      "Train Loss: 0.14451274270532835\n",
      "Test Loss:  0.17691067914711311\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 3 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.85      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.96     11349\n",
      "   macro avg       0.94      0.89      0.92     11349\n",
      "weighted avg       0.96      0.96      0.96     11349\n",
      "\n",
      "Epoch: 3 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.77      0.82       182\n",
      "           1       0.96      0.98      0.97      1080\n",
      "\n",
      "    accuracy                           0.95      1262\n",
      "   macro avg       0.92      0.88      0.90      1262\n",
      "weighted avg       0.95      0.95      0.95      1262\n",
      "\n",
      "Train Loss: 0.14181042633275173\n",
      "Test Loss:  0.17458244849694893\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 4 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.80      0.86      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.96     11349\n",
      "   macro avg       0.95      0.89      0.92     11349\n",
      "weighted avg       0.96      0.96      0.96     11349\n",
      "\n",
      "Epoch: 4 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.73      0.82       182\n",
      "           1       0.96      0.99      0.97      1080\n",
      "\n",
      "    accuracy                           0.95      1262\n",
      "   macro avg       0.95      0.86      0.90      1262\n",
      "weighted avg       0.95      0.95      0.95      1262\n",
      "\n",
      "Train Loss: 0.13516524790550097\n",
      "Test Loss:  0.1683389662357513\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 4 and f1: 0.9523876766948354\n",
      "[[ 133   49]\n",
      " [   8 1072]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 5 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.80      0.86      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.96     11349\n",
      "   macro avg       0.95      0.89      0.92     11349\n",
      "weighted avg       0.96      0.96      0.96     11349\n",
      "\n",
      "Epoch: 5 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85       182\n",
      "           1       0.96      0.99      0.98      1080\n",
      "\n",
      "    accuracy                           0.96      1262\n",
      "   macro avg       0.94      0.89      0.91      1262\n",
      "weighted avg       0.96      0.96      0.96      1262\n",
      "\n",
      "Train Loss: 0.13846577933012233\n",
      "Test Loss:  0.15931972148246132\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 5 and f1: 0.957455816657798\n",
      "[[ 143   39]\n",
      " [  13 1067]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 6 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.86      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.96     11349\n",
      "   macro avg       0.95      0.90      0.92     11349\n",
      "weighted avg       0.96      0.96      0.96     11349\n",
      "\n",
      "Epoch: 6 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.78      0.84       182\n",
      "           1       0.96      0.99      0.98      1080\n",
      "\n",
      "    accuracy                           0.96      1262\n",
      "   macro avg       0.94      0.88      0.91      1262\n",
      "weighted avg       0.96      0.96      0.96      1262\n",
      "\n",
      "Train Loss: 0.12882674177518297\n",
      "Test Loss:  0.14272059910581447\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 7 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.97     11349\n",
      "   macro avg       0.95      0.90      0.93     11349\n",
      "weighted avg       0.97      0.97      0.97     11349\n",
      "\n",
      "Epoch: 7 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.77      0.84       182\n",
      "           1       0.96      0.99      0.97      1080\n",
      "\n",
      "    accuracy                           0.96      1262\n",
      "   macro avg       0.94      0.88      0.91      1262\n",
      "weighted avg       0.96      0.96      0.95      1262\n",
      "\n",
      "Train Loss: 0.12093686101003878\n",
      "Test Loss:  0.15111823263578117\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 8 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.87      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.96     11349\n",
      "   macro avg       0.95      0.90      0.92     11349\n",
      "weighted avg       0.96      0.96      0.96     11349\n",
      "\n",
      "Epoch: 8 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.75      0.82       182\n",
      "           1       0.96      0.99      0.97      1080\n",
      "\n",
      "    accuracy                           0.95      1262\n",
      "   macro avg       0.93      0.87      0.90      1262\n",
      "weighted avg       0.95      0.95      0.95      1262\n",
      "\n",
      "Train Loss: 0.1196152794717575\n",
      "Test Loss:  0.1645763572305441\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.97     11349\n",
      "   macro avg       0.95      0.90      0.93     11349\n",
      "weighted avg       0.97      0.97      0.96     11349\n",
      "\n",
      "Epoch: 9 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.75      0.83       182\n",
      "           1       0.96      0.99      0.97      1080\n",
      "\n",
      "    accuracy                           0.96      1262\n",
      "   macro avg       0.95      0.87      0.90      1262\n",
      "weighted avg       0.96      0.96      0.95      1262\n",
      "\n",
      "Train Loss: 0.1206846370707712\n",
      "Test Loss:  0.1555123495636508\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Best/Average scores: F1: 0.957455816657798, P: 0.9578051907236043, R: 0.9587955625990491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.957455816657798,\n",
       " 'p': 0.9578051907236043,\n",
       " 'r': 0.9587955625990491,\n",
       " 'cls_report': {'0': {'precision': 0.9166666666666666,\n",
       "   'recall': 0.7857142857142857,\n",
       "   'f1-score': 0.8461538461538461,\n",
       "   'support': 182},\n",
       "  '1': {'precision': 0.9647377938517179,\n",
       "   'recall': 0.9879629629629629,\n",
       "   'f1-score': 0.9762122598353157,\n",
       "   'support': 1080},\n",
       "  'accuracy': 0.9587955625990491,\n",
       "  'macro avg': {'precision': 0.9407022302591923,\n",
       "   'recall': 0.8868386243386244,\n",
       "   'f1-score': 0.9111830529945809,\n",
       "   'support': 1262},\n",
       "  'weighted avg': {'precision': 0.9578051907236043,\n",
       "   'recall': 0.9587955625990491,\n",
       "   'f1-score': 0.957455816657798,\n",
       "   'support': 1262}}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and evaluate MetaCAT on all negations of the EMC DCC dataset\n",
    "mc_negation = MetaCAT(tokenizer=tokenizer, embeddings=embeddings, pad_id=len(embeddings) -1, save_dir='data/output/mc_negation_all', device='cpu')\n",
    "mc_negation.train(json_file_all, 'Negation', nepochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Radiology letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Project', max=1.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Document', max=1340.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.78       539\n",
      "           1       0.96      0.96      0.96      2775\n",
      "\n",
      "    accuracy                           0.93      3314\n",
      "   macro avg       0.88      0.87      0.87      3314\n",
      "weighted avg       0.93      0.93      0.93      3314\n",
      "\n",
      "Epoch: 0 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89        56\n",
      "           1       0.97      0.99      0.98       313\n",
      "\n",
      "    accuracy                           0.97       369\n",
      "   macro avg       0.95      0.92      0.93       369\n",
      "weighted avg       0.97      0.97      0.97       369\n",
      "\n",
      "Train Loss: 0.19597539066684894\n",
      "Test Loss:  0.27506222212687137\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 0 and f1: 0.9669806856798727\n",
      "[[ 48   8]\n",
      " [  4 309]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 1 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90       539\n",
      "           1       0.97      0.99      0.98      2775\n",
      "\n",
      "    accuracy                           0.97      3314\n",
      "   macro avg       0.95      0.93      0.94      3314\n",
      "weighted avg       0.97      0.97      0.97      3314\n",
      "\n",
      "Epoch: 1 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.79      0.87        56\n",
      "           1       0.96      1.00      0.98       313\n",
      "\n",
      "    accuracy                           0.96       369\n",
      "   macro avg       0.97      0.89      0.93       369\n",
      "weighted avg       0.97      0.96      0.96       369\n",
      "\n",
      "Train Loss: 0.11452372417033437\n",
      "Test Loss:  0.2793078252580017\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 2 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92       539\n",
      "           1       0.98      0.99      0.98      2775\n",
      "\n",
      "    accuracy                           0.97      3314\n",
      "   macro avg       0.96      0.94      0.95      3314\n",
      "weighted avg       0.97      0.97      0.97      3314\n",
      "\n",
      "Epoch: 2 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.82      0.88        56\n",
      "           1       0.97      0.99      0.98       313\n",
      "\n",
      "    accuracy                           0.97       369\n",
      "   macro avg       0.96      0.91      0.93       369\n",
      "weighted avg       0.97      0.97      0.97       369\n",
      "\n",
      "Train Loss: 0.09361708664941232\n",
      "Test Loss:  0.27496132122469136\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 3 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93       539\n",
      "           1       0.98      0.99      0.99      2775\n",
      "\n",
      "    accuracy                           0.98      3314\n",
      "   macro avg       0.97      0.95      0.96      3314\n",
      "weighted avg       0.98      0.98      0.98      3314\n",
      "\n",
      "Epoch: 3 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87        56\n",
      "           1       0.97      0.99      0.98       313\n",
      "\n",
      "    accuracy                           0.96       369\n",
      "   macro avg       0.94      0.90      0.92       369\n",
      "weighted avg       0.96      0.96      0.96       369\n",
      "\n",
      "Train Loss: 0.08145468528326376\n",
      "Test Loss:  0.2637672819662839\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 4 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93       539\n",
      "           1       0.98      0.99      0.99      2775\n",
      "\n",
      "    accuracy                           0.98      3314\n",
      "   macro avg       0.97      0.95      0.96      3314\n",
      "weighted avg       0.98      0.98      0.98      3314\n",
      "\n",
      "Epoch: 4 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.84      0.89        56\n",
      "           1       0.97      0.99      0.98       313\n",
      "\n",
      "    accuracy                           0.97       369\n",
      "   macro avg       0.96      0.91      0.93       369\n",
      "weighted avg       0.97      0.97      0.97       369\n",
      "\n",
      "Train Loss: 0.08080452755346042\n",
      "Test Loss:  0.2468440731288865\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 5 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       539\n",
      "           1       0.99      0.99      0.99      2775\n",
      "\n",
      "    accuracy                           0.98      3314\n",
      "   macro avg       0.97      0.96      0.96      3314\n",
      "weighted avg       0.98      0.98      0.98      3314\n",
      "\n",
      "Epoch: 5 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.82      0.89        56\n",
      "           1       0.97      1.00      0.98       313\n",
      "\n",
      "    accuracy                           0.97       369\n",
      "   macro avg       0.97      0.91      0.94       369\n",
      "weighted avg       0.97      0.97      0.97       369\n",
      "\n",
      "Train Loss: 0.07146387514574117\n",
      "Test Loss:  0.26073871690314265\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 5 and f1: 0.9690985643133705\n",
      "[[ 46  10]\n",
      " [  1 312]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 6 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93       539\n",
      "           1       0.98      0.99      0.99      2775\n",
      "\n",
      "    accuracy                           0.98      3314\n",
      "   macro avg       0.97      0.95      0.96      3314\n",
      "weighted avg       0.98      0.98      0.98      3314\n",
      "\n",
      "Epoch: 6 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.82      0.89        56\n",
      "           1       0.97      1.00      0.98       313\n",
      "\n",
      "    accuracy                           0.97       369\n",
      "   macro avg       0.97      0.91      0.94       369\n",
      "weighted avg       0.97      0.97      0.97       369\n",
      "\n",
      "Train Loss: 0.07084324482214042\n",
      "Test Loss:  0.2459624167648144\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 7 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       539\n",
      "           1       0.99      1.00      0.99      2775\n",
      "\n",
      "    accuracy                           0.99      3314\n",
      "   macro avg       0.98      0.97      0.97      3314\n",
      "weighted avg       0.99      0.99      0.99      3314\n",
      "\n",
      "Epoch: 7 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.90        56\n",
      "           1       0.97      0.99      0.98       313\n",
      "\n",
      "    accuracy                           0.97       369\n",
      "   macro avg       0.97      0.92      0.94       369\n",
      "weighted avg       0.97      0.97      0.97       369\n",
      "\n",
      "Train Loss: 0.05117749729956758\n",
      "Test Loss:  0.22780855940654873\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 7 and f1: 0.9693608531661936\n",
      "[[ 47   9]\n",
      " [  2 311]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 8 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       539\n",
      "           1       0.99      0.99      0.99      2775\n",
      "\n",
      "    accuracy                           0.98      3314\n",
      "   macro avg       0.98      0.96      0.97      3314\n",
      "weighted avg       0.98      0.98      0.98      3314\n",
      "\n",
      "Epoch: 8 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.82      0.89        56\n",
      "           1       0.97      1.00      0.98       313\n",
      "\n",
      "    accuracy                           0.97       369\n",
      "   macro avg       0.97      0.91      0.94       369\n",
      "weighted avg       0.97      0.97      0.97       369\n",
      "\n",
      "Train Loss: 0.06255422444370329\n",
      "Test Loss:  0.3372220843075411\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 9 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       539\n",
      "           1       0.99      0.99      0.99      2775\n",
      "\n",
      "    accuracy                           0.99      3314\n",
      "   macro avg       0.98      0.97      0.98      3314\n",
      "weighted avg       0.99      0.99      0.99      3314\n",
      "\n",
      "Epoch: 9 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87        56\n",
      "           1       0.97      0.99      0.98       313\n",
      "\n",
      "    accuracy                           0.96       369\n",
      "   macro avg       0.94      0.90      0.92       369\n",
      "weighted avg       0.96      0.96      0.96       369\n",
      "\n",
      "Train Loss: 0.042771662396087075\n",
      "Test Loss:  0.36901109730824827\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Best/Average scores: F1: 0.9693608531661936, P: 0.9699489450251646, R: 0.9701897018970189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.9693608531661936,\n",
       " 'p': 0.9699489450251646,\n",
       " 'r': 0.9701897018970189,\n",
       " 'cls_report': {'0': {'precision': 0.9591836734693877,\n",
       "   'recall': 0.8392857142857143,\n",
       "   'f1-score': 0.8952380952380952,\n",
       "   'support': 56},\n",
       "  '1': {'precision': 0.971875,\n",
       "   'recall': 0.9936102236421726,\n",
       "   'f1-score': 0.9826224328593998,\n",
       "   'support': 313},\n",
       "  'accuracy': 0.9701897018970189,\n",
       "  'macro avg': {'precision': 0.9655293367346939,\n",
       "   'recall': 0.9164479689639434,\n",
       "   'f1-score': 0.9389302640487475,\n",
       "   'support': 369},\n",
       "  'weighted avg': {'precision': 0.9699489450251646,\n",
       "   'recall': 0.9701897018970189,\n",
       "   'f1-score': 0.9693608531661936,\n",
       "   'support': 369}}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create MedCAT trained only on radiology letters\n",
    "cat_RD = CAT(cdb=cdb, vocab=vocab, config=config)\n",
    "cat_RD.train_supervised(data_path=json_file_RD, \n",
    "                     nepochs=1,\n",
    "                     reset_cui_count=False,\n",
    "                     print_stats=False, \n",
    "                     test_size = 0.1,\n",
    "                     use_filters=True) \n",
    "\n",
    "# train and evaluate MetaCAT on radiology letters\n",
    "mc_negation_RD = MetaCAT(tokenizer=tokenizer, embeddings=embeddings, pad_id=len(embeddings) -1, save_dir='data/output/mc_negation_RD', device='cpu')\n",
    "mc_negation_RD.train(json_file_RD, 'Negation', nepochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specialist letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Stats project', max=1.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Stats document', max=97.0, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Prec: 0.012698412698412698, Rec: 0.029304029304029304, F1: 0.017718715393133997\n",
      "\n",
      "Docs with false positives: SP1618; SP1648; SP1175; SP1243; SP1830; SP1180; SP1476; SP2092; SP1219; SP1746\n",
      "\n",
      "Docs with false negatives: SP1618; SP1648; SP1175; SP1243; SP1830; SP1180; SP1476; SP2092; SP1219; SP1746\n",
      "\n",
      "\n",
      "\n",
      "False Positives\n",
      "\n",
      "blauw~naevus                                                           - 5                    -         28\n",
      "albuminurie                                                            - 6                    -         28\n",
      "misselijkheid                                                          - 7                    -         28\n",
      "acute~diarree                                                          - 13                   -         20\n",
      "klacht                                                                 - C0277786             -         20\n",
      "zwelling                                                               - 3                    -         20\n",
      "congenitale~leverfibrose                                               - 4                    -         18\n",
      "pijn~in~de~nek                                                         - 12                   -         17\n",
      "misselijkheid                                                          - 14                   -         16\n",
      "schouder~symptoom~klacht                                               - 10                   -         16\n",
      "\n",
      "\n",
      "False Negatives\n",
      "\n",
      "congenitaal~megacolon                                                  - 18                   -         17\n",
      "schouder~symptoom~klacht                                               - 10                   -         14\n",
      "darmbloeding                                                           - 24                   -         13\n",
      "lacunair~infarct                                                       - 30                   -         13\n",
      "congenitaal~megacolon                                                  - 29                   -         11\n",
      "blauw~naevus                                                           - 5                    -         11\n",
      "vergroten~prostaat                                                     - 21                   -         11\n",
      "chirurgisch~ingreep                                                    - 8                    -         11\n",
      "diabetes                                                               - 26                   -         10\n",
      "avulsiefractuur                                                        - 28                   -         10\n",
      "\n",
      "\n",
      "True Positives\n",
      "\n",
      "pijn~in~de~nek                                                         - 12                   -          3\n",
      "bursitis~trochanterica                                                 - 11                   -          2\n",
      "zwelling                                                               - 3                    -          1\n",
      "congenitale~leverfibrose                                               - 4                    -          1\n",
      "albuminurie                                                            - 6                    -          1\n",
      "**************************************************************************************************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Project', max=1.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Document', max=892.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Stats project', max=1.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Stats document', max=97.0, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Prec: 0.01904761904761905, Rec: 0.04395604395604396, F1: 0.026578073089701\n",
      "\n",
      "Docs with false positives: SP1618; SP1648; SP1175; SP1243; SP1830; SP1180; SP1476; SP2092; SP1219; SP1746\n",
      "\n",
      "Docs with false negatives: SP1618; SP1648; SP1175; SP1243; SP1830; SP1180; SP1476; SP2092; SP1219; SP1746\n",
      "\n",
      "\n",
      "\n",
      "False Positives\n",
      "\n",
      "blauw~naevus                                                           - 5                    -         30\n",
      "misselijkheid                                                          - 7                    -         26\n",
      "albuminurie                                                            - 6                    -         25\n",
      "acute~diarree                                                          - 13                   -         20\n",
      "klacht                                                                 - C0277786             -         20\n",
      "zwelling                                                               - 3                    -         19\n",
      "pijn~in~de~nek                                                         - 12                   -         18\n",
      "congenitale~leverfibrose                                               - 4                    -         17\n",
      "schouder~symptoom~klacht                                               - 10                   -         17\n",
      "misselijkheid                                                          - 14                   -         16\n",
      "\n",
      "\n",
      "False Negatives\n",
      "\n",
      "congenitaal~megacolon                                                  - 18                   -         17\n",
      "schouder~symptoom~klacht                                               - 10                   -         14\n",
      "darmbloeding                                                           - 24                   -         13\n",
      "artritis                                                               - 30                   -         13\n",
      "artritis                                                               - 29                   -         11\n",
      "migraine                                                               - 21                   -         11\n",
      "chirurgisch~ingreep                                                    - 8                    -         11\n",
      "hoest                                                                  - 26                   -         10\n",
      "poliep                                                                 - 28                   -         10\n",
      "psoriasis~vulgaris                                                     - 19                   -         10\n",
      "\n",
      "\n",
      "True Positives\n",
      "\n",
      "pijn~in~de~nek                                                         - 12                   -          3\n",
      "darmbloeding                                                           - 11                   -          2\n",
      "albuminurie                                                            - 6                    -          2\n",
      "blauw~naevus                                                           - 5                    -          2\n",
      "zwelling                                                               - 3                    -          1\n",
      "acute~diarree                                                          - 13                   -          1\n",
      "congenitale~leverfibrose                                               - 4                    -          1\n",
      "**************************************************************************************************************\n",
      "\n",
      "Epoch: 0 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.61      0.64       391\n",
      "           1       0.93      0.95      0.94      2061\n",
      "\n",
      "    accuracy                           0.89      2452\n",
      "   macro avg       0.80      0.78      0.79      2452\n",
      "weighted avg       0.89      0.89      0.89      2452\n",
      "\n",
      "Epoch: 0 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.68      0.71        25\n",
      "           1       0.97      0.98      0.97       248\n",
      "\n",
      "    accuracy                           0.95       273\n",
      "   macro avg       0.85      0.83      0.84       273\n",
      "weighted avg       0.95      0.95      0.95       273\n",
      "\n",
      "Train Loss: 0.29349211609411624\n",
      "Test Loss:  0.1811635914657797\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 0 and f1: 0.9477525486561631\n",
      "[[ 17   8]\n",
      " [  6 242]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 1 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.68      0.76       391\n",
      "           1       0.94      0.98      0.96      2061\n",
      "\n",
      "    accuracy                           0.93      2452\n",
      "   macro avg       0.90      0.83      0.86      2452\n",
      "weighted avg       0.93      0.93      0.93      2452\n",
      "\n",
      "Epoch: 1 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.78        25\n",
      "           1       0.98      0.98      0.98       248\n",
      "\n",
      "    accuracy                           0.96       273\n",
      "   macro avg       0.88      0.87      0.88       273\n",
      "weighted avg       0.96      0.96      0.96       273\n",
      "\n",
      "Train Loss: 0.23017558818983455\n",
      "Test Loss:  0.1706851880465235\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 1 and f1: 0.9593363424924218\n",
      "[[ 19   6]\n",
      " [  5 243]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 2 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.74      0.81       391\n",
      "           1       0.95      0.98      0.97      2061\n",
      "\n",
      "    accuracy                           0.94      2452\n",
      "   macro avg       0.92      0.86      0.89      2452\n",
      "weighted avg       0.94      0.94      0.94      2452\n",
      "\n",
      "Epoch: 2 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77        25\n",
      "           1       0.98      0.97      0.98       248\n",
      "\n",
      "    accuracy                           0.96       273\n",
      "   macro avg       0.86      0.89      0.87       273\n",
      "weighted avg       0.96      0.96      0.96       273\n",
      "\n",
      "Train Loss: 0.19338506991944968\n",
      "Test Loss:  0.15117867876376426\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 3 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.77      0.83       391\n",
      "           1       0.96      0.98      0.97      2061\n",
      "\n",
      "    accuracy                           0.95      2452\n",
      "   macro avg       0.92      0.88      0.90      2452\n",
      "weighted avg       0.95      0.95      0.95      2452\n",
      "\n",
      "Epoch: 3 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.84      0.79        25\n",
      "           1       0.98      0.97      0.98       248\n",
      "\n",
      "    accuracy                           0.96       273\n",
      "   macro avg       0.87      0.91      0.89       273\n",
      "weighted avg       0.96      0.96      0.96       273\n",
      "\n",
      "Train Loss: 0.1657937231038006\n",
      "Test Loss:  0.18364250021321432\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 3 and f1: 0.960724733314576\n",
      "[[ 21   4]\n",
      " [  7 241]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 4 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.78      0.83       391\n",
      "           1       0.96      0.98      0.97      2061\n",
      "\n",
      "    accuracy                           0.95      2452\n",
      "   macro avg       0.93      0.88      0.90      2452\n",
      "weighted avg       0.95      0.95      0.95      2452\n",
      "\n",
      "Epoch: 4 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84        25\n",
      "           1       0.98      0.98      0.98       248\n",
      "\n",
      "    accuracy                           0.97       273\n",
      "   macro avg       0.91      0.91      0.91       273\n",
      "weighted avg       0.97      0.97      0.97       273\n",
      "\n",
      "Train Loss: 0.1698958938640933\n",
      "Test Loss:  0.13340569580239908\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 4 and f1: 0.9706959706959707\n",
      "[[ 21   4]\n",
      " [  4 244]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 5 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87       391\n",
      "           1       0.97      0.99      0.98      2061\n",
      "\n",
      "    accuracy                           0.96      2452\n",
      "   macro avg       0.94      0.90      0.92      2452\n",
      "weighted avg       0.96      0.96      0.96      2452\n",
      "\n",
      "Epoch: 5 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83        25\n",
      "           1       0.99      0.98      0.98       248\n",
      "\n",
      "    accuracy                           0.97       273\n",
      "   macro avg       0.89      0.93      0.91       273\n",
      "weighted avg       0.97      0.97      0.97       273\n",
      "\n",
      "Train Loss: 0.13482002602259238\n",
      "Test Loss:  0.14861392469278403\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89       391\n",
      "           1       0.97      0.99      0.98      2061\n",
      "\n",
      "    accuracy                           0.97      2452\n",
      "   macro avg       0.95      0.92      0.94      2452\n",
      "weighted avg       0.97      0.97      0.97      2452\n",
      "\n",
      "Epoch: 6 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.92      0.81        25\n",
      "           1       0.99      0.96      0.98       248\n",
      "\n",
      "    accuracy                           0.96       273\n",
      "   macro avg       0.86      0.94      0.89       273\n",
      "weighted avg       0.97      0.96      0.96       273\n",
      "\n",
      "Train Loss: 0.11033053060377677\n",
      "Test Loss:  0.16150759496460004\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 7 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89       391\n",
      "           1       0.97      0.99      0.98      2061\n",
      "\n",
      "    accuracy                           0.97      2452\n",
      "   macro avg       0.95      0.92      0.94      2452\n",
      "weighted avg       0.97      0.97      0.97      2452\n",
      "\n",
      "Epoch: 7 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.92      0.75        25\n",
      "           1       0.99      0.95      0.97       248\n",
      "\n",
      "    accuracy                           0.95       273\n",
      "   macro avg       0.82      0.93      0.86       273\n",
      "weighted avg       0.96      0.95      0.95       273\n",
      "\n",
      "Train Loss: 0.10613496348472132\n",
      "Test Loss:  0.20555261096784047\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 8 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89       391\n",
      "           1       0.98      0.99      0.98      2061\n",
      "\n",
      "    accuracy                           0.97      2452\n",
      "   macro avg       0.95      0.93      0.94      2452\n",
      "weighted avg       0.97      0.97      0.97      2452\n",
      "\n",
      "Epoch: 8 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82        25\n",
      "           1       0.98      0.98      0.98       248\n",
      "\n",
      "    accuracy                           0.97       273\n",
      "   macro avg       0.91      0.89      0.90       273\n",
      "weighted avg       0.97      0.97      0.97       273\n",
      "\n",
      "Train Loss: 0.09210090192913588\n",
      "Test Loss:  0.15844747477344104\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 9 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       391\n",
      "           1       0.98      0.99      0.99      2061\n",
      "\n",
      "    accuracy                           0.98      2452\n",
      "   macro avg       0.96      0.95      0.96      2452\n",
      "weighted avg       0.98      0.98      0.98      2452\n",
      "\n",
      "Epoch: 9 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.88      0.79        25\n",
      "           1       0.99      0.96      0.98       248\n",
      "\n",
      "    accuracy                           0.96       273\n",
      "   macro avg       0.85      0.92      0.88       273\n",
      "weighted avg       0.96      0.96      0.96       273\n",
      "\n",
      "Train Loss: 0.07805316805118515\n",
      "Test Loss:  0.22481903373929008\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Best/Average scores: F1: 0.9706959706959707, P: 0.9706959706959707, R: 0.9706959706959707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.9706959706959707,\n",
       " 'p': 0.9706959706959707,\n",
       " 'r': 0.9706959706959707,\n",
       " 'cls_report': {'0': {'precision': 0.84,\n",
       "   'recall': 0.84,\n",
       "   'f1-score': 0.8399999999999999,\n",
       "   'support': 25},\n",
       "  '1': {'precision': 0.9838709677419355,\n",
       "   'recall': 0.9838709677419355,\n",
       "   'f1-score': 0.9838709677419355,\n",
       "   'support': 248},\n",
       "  'accuracy': 0.9706959706959707,\n",
       "  'macro avg': {'precision': 0.9119354838709677,\n",
       "   'recall': 0.9119354838709677,\n",
       "   'f1-score': 0.9119354838709677,\n",
       "   'support': 273},\n",
       "  'weighted avg': {'precision': 0.9706959706959707,\n",
       "   'recall': 0.9706959706959707,\n",
       "   'f1-score': 0.9706959706959707,\n",
       "   'support': 273}}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create MedCAT trained only on specialist letters\n",
    "cat_SP = CAT(cdb=cdb, vocab=vocab, config=config)\n",
    "cat_SP.train_supervised(data_path=json_file_SP, \n",
    "                     nepochs=1,\n",
    "                     test_size = 0.1,\n",
    "                     reset_cui_count=False,\n",
    "                     print_stats=True, \n",
    "                     use_filters=True) \n",
    "\n",
    "# train and evaluate MetaCAT on specialist letters\n",
    "mc_negation_SP = MetaCAT(tokenizer=tokenizer, embeddings=embeddings, pad_id=len(embeddings) -1, save_dir='data/output/mc_negation_SP', device='cpu')\n",
    "mc_negation_SP.train(json_file_SP, 'Negation', nepochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discharge letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Project', max=1.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Document', max=900.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.68      0.74       336\n",
      "           1       0.95      0.98      0.96      2180\n",
      "\n",
      "    accuracy                           0.94      2516\n",
      "   macro avg       0.88      0.83      0.85      2516\n",
      "weighted avg       0.93      0.94      0.93      2516\n",
      "\n",
      "Epoch: 0 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87        43\n",
      "           1       0.99      0.96      0.97       237\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.90      0.96      0.92       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Train Loss: 0.22446347778988263\n",
      "Test Loss:  0.09224599160786186\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 0 and f1: 0.9585986928786673\n",
      "[[ 41   2]\n",
      " [ 10 227]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 1 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87       336\n",
      "           1       0.97      0.99      0.98      2180\n",
      "\n",
      "    accuracy                           0.97      2516\n",
      "   macro avg       0.95      0.91      0.93      2516\n",
      "weighted avg       0.97      0.97      0.97      2516\n",
      "\n",
      "Epoch: 1 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88        43\n",
      "           1       0.99      0.97      0.98       237\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.91      0.95      0.93       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Train Loss: 0.11760993906673753\n",
      "Test Loss:  0.11616719514131546\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 1 and f1: 0.9615841514562196\n",
      "[[ 40   3]\n",
      " [  8 229]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 2 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91       336\n",
      "           1       0.98      0.99      0.99      2180\n",
      "\n",
      "    accuracy                           0.98      2516\n",
      "   macro avg       0.96      0.94      0.95      2516\n",
      "weighted avg       0.98      0.98      0.98      2516\n",
      "\n",
      "Epoch: 2 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93        43\n",
      "           1       0.98      0.99      0.99       237\n",
      "\n",
      "    accuracy                           0.98       280\n",
      "   macro avg       0.97      0.95      0.96       280\n",
      "weighted avg       0.98      0.98      0.98       280\n",
      "\n",
      "Train Loss: 0.08841145645812272\n",
      "Test Loss:  0.08818251617153042\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 2 and f1: 0.9783613445378151\n",
      "[[ 39   4]\n",
      " [  2 235]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 3 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.93       336\n",
      "           1       0.99      0.99      0.99      2180\n",
      "\n",
      "    accuracy                           0.98      2516\n",
      "   macro avg       0.97      0.95      0.96      2516\n",
      "weighted avg       0.98      0.98      0.98      2516\n",
      "\n",
      "Epoch: 3 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.98      0.85        43\n",
      "           1       1.00      0.94      0.97       237\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.87      0.96      0.91       280\n",
      "weighted avg       0.96      0.95      0.95       280\n",
      "\n",
      "Train Loss: 0.06267821590466026\n",
      "Test Loss:  0.17872127987045264\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 4 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92       336\n",
      "           1       0.98      0.99      0.99      2180\n",
      "\n",
      "    accuracy                           0.98      2516\n",
      "   macro avg       0.97      0.94      0.96      2516\n",
      "weighted avg       0.98      0.98      0.98      2516\n",
      "\n",
      "Epoch: 4 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90        43\n",
      "           1       0.98      0.98      0.98       237\n",
      "\n",
      "    accuracy                           0.97       280\n",
      "   macro avg       0.93      0.94      0.94       280\n",
      "weighted avg       0.97      0.97      0.97       280\n",
      "\n",
      "Train Loss: 0.07239692310787856\n",
      "Test Loss:  0.179362552789306\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 5 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95       336\n",
      "           1       0.99      0.99      0.99      2180\n",
      "\n",
      "    accuracy                           0.99      2516\n",
      "   macro avg       0.98      0.96      0.97      2516\n",
      "weighted avg       0.99      0.99      0.99      2516\n",
      "\n",
      "Epoch: 5 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90        43\n",
      "           1       0.98      0.99      0.98       237\n",
      "\n",
      "    accuracy                           0.97       280\n",
      "   macro avg       0.95      0.94      0.94       280\n",
      "weighted avg       0.97      0.97      0.97       280\n",
      "\n",
      "Train Loss: 0.057095408209577383\n",
      "Test Loss:  0.1694744773142572\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 6 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95       336\n",
      "           1       0.99      0.99      0.99      2180\n",
      "\n",
      "    accuracy                           0.99      2516\n",
      "   macro avg       0.97      0.96      0.97      2516\n",
      "weighted avg       0.99      0.99      0.99      2516\n",
      "\n",
      "Epoch: 6 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94        43\n",
      "           1       0.98      1.00      0.99       237\n",
      "\n",
      "    accuracy                           0.98       280\n",
      "   macro avg       0.98      0.95      0.96       280\n",
      "weighted avg       0.98      0.98      0.98       280\n",
      "\n",
      "Train Loss: 0.05404199010346986\n",
      "Test Loss:  0.14743061293224205\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 6 and f1: 0.9818762922309182\n",
      "[[ 39   4]\n",
      " [  1 236]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 7 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       336\n",
      "           1       0.99      0.99      0.99      2180\n",
      "\n",
      "    accuracy                           0.98      2516\n",
      "   macro avg       0.97      0.96      0.97      2516\n",
      "weighted avg       0.98      0.98      0.98      2516\n",
      "\n",
      "Epoch: 7 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91        43\n",
      "           1       0.99      0.98      0.98       237\n",
      "\n",
      "    accuracy                           0.97       280\n",
      "   macro avg       0.94      0.95      0.95       280\n",
      "weighted avg       0.97      0.97      0.97       280\n",
      "\n",
      "Train Loss: 0.04994412606821344\n",
      "Test Loss:  0.16324498961538275\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 8 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       336\n",
      "           1       0.99      0.99      0.99      2180\n",
      "\n",
      "    accuracy                           0.99      2516\n",
      "   macro avg       0.97      0.96      0.97      2516\n",
      "weighted avg       0.99      0.99      0.99      2516\n",
      "\n",
      "Epoch: 8 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92        43\n",
      "           1       0.98      1.00      0.99       237\n",
      "\n",
      "    accuracy                           0.98       280\n",
      "   macro avg       0.99      0.93      0.96       280\n",
      "weighted avg       0.98      0.98      0.98       280\n",
      "\n",
      "Train Loss: 0.04839947439835496\n",
      "Test Loss:  0.12216009156379316\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       336\n",
      "           1       0.99      1.00      1.00      2180\n",
      "\n",
      "    accuracy                           0.99      2516\n",
      "   macro avg       0.99      0.98      0.98      2516\n",
      "weighted avg       0.99      0.99      0.99      2516\n",
      "\n",
      "Epoch: 9 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.91        43\n",
      "           1       0.98      1.00      0.99       237\n",
      "\n",
      "    accuracy                           0.97       280\n",
      "   macro avg       0.97      0.93      0.95       280\n",
      "weighted avg       0.97      0.97      0.97       280\n",
      "\n",
      "Train Loss: 0.024546770298103284\n",
      "Test Loss:  0.17368482039351615\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Best/Average scores: F1: 0.9818762922309182, P: 0.9820535714285713, R: 0.9821428571428571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.9818762922309182,\n",
       " 'p': 0.9820535714285713,\n",
       " 'r': 0.9821428571428571,\n",
       " 'cls_report': {'0': {'precision': 0.975,\n",
       "   'recall': 0.9069767441860465,\n",
       "   'f1-score': 0.9397590361445783,\n",
       "   'support': 43},\n",
       "  '1': {'precision': 0.9833333333333333,\n",
       "   'recall': 0.9957805907172996,\n",
       "   'f1-score': 0.989517819706499,\n",
       "   'support': 237},\n",
       "  'accuracy': 0.9821428571428571,\n",
       "  'macro avg': {'precision': 0.9791666666666666,\n",
       "   'recall': 0.9513786674516731,\n",
       "   'f1-score': 0.9646384279255387,\n",
       "   'support': 280},\n",
       "  'weighted avg': {'precision': 0.9820535714285713,\n",
       "   'recall': 0.9821428571428571,\n",
       "   'f1-score': 0.9818762922309182,\n",
       "   'support': 280}}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create MedCAT trained only on discharge letters\n",
    "cat_DL = CAT(cdb=cdb, vocab=vocab, config=config)\n",
    "cat_DL.train_supervised(data_path=json_file_DL, \n",
    "                     nepochs=1,\n",
    "                     test_size = 0.1,\n",
    "                     reset_cui_count=False,\n",
    "                     print_stats=False, \n",
    "                     use_filters=True) \n",
    "\n",
    "\n",
    "# train and evaluate MetaCAT on discharge letters\n",
    "mc_negation_DL = MetaCAT(tokenizer=tokenizer, embeddings=embeddings, pad_id=len(embeddings) -1, save_dir='data/output/mc_negation_DL', device='cpu')\n",
    "mc_negation_DL.train(json_file_DL, 'Negation', nepochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GP entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Project', max=1.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Document', max=1702.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The provided entity for cui <2> was empty, nothing to train\n",
      "The provided entity for cui <13> was empty, nothing to train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.60      0.66       346\n",
      "           1       0.95      0.97      0.96      2720\n",
      "\n",
      "    accuracy                           0.93      3066\n",
      "   macro avg       0.84      0.79      0.81      3066\n",
      "weighted avg       0.93      0.93      0.93      3066\n",
      "\n",
      "Epoch: 0 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89        37\n",
      "           1       0.99      0.98      0.99       304\n",
      "\n",
      "    accuracy                           0.98       341\n",
      "   macro avg       0.93      0.95      0.94       341\n",
      "weighted avg       0.98      0.98      0.98       341\n",
      "\n",
      "Train Loss: 0.19272605841979384\n",
      "Test Loss:  0.09101145052247578\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 0 and f1: 0.9768095655066356\n",
      "[[ 34   3]\n",
      " [  5 299]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 1 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.77      0.84       346\n",
      "           1       0.97      0.99      0.98      2720\n",
      "\n",
      "    accuracy                           0.97      3066\n",
      "   macro avg       0.95      0.88      0.91      3066\n",
      "weighted avg       0.97      0.97      0.97      3066\n",
      "\n",
      "Epoch: 1 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92        37\n",
      "           1       0.99      0.99      0.99       304\n",
      "\n",
      "    accuracy                           0.98       341\n",
      "   macro avg       0.96      0.94      0.95       341\n",
      "weighted avg       0.98      0.98      0.98       341\n",
      "\n",
      "Train Loss: 0.10744177379536551\n",
      "Test Loss:  0.05989875349526604\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 1 and f1: 0.9821891575725527\n",
      "[[ 33   4]\n",
      " [  2 302]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 2 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91       346\n",
      "           1       0.99      0.99      0.99      2720\n",
      "\n",
      "    accuracy                           0.98      3066\n",
      "   macro avg       0.96      0.94      0.95      3066\n",
      "weighted avg       0.98      0.98      0.98      3066\n",
      "\n",
      "Epoch: 2 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.92      0.83        37\n",
      "           1       0.99      0.96      0.98       304\n",
      "\n",
      "    accuracy                           0.96       341\n",
      "   macro avg       0.87      0.94      0.90       341\n",
      "weighted avg       0.96      0.96      0.96       341\n",
      "\n",
      "Train Loss: 0.06995551144952172\n",
      "Test Loss:  0.11767120708504485\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 3 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93       346\n",
      "           1       0.99      0.99      0.99      2720\n",
      "\n",
      "    accuracy                           0.99      3066\n",
      "   macro avg       0.97      0.95      0.96      3066\n",
      "weighted avg       0.99      0.99      0.99      3066\n",
      "\n",
      "Epoch: 3 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85        37\n",
      "           1       0.98      0.98      0.98       304\n",
      "\n",
      "    accuracy                           0.97       341\n",
      "   macro avg       0.91      0.92      0.92       341\n",
      "weighted avg       0.97      0.97      0.97       341\n",
      "\n",
      "Train Loss: 0.0609581994025835\n",
      "Test Loss:  0.12046180805191398\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 4 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93       346\n",
      "           1       0.99      0.99      0.99      2720\n",
      "\n",
      "    accuracy                           0.98      3066\n",
      "   macro avg       0.97      0.95      0.96      3066\n",
      "weighted avg       0.98      0.98      0.98      3066\n",
      "\n",
      "Epoch: 4 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92        37\n",
      "           1       0.99      0.99      0.99       304\n",
      "\n",
      "    accuracy                           0.98       341\n",
      "   macro avg       0.96      0.94      0.95       341\n",
      "weighted avg       0.98      0.98      0.98       341\n",
      "\n",
      "Train Loss: 0.055520244392146076\n",
      "Test Loss:  0.06615217381881343\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 5 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94       346\n",
      "           1       0.99      1.00      0.99      2720\n",
      "\n",
      "    accuracy                           0.99      3066\n",
      "   macro avg       0.98      0.96      0.97      3066\n",
      "weighted avg       0.99      0.99      0.99      3066\n",
      "\n",
      "Epoch: 5 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82        37\n",
      "           1       0.98      0.97      0.98       304\n",
      "\n",
      "    accuracy                           0.96       341\n",
      "   macro avg       0.88      0.92      0.90       341\n",
      "weighted avg       0.96      0.96      0.96       341\n",
      "\n",
      "Train Loss: 0.048046157473105595\n",
      "Test Loss:  0.1294519767527365\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 6 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93       346\n",
      "           1       0.99      0.99      0.99      2720\n",
      "\n",
      "    accuracy                           0.98      3066\n",
      "   macro avg       0.97      0.95      0.96      3066\n",
      "weighted avg       0.98      0.98      0.98      3066\n",
      "\n",
      "Epoch: 6 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93        37\n",
      "           1       0.99      0.99      0.99       304\n",
      "\n",
      "    accuracy                           0.99       341\n",
      "   macro avg       0.97      0.96      0.96       341\n",
      "weighted avg       0.99      0.99      0.99       341\n",
      "\n",
      "Train Loss: 0.05115129854585847\n",
      "Test Loss:  0.08539440251317704\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 6 and f1: 0.9852488519500573\n",
      "[[ 34   3]\n",
      " [  2 302]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 7 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       346\n",
      "           1       0.99      0.99      0.99      2720\n",
      "\n",
      "    accuracy                           0.99      3066\n",
      "   macro avg       0.97      0.96      0.97      3066\n",
      "weighted avg       0.99      0.99      0.99      3066\n",
      "\n",
      "Epoch: 7 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.84      0.89        37\n",
      "           1       0.98      0.99      0.99       304\n",
      "\n",
      "    accuracy                           0.98       341\n",
      "   macro avg       0.96      0.92      0.94       341\n",
      "weighted avg       0.98      0.98      0.98       341\n",
      "\n",
      "Train Loss: 0.04181461643095751\n",
      "Test Loss:  0.10324886518194237\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 8 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       346\n",
      "           1       0.99      1.00      1.00      2720\n",
      "\n",
      "    accuracy                           0.99      3066\n",
      "   macro avg       0.98      0.98      0.98      3066\n",
      "weighted avg       0.99      0.99      0.99      3066\n",
      "\n",
      "Epoch: 8 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.84      0.90        37\n",
      "           1       0.98      1.00      0.99       304\n",
      "\n",
      "    accuracy                           0.98       341\n",
      "   macro avg       0.97      0.92      0.94       341\n",
      "weighted avg       0.98      0.98      0.98       341\n",
      "\n",
      "Train Loss: 0.032657565167831415\n",
      "Test Loss:  0.0971467049805344\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 9 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95       346\n",
      "           1       0.99      1.00      0.99      2720\n",
      "\n",
      "    accuracy                           0.99      3066\n",
      "   macro avg       0.98      0.96      0.97      3066\n",
      "weighted avg       0.99      0.99      0.99      3066\n",
      "\n",
      "Epoch: 9 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        37\n",
      "           1       0.98      0.98      0.98       304\n",
      "\n",
      "    accuracy                           0.97       341\n",
      "   macro avg       0.92      0.92      0.92       341\n",
      "weighted avg       0.97      0.97      0.97       341\n",
      "\n",
      "Train Loss: 0.03783209049165576\n",
      "Test Loss:  0.11132375257147942\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Best/Average scores: F1: 0.9852488519500573, P: 0.9852031686510798, R: 0.9853372434017595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.9852488519500573,\n",
       " 'p': 0.9852031686510798,\n",
       " 'r': 0.9853372434017595,\n",
       " 'cls_report': {'0': {'precision': 0.9444444444444444,\n",
       "   'recall': 0.918918918918919,\n",
       "   'f1-score': 0.9315068493150684,\n",
       "   'support': 37},\n",
       "  '1': {'precision': 0.9901639344262295,\n",
       "   'recall': 0.993421052631579,\n",
       "   'f1-score': 0.9917898193760264,\n",
       "   'support': 304},\n",
       "  'accuracy': 0.9853372434017595,\n",
       "  'macro avg': {'precision': 0.9673041894353369,\n",
       "   'recall': 0.956169985775249,\n",
       "   'f1-score': 0.9616483343455474,\n",
       "   'support': 341},\n",
       "  'weighted avg': {'precision': 0.9852031686510798,\n",
       "   'recall': 0.9853372434017595,\n",
       "   'f1-score': 0.9852488519500573,\n",
       "   'support': 341}}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create MedCAT trained only on GP entries\n",
    "cat_GP = CAT(cdb=cdb, vocab=vocab,config=config)\n",
    "cat_GP.train_supervised(data_path=json_file_GP, \n",
    "                     nepochs=1,\n",
    "                     test_size = 0.1,\n",
    "                     reset_cui_count=False,\n",
    "                     print_stats=False, \n",
    "                     use_filters=True) \n",
    "\n",
    "# train and evaluate MetaCAT on GP entries\n",
    "mc_negation_GP = MetaCAT(tokenizer=tokenizer, embeddings=embeddings, pad_id=len(embeddings) -1, save_dir='data/output/mc_negation_GP', device='cpu')\n",
    "mc_negation_GP.train(json_file_GP, 'Negation', nepochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
