{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e6a601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from evaluation_utils import get_document_text\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "dcc_dir = Path('data') / 'EMCDutchClinicalCorpus'\n",
    "data_dir = Path('data')\n",
    "result_dir = Path('results')\n",
    "bilstm_result_file = result_dir / 'bilstm_predictions_cv.csv.gz'\n",
    "robbert_result_file = result_dir / 'robbert_predictions.csv.gz'\n",
    "merged_result_file = result_dir / 'merged_results.csv.gz'\n",
    "annotation_file = data_dir / 'emc-dcc_ann.json'\n",
    "\n",
    "# Load results\n",
    "results = pd.read_csv(merged_result_file)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37eae35",
   "metadata": {},
   "source": [
    "# RobBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340c847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(robbert_result_file)\n",
    "print(results.shape[0], results.isna().sum())\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04023c98",
   "metadata": {},
   "source": [
    "## Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd01e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d833439",
   "metadata": {},
   "outputs": [],
   "source": [
    "FN = results[(results.label=='negated') & (results.robbert_512_2=='not negated')].shape[0]\n",
    "TN = results[(results.label=='not negated') & (results.robbert_512_2=='not negated')].shape[0]\n",
    "FP = results[(results.label=='not negated') & (results.robbert_512_2=='negated')].shape[0]\n",
    "TP = results[(results.label=='negated') & (results.robbert_512_2=='negated')].shape[0]\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"Overall accuracy\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\tTP:{TP} \\tFP:{FP} \\n\\n\\tFN:{FN} \\t\\tTN:{TN} \\n\")\n",
    "\n",
    "ACC = (TP+TN)/(TP+TN+FP+FN)\n",
    "SPEC = TN/(TN+FP)\n",
    "SENS = TP/(TP+FN)\n",
    "PPV = TP/(TP+FP)\n",
    "NPV = TN/(TN+FN)\n",
    "print(\"-\"*80)\n",
    "print(f\"ACC:{round(ACC,3)},\\tSENS:{round(SENS,3)},\\tSPEC:{round(SPEC,3)},\\tPPV:{round(PPV,3)},\\tNPV:{round(NPV,3)}\")\n",
    "print(\"-\"*80+\"\\n\")\n",
    "\n",
    "#################\n",
    "\n",
    "FN = results[(results.category=='DL') & (results.label=='negated') & (results.robbert_512_2=='not negated')].shape[0]\n",
    "TN = results[(results.category=='DL') & (results.label=='not negated') & (results.robbert_512_2=='not negated')].shape[0]\n",
    "FP = results[(results.category=='DL') & (results.label=='not negated') & (results.robbert_512_2=='negated')].shape[0]\n",
    "TP = results[(results.category=='DL') & (results.label=='negated') & (results.robbert_512_2=='negated')].shape[0]\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"DL accuracy\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\tTP:{TP} \\t\\tFP:{FP} \\n\\n\\tFN:{FN} \\t\\tTN:{TN} \\n\")\n",
    "\n",
    "ACC = (TP+TN)/(TP+TN+FP+FN)\n",
    "SPEC = TN/(TN+FP)\n",
    "SENS = TP/(TP+FN)\n",
    "PPV = TP/(TP+FP)\n",
    "NPV = TN/(TN+FN)\n",
    "print(\"-\"*80)\n",
    "print(f\"ACC:{round(ACC,3)},\\tSENS:{round(SENS,3)},\\tSPEC:{round(SPEC,3)},\\tPPV:{round(PPV,3)},\\tNPV:{round(NPV,3)}\")\n",
    "print(\"-\"*80+\"\\n\")\n",
    "\n",
    "#################\n",
    "\n",
    "FN = results[(results.category=='SP') & (results.label=='negated') & (results.robbert_512_2=='not negated')].shape[0]\n",
    "TN = results[(results.category=='SP') & (results.label=='not negated') & (results.robbert_512_2=='not negated')].shape[0]\n",
    "FP = results[(results.category=='SP') & (results.label=='not negated') & (results.robbert_512_2=='negated')].shape[0]\n",
    "TP = results[(results.category=='SP') & (results.label=='negated') & (results.robbert_512_2=='negated')].shape[0]\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"SP accuracy\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\tTP:{TP} \\t\\tFP:{FP} \\n\\n\\tFN:{FN} \\t\\tTN:{TN} \\n\")\n",
    "\n",
    "ACC = (TP+TN)/(TP+TN+FP+FN)\n",
    "SPEC = TN/(TN+FP)\n",
    "SENS = TP/(TP+FN)\n",
    "PPV = TP/(TP+FP)\n",
    "NPV = TN/(TN+FN)\n",
    "print(\"-\"*80)\n",
    "print(f\"ACC:{round(ACC,3)},\\tSENS:{round(SENS,3)},\\tSPEC:{round(SPEC,3)},\\tPPV:{round(PPV,3)},\\tNPV:{round(NPV,3)}\")\n",
    "print(\"-\"*80+\"\\n\")\n",
    "\n",
    "#################\n",
    "\n",
    "FN = results[(results.category=='RD') & (results.label=='negated') & (results.robbert_512_2=='not negated')].shape[0]\n",
    "TN = results[(results.category=='RD') & (results.label=='not negated') & (results.robbert_512_2=='not negated')].shape[0]\n",
    "FP = results[(results.category=='RD') & (results.label=='not negated') & (results.robbert_512_2=='negated')].shape[0]\n",
    "TP = results[(results.category=='RD') & (results.label=='negated') & (results.robbert_512_2=='negated')].shape[0]\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"RD accuracy\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\tTP:{TP} \\t\\tFP:{FP} \\n\\n\\tFN:{FN} \\t\\tTN:{TN} \\n\")\n",
    "\n",
    "ACC = (TP+TN)/(TP+TN+FP+FN)\n",
    "SPEC = TN/(TN+FP)\n",
    "SENS = TP/(TP+FN)\n",
    "PPV = TP/(TP+FP)\n",
    "NPV = TN/(TN+FN)\n",
    "print(\"-\"*80)\n",
    "print(f\"ACC:{round(ACC,3)},\\tSENS:{round(SENS,3)},\\tSPEC:{round(SPEC,3)},\\tPPV:{round(PPV,3)},\\tNPV:{round(NPV,3)}\")\n",
    "print(\"-\"*80+\"\\n\")\n",
    "\n",
    "#################\n",
    "\n",
    "FN = results[(results.category=='GP') & (results.label=='negated') & (results.robbert_512_2=='not negated')].shape[0]\n",
    "TN = results[(results.category=='GP') & (results.label=='not negated') & (results.robbert_512_2=='not negated')].shape[0]\n",
    "FP = results[(results.category=='GP') & (results.label=='not negated') & (results.robbert_512_2=='negated')].shape[0]\n",
    "TP = results[(results.category=='GP') & (results.label=='negated') & (results.robbert_512_2=='negated')].shape[0]\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"GP accuracy\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\tTP:{TP} \\t\\tFP:{FP} \\n\\n\\tFN:{FN} \\t\\tTN:{TN} \\n\")\n",
    "\n",
    "ACC = (TP+TN)/(TP+TN+FP+FN)\n",
    "SPEC = TN/(TN+FP)\n",
    "SENS = TP/(TP+FN)\n",
    "PPV = TP/(TP+FP)\n",
    "V = TN/(TN+FN)\n",
    "\n",
    "print(\"-\"*80)\n",
    "print(f\"ACC:{round(ACC,3)},\\tSENS:{round(SENS,3)},\\tSPEC:{round(SPEC,3)},\\tPPV:{round(PPV,3)},\\tNPV:{round(NPV,3)}\")\n",
    "print(\"-\"*80+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4564c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "FN = results[(results.label=='negated') & (results.robbert_512_2=='not negated')].shape[0]\n",
    "TN = results[(results.label=='not negated') & (results.robbert_512_2=='not negated')].shape[0]\n",
    "FP = results[(results.label=='not negated') & (results.robbert_512_2=='negated')].shape[0]\n",
    "TP = results[(results.label=='negated') & (results.robbert_512_2=='negated')].shape[0]\n",
    "\n",
    "ACC = (TP+TN)/(TP+TN+FP+FN)\n",
    "SPEC = TN/(TN+FP)\n",
    "SENS = TP/(TP+FN)\n",
    "PPV = TP/(TP+FP)\n",
    "NPV = TN/(TN+FN)\n",
    "\n",
    "missing_perc = results.robbert_512_2.isna().sum()/results.shape[0]\n",
    "\n",
    "scores.append({'blocksize': 512, 'acc': ACC, 'spec': SPEC, 'sens': SENS, 'ppv': PPV, 'npv': NPV, 'miss':missing_perc})\n",
    "\n",
    "############################\n",
    "\n",
    "FN = results[(results.label=='negated') & (results.robbert_128_2=='not negated')].shape[0]\n",
    "TN = results[(results.label=='not negated') & (results.robbert_128_2=='not negated')].shape[0]\n",
    "FP = results[(results.label=='not negated') & (results.robbert_128_2=='negated')].shape[0]\n",
    "TP = results[(results.label=='negated') & (results.robbert_128_2=='negated')].shape[0]\n",
    "\n",
    "ACC = (TP+TN)/(TP+TN+FP+FN)\n",
    "SPEC = TN/(TN+FP)\n",
    "SENS = TP/(TP+FN)\n",
    "PPV = TP/(TP+FP)\n",
    "NPV = TN/(TN+FN)\n",
    "\n",
    "missing_perc = results.robbert_128_2.isna().sum()/results.shape[0]\n",
    "\n",
    "scores.append({'blocksize': 128, 'acc': ACC, 'spec': SPEC, 'sens': SENS, 'ppv': PPV, 'npv': NPV, 'miss':missing_perc})\n",
    "\n",
    "############################\n",
    "\n",
    "FN = results[(results.label=='negated') & (results.robbert_32_2=='not negated')].shape[0]\n",
    "TN = results[(results.label=='not negated') & (results.robbert_32_2=='not negated')].shape[0]\n",
    "FP = results[(results.label=='not negated') & (results.robbert_32_2=='negated')].shape[0]\n",
    "TP = results[(results.label=='negated') & (results.robbert_32_2=='negated')].shape[0]\n",
    "\n",
    "ACC = (TP+TN)/(TP+TN+FP+FN)\n",
    "SPEC = TN/(TN+FP)\n",
    "SENS = TP/(TP+FN)\n",
    "PPV = TP/(TP+FP)\n",
    "NPV = TN/(TN+FN)\n",
    "\n",
    "missing_perc = results.robbert_32_2.isna().sum()/results.shape[0]\n",
    "\n",
    "scores.append({'blocksize': 32, 'acc': ACC, 'spec': SPEC, 'sens': SENS, 'ppv': PPV, 'npv': NPV, 'miss':missing_perc})\n",
    "\n",
    "scores_df = pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8273536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6433ae8",
   "metadata": {},
   "source": [
    "Going from a block size of $512$ to a block-size of $32$ does not lead to a noticeable performance decrease, it does decrease the computation time by a factor of $10$. We have to note here that due to the current batch process we skip label tokens that are outside the block size. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b1aecb",
   "metadata": {},
   "source": [
    "## False negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2d8a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatives = results[(results.label == 'negated') & (results.robbert_512_2== 'not negated')]\n",
    "false_negatives.head()\n",
    "print(false_negatives.shape[0])\n",
    "\n",
    "false_positives = results[(results.label == 'not negated') & (results.robbert_512_2== 'negated')]\n",
    "false_positives.head()\n",
    "print(false_positives.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ec7f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show issue with a random record\n",
    "random_entity = false_negatives.entity_id.tolist()[115]\n",
    "text, start, end = get_document_text(random_entity, dcc_dir, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32955610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show issue with a random record\n",
    "random_entity = false_positives.entity_id.tolist()[69]\n",
    "text, start, end = get_document_text(random_entity, dcc_dir, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb9f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_types = {'false_negative': {'uncommon': [0,5,8,10,12,22,36,47,51,53,63,66,70,77,\n",
    "                                               78,79,80,84,85,88,89,90,96,97,99,103,104,\n",
    "                                               107,112,113,114], \n",
    "                                  'annotation_error': [1,19,21,25,30,31,41,62,68,72,75,76,83,87,98,117],\n",
    "                                  'uncertainty': [2,3,4,6,7,37,46,56,57,60,61,62,67,71,109],\n",
    "                                  'long_distance': [9,40,50,52],\n",
    "                                  'minus': [11,13,14,15,16,17,18,20,23,24,26,\n",
    "                                            27,28,29,32,33,34,35,38,39,42,43,\n",
    "                                            44,45,48,49,81,115],\n",
    "                                  'other': [47,55,58,59,64,74,91,92,95,105,106,108,116],\n",
    "                                  'list': [69,73,102],\n",
    "                                  'sentence_structure': [82,86,93,94,95,96,101,110,111],\n",
    "                                  'punctuation': []\n",
    "                                 },\n",
    "              'false_positive': {'annotation_error': [0,1,2,8,10,13,14,39,42,\n",
    "                                                      43,49,53,54,55,57,59,71,\n",
    "                                                      74,75],\n",
    "                                 'negation_of_different_term': [3,4,5,6,9,12,15,18,26,27,\n",
    "                                                                28,29,36,37,38,40,48,50,\n",
    "                                                                58,65,70],\n",
    "                                 'uncertainty': [7,11,16,41,44,52,68],\n",
    "                                 'grammar': [],\n",
    "                                 'punctuation': [30,23,32,21,20],\n",
    "                                 'other': [17,19,24,25,35,46,47,51,60,61,64,\n",
    "                                           72,73, 22,31,33,34,45,62,63,66,76],\n",
    "                                 'list': [],                                                 \n",
    "                                 'hyphen': [56,67,69]\n",
    "              }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d7a4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(error_types)\n",
    "tmp['false_negative'] = tmp['false_negative'].apply(lambda x: x if isinstance(x,list) else [])\n",
    "tmp['false_positive'] = tmp['false_positive'].apply(lambda x: x if isinstance(x,list) else [])\n",
    "tmp['fn_count'], tmp['fp_count'] = zip(*tmp.apply(lambda x: (len(x[0]), len(x[1])), axis=1))\n",
    "tmp[['fn_perc','fp_perc']] = tmp[['fn_count', 'fp_count']]/tmp[['fn_count', 'fp_count']].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cae959",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[['fn_count', 'fp_count', 'fn_perc', 'fp_perc']].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b44678",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negative_map = {_v:k for k,v in error_types['false_negative'].items() for _v in v}\n",
    "false_positive_map = {_v:k for k,v in error_types['false_positive'].items() for _v in v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86db3a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatives.reset_index(inplace=True, drop=True)\n",
    "false_negatives.loc[:, 'error_type'] = \"UNDEFINED\"\n",
    "false_negatives.loc[:, 'error_type'] = false_negatives.index.map(false_negative_map)\n",
    "\n",
    "false_positives.reset_index(inplace=True, drop=True)\n",
    "false_positives.loc[:, 'error_type'] = \"UNDEFINED\"\n",
    "false_positives.loc[:, 'error_type'] = false_positives.index.map(false_positive_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5182f7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([false_positives, false_negatives]).to_csv(\"results/robbert_error_types.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860daa7f",
   "metadata": {},
   "source": [
    "# biLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4217c0",
   "metadata": {},
   "source": [
    "## False negatives biLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5867e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select false negatives\n",
    "false_negatives = results[(results.label == 'negated') & (results.bilstm == 'not negated')]\n",
    "false_negatives.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263150b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show issue with a random record\n",
    "random_entity = false_negatives.sample(1).entity_id.tolist()[0]\n",
    "text, start, end = get_document_text(random_entity, dcc_dir, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df84c972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of false negatives caused by -\n",
    "count = 0\n",
    "for index, record in false_negatives.iterrows():\n",
    "    text, start, end = get_document_text(record.entity_id, dcc_dir, Path('data'), print_text=False)\n",
    "    if text[end:end+1] == '-':\n",
    "        count += 1\n",
    "print(f'{count} of {false_negatives.shape[0]} ({round((count / false_negatives.shape[0]) * 100)}%) false negatives caused by negation described as \"-\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a20510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show text for all errors in BiLSTM cross-validation\n",
    "model_pred = pd.read_csv(bilstm_result_file)\n",
    "\n",
    "# Load annotated data\n",
    "with open(annotation_file) as f:\n",
    "    annotations = json.load(f)\n",
    "result = []\n",
    "for document in annotations['projects'][0]['documents']:\n",
    "    document_name = document['name']\n",
    "    text = document['text']\n",
    "\n",
    "    for annotation in document['annotations']:\n",
    "\n",
    "        # Extract data\n",
    "        start_char = annotation['start']\n",
    "        end_char = annotation['end']\n",
    "        negation_value = annotation['meta_anns']['Negation']['value']\n",
    "\n",
    "        # Create custom ID\n",
    "        entity_id = f'{document_name}_{start_char}_{end_char}'\n",
    "        result.append([entity_id, negation_value])\n",
    "ann_labels = pd.DataFrame(result, columns=['entity_id', 'label'])  \n",
    "cmp_labels = pd.merge(left=ann_labels, right = model_pred, left_on='entity_id', right_on='entity_id')\n",
    "all_errors = cmp_labels[cmp_labels.label != cmp_labels.bilstm_cv]\n",
    "\n",
    "for error_id, series in all_errors.iterrows():\n",
    "    get_document_text(cmp_labels[\"entity_id\"].iloc[error_id], dcc_dir, cmp_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb4952b",
   "metadata": {},
   "source": [
    "# Rule based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dd87ad",
   "metadata": {},
   "source": [
    "## False negatives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecc4bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "FNs_rule = results[(results.label == 'negated') & (results.rule_based == 'not negated')]['entity_id']\n",
    "len(FNs_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cea167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_FNs_rule = iter(FNs_rule.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd0d7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through one doc at a time\n",
    "get_document_text(next(g_FNs_rule), dcc_dir, results);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a245bb4a",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "1. Most frequent false negatives are a \"list of negations\", e.g.:\n",
    "    - \"`ENT`-\" or \"`ENT` -\" or \"`ENT`:-\" (58 cases)\n",
    "    - \"`ENT`: nee\" or \"`ENT`: geen\" or \"`ENT`: negatief\" (7 cases)\n",
    "2. 2nd most frequent are actually not false negatives, but labeling errors (22 cases)\n",
    "    - negation is labelled as part of the entity, e.g. \"geen bijwerking\" is the entity (GP1665_79_94, GP1681_0_11, GP2567_126_137)\n",
    "    - no negation actually present (GP1558_64_70, GP2796_56_63, GP2967_0_6, RD1951_465_472, SP1164_179_186)\n",
    "    - entity is a (sub)heading of report; not actually present (e.g. SP1188_26_31; only occurs in SP)\n",
    "3. A negation trigger is missing that could easily be added\n",
    "    - \"neg\" / \"negatief\" (13 cases)\n",
    "    - \"pleit tegen\" (4 cases)\n",
    "    - \"niet voorafgegaan\" (8 cases)\n",
    "    - words like \"niet\" en \"geen\" that occur directly next to `ENT`, so have a scope of 1; probably too many false positives with broader scope (12 cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36361fdf-617d-4dd7-a06f-b7732ba8ca11",
   "metadata": {},
   "source": [
    "### Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9946db50-00eb-4810-8025-06164e82f79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load entity_id, snippet containing error, error category, and (absence of) trigger involved\n",
    "errors_FN = pd.read_csv(result_dir / 'false-negatives_rule-based.csv', sep = ';')\n",
    "errors_FN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346295f8-2f86-44e5-a09d-d28a514aec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_category_counts(df, err_type):\n",
    "    cnt = df['category'].value_counts()\n",
    "    tot = df.shape[0]\n",
    "    print(f'{err_type} ({tot} total)')\n",
    "    print(pd.concat([cnt.rename('count'),\n",
    "               (cnt / tot * 100).rename('percentage')],\n",
    "              axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3964f77-a614-4014-a4a8-ee3e4a7d8c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_category_counts(errors_FN, 'False negatives')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633054ec-0f67-4188-ac91-0f041d552250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_example_error(df, category):\n",
    "    smpl = df[df['category'] == category].sample()\n",
    "    get_document_text(smpl.entity_id.values[0], dcc_dir, results.iloc[:,0:3]);\n",
    "    print(smpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05e8003-4c46-4dc3-8ea3-4802a298715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_example_error(errors_FN, 'sentence splitting')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9d47fb",
   "metadata": {},
   "source": [
    "## False positives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84556b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FPs_rule = results[(results.label == 'not negated') & (results.rule_based == 'negated')]['entity_id']\n",
    "len(FPs_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a6730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_FPs_rule = iter(FPs_rule.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad702da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through one doc at a time\n",
    "get_document_text(next(g_FPs_rule), dcc_dir, results);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acc8c76",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "- \"wel\" should be a termination trigger\n",
    "- triggers like \"geen\" and \"niet\" should have a reduced scope (maybe even just 1?)\n",
    "    - might also help to add punctuation like `,` and `;` as termination triggers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ef6cc3-321b-4b03-8496-85dc2111e1a7",
   "metadata": {},
   "source": [
    "### Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c5bf86-2758-44bc-97b3-1645515d363e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load entity_id, snippet containing error, error category, and (absence of) trigger involved\n",
    "errors_FP = pd.read_csv(result_dir / 'false-positives_rule-based.csv', sep = ';')\n",
    "errors_FP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66df3427-71dc-441d-af73-40743e7c7c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_category_counts(errors_FP, 'False positives')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de792f15-9868-490d-81b1-9b9463021570",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_example_error(errors_FP, 'missing termination trigger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005a7f20",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c53504",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[['label', 'bilstm', 'bilstm_cv', 'rule_based', \n",
    "         'robbert_512_2', 'robbert_128_2', 'robbert_32_2']]=\\\n",
    "results[['label', 'bilstm', 'bilstm_cv', 'rule_based', \n",
    "         'robbert_512_2', 'robbert_128_2', 'robbert_32_2']].apply(lambda x: x.map({'not negated':0,\n",
    "                                                                                   'negated': 1}), \n",
    "                                                                  axis=1)\n",
    "results.dropna(subset=['robbert_512_2'], inplace=True)\n",
    "results.drop(['bilstm', 'robbert_128_2', 'robbert_32_2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba47240",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ACC = (TP+TN)/(TP+TN+FP+FN)\n",
    "SPEC = TN/(TN+FP)\n",
    "SENS = TP/(TP+FN)\n",
    "PPV = TP/(TP+FP)\n",
    "NPV = TN/(TN+FN)\n",
    "'''\n",
    "\n",
    "results['ensemble_mv'] = results[['bilstm_cv', 'rule_based', 'robbert_512_2']].\\\n",
    "                            apply(lambda x: round(np.mean(x)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25acc5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(ys,est='ensemble_mv'):\n",
    "    y_est = ys[est]\n",
    "    y_true = ys['label']\n",
    "    TP = sum((y_est==y_true) & (y_true==1))\n",
    "    TN = sum((y_est==y_true) & (y_true==0))\n",
    "    FP = sum((y_est!=y_true) & (y_true==0))\n",
    "    FN = sum((y_est!=y_true) & (y_true==1))\n",
    "    \n",
    "    ACC = (TP+TN)/(TP+TN+FP+FN)\n",
    "    SPEC = TN/(TN+FP)\n",
    "    SENS = TP/(TP+FN)\n",
    "    PPV = TP/(TP+FP)\n",
    "    NPV = TN/(TN+FN)\n",
    "\n",
    "    return round(ACC,3),round(SPEC,3),round(SENS,3),round(PPV,3),round(NPV,3)\n",
    "\n",
    "results[['category', 'label', 'ensemble_mv']].groupby('category').apply(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfdf28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[['category', 'label', 'bilstm_cv']].groupby('category').apply(lambda x: confusion_matrix(x,est='bilstm_cv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a58ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[['category', 'label', 'rule_based']].groupby('category').apply(lambda x: confusion_matrix(x,est='rule_based'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d317f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[['category', 'label', 'robbert_512_2']].groupby('category').apply(lambda x: confusion_matrix(x,est='robbert_512_2'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
