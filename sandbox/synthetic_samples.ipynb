{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a dataset (DCC) with a shortage of certain labels. We want to generate \n",
    "new samples synthetically using GPT-4. We will use the following approach:\n",
    "1. We take the existing samples for each document type and present these to GPT-4\n",
    "2. we ask to generate new sentences like it, where the token labels are provided in the BIO format\n",
    "\n",
    "We care specifically about the following labels:\n",
    "* Experiencer: Other\n",
    "* Historical: Hypothetical\n",
    "\n",
    "The task of the GPT model is to generate new sentences that are similar to the input sentences but with variations of the medical concepts. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions\n",
    "The definitions are taken from the ConText/ConTextD papers:\n",
    "\n",
    "## Negation\n",
    "\n",
    "This property has two values, ‘Negated’ or ‘Not negated’. A clinical condition or term is labeled as ‘Negated’ if there is evidence in the text suggesting that the condition does not occur or exist, e.g., ‘There was no sign of sinus infection’, otherwise it is ‘Not negated’.\n",
    "\n",
    "## Temporality\n",
    "\n",
    "The temporality property places a condition along a time line. There are three possible values for this property: ‘Recent’, ‘Historical’, and ‘Hypothetical’. A condition is considered ‘Recent’ if it is maximally 2 weeks old. Conditions that developed more than 2 weeks ago are labeled as ‘Historical’. A condition is labeled as ‘Hypothetical’ if it is not ‘Recent’ or ‘Historical’, e.g., ‘patient should return if she develops fever’ [13].\n",
    "\n",
    "**Adaptation**: *'Hypothetical' is specifically about (theoretical) concepts, concepts that are not (yet) realized, i.e. concepts that may materialize in the future. 'Historical' and 'Recent' can be used for realized concepts, in which we also include their negations. I.e. if a concept is explicitly denied historically or recently, we can label it as 'Historical' or 'Recent' respectively.*\n",
    "\n",
    "## Experiencer\n",
    "\n",
    "Clinical text may refer to subjects other than the actual patient. The experiencer property describes whether the patient experienced the condition or someone else. For simplicity, we have defined only two possible values for this property: ‘Patient’ or ‘Other’, where ‘Other’ refers to anyone but the actual patient, e.g., ‘Mother is recently diagnosed with cancer’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, re\n",
    "import json, dotenv\n",
    "import pprint\n",
    "\n",
    "import openai\n",
    "import asyncio\n",
    "from openai import AsyncOpenAI, OpenAI\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCC = json.load(open('../data/emc-dcc_ann_Augmented.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = DCC['projects'][0]['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = {'Negation': defaultdict(int),\n",
    "                'Temporality': defaultdict(int),\n",
    "                'Experiencer': defaultdict(int)}\n",
    "\n",
    "for doc in docs:\n",
    "    for ann in doc['annotations']:\n",
    "        for _class, val in ann['meta_anns'].items():\n",
    "            class_counts[_class][val['value']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'Experiencer': defaultdict(<class 'int'>, {'patient': 12455, 'other': 886}),\n",
      "  'Negation': defaultdict(<class 'int'>,\n",
      "                          { 'negated': 1760,\n",
      "                            'not negated': 10791}),\n",
      "  'Temporality': defaultdict(<class 'int'>,\n",
      "                             { 'historical': 513,\n",
      "                               'hypothetical': 106,\n",
      "                               'recent': 11932})}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(class_counts, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_docs_hypothetical = []\n",
    "for i, doc in enumerate(docs):\n",
    "    if doc['source'] == 'EMC_DCC_ORIGINAL':\n",
    "        for concept in doc['annotations']:\n",
    "            if (concept['meta_anns']['Temporality']['value']=='hypothetical'):\n",
    "                doc['index'] = i\n",
    "                relevant_docs_hypothetical.append(doc)\n",
    "                break\n",
    "        \n",
    "relevant_docs_experiencer = []\n",
    "for i, doc in enumerate(docs):\n",
    "    if doc['source'] == 'EMC_DCC_ORIGINAL':\n",
    "        for concept in doc['annotations']:\n",
    "            if (concept['meta_anns']['Experiencer']['value']=='other'):\n",
    "                doc['index'] = i\n",
    "                relevant_docs_experiencer.append(doc)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 79)"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relevant_docs_hypothetical), len(relevant_docs_experiencer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'koorts niet gemeten.\\n'"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_docs_hypothetical[69]['text'][93:129]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(93, 99, 16597)]"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(d['start'],d['end'], d['id']) for d in relevant_docs_hypothetical[69]['annotations'] \n",
    " if d['meta_anns']['Temporality']['value']=='hypothetical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SP1753'"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_docs_hypothetical[69]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections = [\n",
    "    {'doc_id': 'DL1616', 'annotation_id': 1873, 'meta': 'Experiencer', 'value': 'patient'},\n",
    "    {'doc_id': 'DL1139', 'annotation_id': 108, 'meta': 'Experiencer', 'value': 'patient'},\n",
    "    {'doc_id': 'GP2799', 'annotation_id': 8210, 'meta': 'Experiencer', 'value': 'patient'},\n",
    "    {'doc_id': 'SP1476', 'annotation_id': 15532, 'meta': 'Experiencer', 'value': 'patient'},\n",
    "    {'doc_id': 'DL1567', 'annotation_id': 1694, 'meta': 'Temporality', 'value': 'historical'},\n",
    "    {'doc_id': 'DL1711', 'annotation_id': 2232, 'meta': 'Temporality', 'value': 'recent'},\n",
    "    {'doc_id': 'DL1812', 'annotation_id': 2232, 'meta': 'Temporality', 'value': 'historical'},\n",
    "    {'doc_id': 'DL1814', 'annotation_id': 2703, 'meta': 'Temporality', 'value': 'historical'},\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the docs\n",
    "update_docs = docs.copy()\n",
    "for c in corrections:\n",
    "    for d in update_docs:\n",
    "        d['source'] = 'EMC_DCC_ORIGINAL'\n",
    "        if d['name']==c['doc_id']:\n",
    "            for a in d['annotations']:\n",
    "                if a['id']==c['annotation_id']:\n",
    "                    a['meta_anns'][c['meta']]['value'] = c['value']\n",
    "# put updated docs in DCC\n",
    "DCC['projects'][0]['documents'] = update_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write DCC back to json \n",
    "with open('../data/emc-dcc_ann_NEW.json', 'w') as f:\n",
    "    json.dump(DCC, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "OAI_ASYNC_CLIENT = AsyncOpenAI(api_key=os.getenv(\"OPENAI_KEY\"), max_retries=2)\n",
    "OAI_CLIENT = OpenAI(api_key=os.getenv(\"OPENAI_KEY\"), max_retries=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_HYPOTHETICAL = \"\"\"\n",
    "    Je bent een kritische assistent die mij helpt om nieuwe tekst te bedenken.\n",
    "    De tekst moeten voldoen aan de volgende eisen:\n",
    "    - ze moeten semantisch correct zijn en vergelijkbaar zijn met de voorbeeltekst die ik je geef.\n",
    "    - de voorbeeltekst wordt voorafgegaan door de term VOORBEELDTEKST\n",
    "    - in de voorbeeldzin worden 1 of meer concepten benoemd die hypothethisch zijn, het is belangrijk\n",
    "    dat deze concepten in de nieuwe zin ook hypothetisch zijn, het mogen ook andere concepten zijn. \n",
    "    Een voorbeeld van een hypothetische concept = 'een voorafgaand trauma kan niet worden herinnerd', waarin 'trauma' het concept is.\n",
    "    Een ander voorbeeld = 'ter uitsluiting van epifysaire dysplasie' waarin 'epifysaire dysplasie' het concept is.\n",
    "    - de concepten die je moet vervangen zijn aangegeven met verticale streepjes, dus |concept|.\n",
    "    - het domein is medisch dus gebruik medische concepten.\n",
    "    - probeer de medische concepten te varieren, dus gebruik niet steeds dezelfde concepten.\n",
    "    - geef als antwoord ALLEEN de nieuw gegenereerde zinnen, voorafgaand met de term NIEUWE_TEKST\n",
    "    - in de NIEUWE_TEKST, plaats de concepten die hypothetisch zijn tussen verticale streepjes, dus '|', \n",
    "    dus bijvoorbeeld: 'ter uitsluiting van |epifysaire dysplasie|'\n",
    "    \n",
    "In case you have doubts:\n",
    "'Hypothetical' is specifically about (theoretical) concepts, which means concepts that are not (yet) realized OR\n",
    "concepts that may have occurred in the past. 'Historical' and 'Recent' can be used for realized concepts, in which we also include their negations. \n",
    "I.e. if a concept is explicitly denied historically or recently, we can label it as 'Historical' or 'Recent' respectively.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "SYSTEM_PROMPT_EXPERIENCER = \"\"\"\n",
    "    Je bent een kritische assistent die mij helpt om nieuwe text te bedenken.\n",
    "    Deze text moeten voldoen aan de volgende eisen:\n",
    "    - het moet semantisch correct zijn en vergelijkbaar zijn met de text die ik je geef.\n",
    "    - de voorbeeldtext wordt voorafgegaan door de term VOORBEELDTEKST\n",
    "    - in de voorbeeldtext worden 1 of meer concepten benoemd die verwijzen naar een persoon anders dan de patient, het is belangrijk\n",
    "    dat deze concepten in de nieuwe zin ook verwijzen naar iemand anders dan de patient (zoals een familielid), \n",
    "    het mogen ook andere medische concepten zijn.\n",
    "    - de concepten die je moet vervangen zijn aangegeven met verticale streepjes, dus |concept|.\n",
    "    - Een voorbeeld van een concept wat verwijst naar een ander persoon dan de patient =\n",
    "    'Een zusje van #Name# is elders operatief behandeld in verband met recidiverende patella luxaties', waarin 'luxaties' het concept is, en er \n",
    "    wordt verwezen naar de zus van de patient.    \n",
    "    - het domein is medisch dus gebruik medische concepten.\n",
    "    - probeer de medische concepten te varieren, dus gebruik niet steeds dezelfde concepten.\n",
    "    - varieer de ziektebeelden\n",
    "    - varieer de opmaak van de text, dus gebruik niet steeds dezelfde opmaak.\n",
    "    - geef als antwoord ALLEEN de nieuw gegenereerde text, voorafgaand met de term NIEUWE_TEKST\n",
    "    - in de NIEUWE_TEKST, plaats alleen de concepten die verwijzen naar een ander persoon dan de patient tussen tussen verticale streepjes |, \n",
    "    dus bijvoorbeeld: 'Een zusje van #Name# is elders operatief behandeld in verband met recidiverende patella |luxaties|'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_res(USER_TEXT='Good day', \n",
    "                 SYSTEM_PROMPT=SYSTEM_PROMPT_HYPOTHETICAL, \n",
    "                 n = 10,\n",
    "                 MODEL=\"gpt-4\"):\n",
    "    return OAI_CLIENT.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            n = n,\n",
    "            messages=[\n",
    "                        {\"role\": \"system\",\n",
    "                        \"content\": SYSTEM_PROMPT\n",
    "                        },\n",
    "                        {\"role\": \"user\", \n",
    "                        \"content\": USER_TEXT\n",
    "                        }],\n",
    "            stream=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_VERSION = 'gpt-4-1106-preview'\n",
    "CURRENT_DATE = datetime.datetime.now().strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:10, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "#re_extract = re.compile(r'NIEUWE_ZIN\\:(.*)')\n",
    "nieuwe_zinnen_hypothetisch = []\n",
    "for i, doc in tqdm(enumerate(relevant_docs_hypothetical)):\n",
    "    EXAMPLE = doc['text'].replace('|', ' ')\n",
    "    # add | vertical bars around the concept that needs to be replaced\n",
    "    LOCS = [(d['start'],d['end']) for d in doc['annotations'] \n",
    "                if d['meta_anns']['Temporality']['value']=='hypothetical']\n",
    "    for loc in LOCS:\n",
    "        EXAMPLE = EXAMPLE[:loc[0]] + '|' + EXAMPLE[loc[0]:loc[1]] + '|' + EXAMPLE[loc[1]:]\n",
    "    \n",
    "    res = get_chat_res(SYSTEM_PROMPT=SYSTEM_PROMPT_HYPOTHETICAL, \n",
    "                       n=2,\n",
    "                       MODEL=GPT_VERSION, # gpt-3.5-turbo-instruct-0914\n",
    "                       USER_TEXT=\"VOORBEELDTEKST: \" + EXAMPLE)\n",
    "\n",
    "    for j, _res in enumerate(res.choices):\n",
    "        txt = _res.message.content\n",
    "        nieuwe_zinnen_hypothetisch.append((\n",
    "            doc['name'],\n",
    "            'hypothetisch',\n",
    "            j,\n",
    "            txt[txt.find('NIEUWE_TEKST')+12:].strip()))\n",
    "    if i==0:\n",
    "        break       \n",
    "#res = pd.DataFrame(nieuwe_zinnen_hypothetisch, columns=['doc_id', 'synth_num', 'text'])\n",
    "#res.to_parquet(f'../data/synth_temporality_{GPT_VERSION.replace(\"-\", \"_\")}_{CURRENT_DATE}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [20:02, 15.22s/it]\n"
     ]
    }
   ],
   "source": [
    "#re_extract = re.compile(r'NIEUWE_ZIN\\:(.*)')\n",
    "nieuwe_zinnen_experiencer = []\n",
    "for i, doc in tqdm(enumerate(relevant_docs_experiencer)):\n",
    "    EXAMPLE = doc['text'].replace('|', ' ')\n",
    "    # add | vertical bars around the concept that needs to be replaced\n",
    "    LOCS = [(d['start'],d['end']) for d in doc['annotations'] \n",
    "                if d['meta_anns']['Experiencer']['value']=='other']\n",
    "    for loc in LOCS:\n",
    "        EXAMPLE = EXAMPLE[:loc[0]] + '|' + EXAMPLE[loc[0]:loc[1]] + '|' + EXAMPLE[loc[1]:]\n",
    "    \n",
    "    res = get_chat_res(SYSTEM_PROMPT=SYSTEM_PROMPT_EXPERIENCER, \n",
    "                       n=10,\n",
    "                       MODEL=GPT_VERSION, # gpt-3.5-turbo-instruct-0914\n",
    "                       USER_TEXT=\"VOORBEELDTEKST: \" + EXAMPLE)\n",
    "\n",
    "    for j, _res in enumerate(res.choices):\n",
    "        txt = _res.message.content\n",
    "        nieuwe_zinnen_experiencer.append((\n",
    "            doc['name'],\n",
    "            'hypothetical',\n",
    "            j,\n",
    "            txt[txt.find('NIEUWE_TEKST')+12:].strip()))\n",
    "        \n",
    "res = pd.DataFrame(nieuwe_zinnen_experiencer, columns=['doc_id', 'synth_num', 'text'])\n",
    "res.to_parquet(f'../data/synth_experiencer_{GPT_VERSION.replace(\"-\", \"_\")}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the spans from the synthetic set and add them to the original dataset with an additional label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191 Geachte collega, tijdens het spreekuur op 14-02-1996 werd uw patiënt #Name# door ons gezien op de afdeling Orthopedie, doorverwezen vanuit het consultatiebureau met de vermoeden van een congenitale heupdysplasie aan de linkerzijde.\n",
      "Bij het opnemen van de anamnese kwam naar voren dat #Name# vier maanden geleden geboren is via een keizersnede, volgend op een ongecompliceerde zwangerschap.\n",
      "Zijn zusje had eerder te maken met een milde scoliose, ook na een keizersnede.\n",
      "Aanvullend onderzoek: Röntgen van het bekken, in AP en laterale projectie: Lichte aanwijzingen voor heupdysplasie aan de linkerkant.\n",
      "Conclusie: Geringe heupdysplasie aan de linkerkant.\n",
      "692 Vanwege ernstige pre-eclampsie bij de moeder was een urgente keizersnede noodzakelijk voor het welzijn van de foetus.\n",
      "Decursus: Momenteel is #Name# 30 maanden oud, waarbij correctie voor vroeggeboorte neerkomt op 27 maanden.\n",
      "Zijn/haar ontwikkelingsquotiënt (DQ) is 89 zonder correctie en met correctie voor vroeggeboorte komt dit uit op 100.\n"
     ]
    }
   ],
   "source": [
    "for i, (name, subid, text) in enumerate(nieuwe_zinnen_experiencer):\n",
    "    try:\n",
    "        start, end = re.search('\\|.*\\|', text).span()\n",
    "        start += 1\n",
    "        end -= 1\n",
    "        _doc = {\n",
    "            'id': i,\n",
    "            'source': 'synthetic',\n",
    "            'source_version': f\"{GPT_VERSION}|{CURRENT_DATE}\",     \n",
    "            'name': f\"{name}|synth|{subid}\",\n",
    "            'text': text.replace('|', ''),\n",
    "            'annotations': [\n",
    "                {\n",
    "                    'id': 1,\n",
    "                    'user': 'emc_dcc_synth',\n",
    "                    'cui': 1,\n",
    "                    'start': start,\n",
    "                    'end': end,\n",
    "                    'value': text[start:end],\n",
    "                    'validated': False,\n",
    "                    'correct': True,\n",
    "                    'alternative': False,\n",
    "                    'killed': False,\n",
    "                    'meta_anns': {\n",
    "                        'Experiencer': {'value': 'other',\n",
    "                                        'name': 'Experiencer',\n",
    "                                        'validated': False,\n",
    "                                        'acc': 1.0\n",
    "                                        },\n",
    "                    }            \n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    except:\n",
    "        print(i, text)\n",
    "    update_docs.append(_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 789,\n",
       " 'source': 'synthetic',\n",
       " 'source_version': 'gpt-4-1106-preview|20231214',\n",
       " 'name': 'SP2066|synth|9',\n",
       " 'text': 'AANLEIDING: onverklaarbare vermoeidheid en gewichtsverlies.\\nEr is geen sprake van gastro-intestinale obstructies of maligniteiten.\\nVervolgstappen: de behandelingsopties zullen worden overlegd tijdens het spreekuur endocrinologie.',\n",
       " 'annotations': [{'id': 1,\n",
       "   'user': 'emc_dcc_synth',\n",
       "   'cui': 1,\n",
       "   'start': 215,\n",
       "   'end': 229,\n",
       "   'value': 'endocrinologie',\n",
       "   'validated': False,\n",
       "   'correct': True,\n",
       "   'alternative': False,\n",
       "   'killed': False,\n",
       "   'meta_anns': {'Experiencer': {'value': 'other',\n",
       "     'name': 'Experiencer',\n",
       "     'validated': False,\n",
       "     'acc': 1.0}}}]}"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_docs[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write new samples to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCC['projects'][0]['documents'] = update_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write DCC back to json \n",
    "with open('../data/emc-dcc_ann_Augmented.json', 'w') as f:\n",
    "    json.dump(DCC, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate English corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* English -- BioScope; [HF](https://huggingface.co/datasets/bigbio/bioscope), [src](https://rgai.inf.u-szeged.hu/downloads)\n",
    "* English -- [Genia](http://www.geniaproject.org/genia-corpus/term-corpus)\n",
    "* English -- Sherlock, SFU review corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
