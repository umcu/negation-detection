{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a dataset (DCC) with a shortage of certain labels. We want to generate \n",
    "new samples synthetically using GPT-4. We will use the following approach:\n",
    "1. We take the existing samples for each document type and present these to GPT-4\n",
    "2. we ask to generate new sentences like it, where the token labels are provided in the BIO format\n",
    "\n",
    "We care specifically about the following labels:\n",
    "* Experiencer: Other\n",
    "* Historical: Hypothetical\n",
    "\n",
    "The task of the GPT model is to generate new sentences that are similar to the input sentences but with variations of the medical concepts. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions\n",
    "The definitions are taken from the ConText/ConTextD papers:\n",
    "\n",
    "## Negation\n",
    "\n",
    "This property has two values, ‘Negated’ or ‘Not negated’. A clinical condition or term is labeled as ‘Negated’ if there is evidence in the text suggesting that the condition does not occur or exist, e.g., ‘There was no sign of sinus infection’, otherwise it is ‘Not negated’.\n",
    "\n",
    "## Temporality\n",
    "\n",
    "The temporality property places a condition along a time line. There are three possible values for this property: ‘Recent’, ‘Historical’, and ‘Hypothetical’. A condition is considered ‘Recent’ if it is maximally 2 weeks old. Conditions that developed more than 2 weeks ago are labeled as ‘Historical’. A condition is labeled as ‘Hypothetical’ if it is not ‘Recent’ or ‘Historical’, e.g., ‘patient should return if she develops fever’ [13].\n",
    "\n",
    "**Adaptation**: *'Hypothetical' is specifically about theoretical concepts, that are not (yet) realized. 'Historical' and 'Recent' \n",
    "can be used for realized concepts, in which we also include their negations. I.e. if a concept is explicitly denied historically or recently, we can label it as 'Historical' or 'Recent' respectively.*\n",
    "\n",
    "## Experiencer\n",
    "\n",
    "Clinical text may refer to subjects other than the actual patient. The experiencer property describes whether the patient experienced the condition or someone else. For simplicity, we have defined only two possible values for this property: ‘Patient’ or ‘Other’, where ‘Other’ refers to anyone but the actual patient, e.g., ‘Mother is recently diagnosed with cancer’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, re\n",
    "import json, dotenv\n",
    "import pprint\n",
    "\n",
    "import openai\n",
    "import asyncio\n",
    "from openai import AsyncOpenAI, OpenAI\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCC = json.load(open('../data/emc-dcc_ann_NEW.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = DCC['projects'][0]['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = {'Negation': defaultdict(int),\n",
    "                'Temporality': defaultdict(int),\n",
    "                'Experiencer': defaultdict(int)}\n",
    "\n",
    "for doc in docs:\n",
    "    for ann in doc['annotations']:\n",
    "        for _class, val in ann['meta_anns'].items():\n",
    "            class_counts[_class][val['value']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'Experiencer': defaultdict(<class 'int'>, {'patient': 12455, 'other': 96}),\n",
      "  'Negation': defaultdict(<class 'int'>,\n",
      "                          { 'negated': 1760,\n",
      "                            'not negated': 10791}),\n",
      "  'Temporality': defaultdict(<class 'int'>,\n",
      "                             { 'historical': 513,\n",
      "                               'hypothetical': 106,\n",
      "                               'recent': 11932})}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(class_counts, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_docs_hypothetical = []\n",
    "for i, doc in enumerate(docs):\n",
    "    for concept in doc['annotations']:\n",
    "        if (concept['meta_anns']['Temporality']['value']=='hypothetical'):\n",
    "            doc['index'] = i\n",
    "            relevant_docs_hypothetical.append(doc)\n",
    "            break\n",
    "        \n",
    "relevant_docs_experiencer = []\n",
    "for i, doc in enumerate(docs):\n",
    "    for concept in doc['annotations']:\n",
    "        if (concept['meta_anns']['Experiencer']['value']=='other'):\n",
    "            doc['index'] = i\n",
    "            relevant_docs_experiencer.append(doc)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 79)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relevant_docs_hypothetical), len(relevant_docs_experiencer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'koorts niet gemeten.\\n'"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_docs_hypothetical[69]['text'][93:129]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(93, 99, 16597)]"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(d['start'],d['end'], d['id']) for d in relevant_docs_hypothetical[69]['annotations'] \n",
    " if d['meta_anns']['Temporality']['value']=='hypothetical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DL1814'"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_docs_hypothetical[9]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections = [\n",
    "    {'doc_id': 'DL1616', 'annotation_id': 1873, 'meta': 'Experiencer', 'value': 'patient'},\n",
    "    {'doc_id': 'DL1139', 'annotation_id': 108, 'meta': 'Experiencer', 'value': 'patient'},\n",
    "    {'doc_id': 'GP2799', 'annotation_id': 8210, 'meta': 'Experiencer', 'value': 'patient'},\n",
    "    {'doc_id': 'SP1476', 'annotation_id': 15532, 'meta': 'Experiencer', 'value': 'patient'},\n",
    "    {'doc_id': 'DL1567', 'annotation_id': 1694, 'meta': 'Temporality', 'value': 'historical'},\n",
    "    {'doc_id': 'DL1711', 'annotation_id': 2232, 'meta': 'Temporality', 'value': 'recent'},\n",
    "    {'doc_id': 'DL1812', 'annotation_id': 2232, 'meta': 'Temporality', 'value': 'historical'},\n",
    "    {'doc_id': 'DL1814', 'annotation_id': 2703, 'meta': 'Temporality', 'value': 'historical'},\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the docs\n",
    "update_docs = docs.copy()\n",
    "for c in corrections:\n",
    "    for d in update_docs:\n",
    "        if d['name']==c['doc_id']:\n",
    "            for a in d['annotations']:\n",
    "                if a['id']==c['annotation_id']:\n",
    "                    a['meta_anns'][c['meta']]['value'] = c['value']\n",
    "# put updated docs in DCC\n",
    "DCC['projects'][0]['documents'] = update_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write DCC back to json \n",
    "with open('../data/emc-dcc_ann_NEW.json', 'w') as f:\n",
    "    json.dump(DCC, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "OAI_ASYNC_CLIENT = AsyncOpenAI(api_key=os.getenv(\"OPENAI_KEY\"), max_retries=2)\n",
    "OAI_CLIENT = OpenAI(api_key=os.getenv(\"OPENAI_KEY\"), max_retries=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_HYPOTHETICAL = \"\"\"\n",
    "    Je bent een kritische assistent die mij helpt om nieuwe zinnen te bedenken.\n",
    "    Deze zinnen moeten voldoen aan de volgende eisen:\n",
    "    - ze moeten semantisch correct zijn en vergelijkbaar zijn met de voorbeeldzinnen die ik je geef.\n",
    "    - de voorbeeldzinnen worden voorafgegaan door de term VOORBEELDZIN\n",
    "    - in de voorbeeldzin worden 1 of meer concepten benoemd die hypothethisch zijn, het is belangrijk\n",
    "    dat deze concepten in de nieuwe zin ook hypothetisch zijn, het mogen ook andere concepten zijn. \n",
    "    Een voorbeeld van een hypothetische concept = 'een voorafgaand trauma kan niet worden herinnerd', waarin 'trauma' het concept is.\n",
    "    Een ander voorbeeld = 'ter uitsluiting van epifysaire dysplasie' waarin 'epifysaire dysplasie' het concept is.\n",
    "    - het domein is medisch dus gebruik medische concepten.\n",
    "    - probeer de medische concepten te varieren, dus gebruik niet steeds dezelfde concepten.\n",
    "    - geef als antwoord ALLEEN de nieuw gegenereerde zinnen, voorafgaand met de term NIEUWE_ZIN\n",
    "    - in de NIEUWE_ZIN, plaats de concepten die hypothetisch zijn tussen verticale streepjes, dus '|', \n",
    "    dus bijvoorbeeld: 'ter uitsluiting van |epifysaire dysplasie|'\n",
    "\"\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT_EXPERIENCER = \"\"\"\n",
    "    Je bent een kritische assistent die mij helpt om nieuwe text te bedenken.\n",
    "    Deze text moeten voldoen aan de volgende eisen:\n",
    "    - het moet semantisch correct zijn en vergelijkbaar zijn met de text die ik je geef.\n",
    "    - de voorbeeldtext wordt voorafgegaan door de term VOORBEELDTEXT\n",
    "    - in de voorbeeldtext worden 1 of meer concepten benoemd die verwijzen naar een persoon anders dan de patient, het is belangrijk\n",
    "    dat deze concepten in de nieuwe zin ook verwijzen naar iemand anders dan de patient (zoals een familielid), \n",
    "    het mogen ook andere medische concepten zijn.\n",
    "    - de concepten die je moet vervangen zijn aangegeven met vertical streepjes, dus |concept|.\n",
    "    - Een voorbeeld van een concept wat verwijst naar een ander persoon dan de patient =\n",
    "    'Een zusje van #Name# is elders operatief behandeld in verband met recidiverende patella luxaties', waarin 'luxaties' het concept is, en er \n",
    "    wordt verwezen naar de zus van de patient.    \n",
    "    - het domein is medisch dus gebruik medische concepten.\n",
    "    - probeer de medische concepten te varieren, dus gebruik niet steeds dezelfde concepten.\n",
    "    - varieer de ziektebeelden\n",
    "    - varieer de opmaak van de text, dus gebruik niet steeds dezelfde opmaak.\n",
    "    - geef als antwoord ALLEEN de nieuw gegenereerde text, voorafgaand met de term NIEUWE_TEXT\n",
    "    - in de NIEUWE_TEXT, plaats de concepten die verwijzen naar een ander persoon dan de patient tussen tussen verticale streepjes |, \n",
    "    dus bijvoorbeeld: 'Een zusje van #Name# is elders operatief behandeld in verband met recidiverende patella |luxaties|'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_res(USER_TEXT='Good day', \n",
    "                 SYSTEM_PROMPT=SYSTEM_PROMPT_HYPOTHETICAL, \n",
    "                 n = 10,\n",
    "                 MODEL=\"gpt-4\"):\n",
    "    return OAI_CLIENT.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            n = n,\n",
    "            messages=[\n",
    "                        {\"role\": \"system\",\n",
    "                        \"content\": SYSTEM_PROMPT\n",
    "                        },\n",
    "                        {\"role\": \"user\", \n",
    "                        \"content\": USER_TEXT\n",
    "                        }],\n",
    "            stream=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:04, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "#re_extract = re.compile(r'NIEUWE_ZIN\\:(.*)')\n",
    "nieuwe_zinnen_hypothetisch = []\n",
    "for i, doc in tqdm(enumerate(relevant_docs_hypothetical)):\n",
    "    res = get_chat_res(SYSTEM_PROMPT=SYSTEM_PROMPT_HYPOTHETICAL, \n",
    "                       n=1,\n",
    "                       USER_TEXT=\"Parafraseer de VOORBEELDZIN: \" + doc['text'])\n",
    "    # extract the part after \"NIEUWE_ZIN\"\n",
    "    for _res in res.choices:\n",
    "        txt = _res.message.content\n",
    "        nieuwe_zinnen_hypothetisch.append(txt[txt.find('NIEUWE_ZIN:')+12:].strip())\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "#re_extract = re.compile(r'NIEUWE_ZIN\\:(.*)')\n",
    "nieuwe_zinnen_experiencer = []\n",
    "for i, doc in tqdm(enumerate(relevant_docs_experiencer)):\n",
    "    EXAMPLE = doc['text'].replace('|', ' ')\n",
    "    # add | vertical bars around the concept that needs to be replaced\n",
    "    LOCS = [(d['start'],d['end']) for d in doc['annotations'] \n",
    "                if d['meta_anns']['Experiencer']['value']=='other']\n",
    "    for loc in LOCS:\n",
    "        EXAMPLE = EXAMPLE[:loc[0]] + '|' + EXAMPLE[loc[0]:loc[1]] + '|' + EXAMPLE[loc[1]:]\n",
    "    \n",
    "    res = get_chat_res(SYSTEM_PROMPT=SYSTEM_PROMPT_EXPERIENCER, \n",
    "                       n=10,\n",
    "                       USER_TEXT=\"VOORBEELDTEXT: \" + EXAMPLE)\n",
    "\n",
    "    for j, _res in enumerate(res.choices):\n",
    "        txt = _res.message.content\n",
    "        nieuwe_zinnen_experiencer.append((\n",
    "            doc['name'],\n",
    "            j,\n",
    "            txt[txt.find('NIEUWE_TEXT')+12:].strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>synth_num</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>De broer van #Name# is in een ander ziekenhuis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>335</td>\n",
       "      <td>0</td>\n",
       "      <td>In de familiegeschiedenis is geen sprake van |...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>338</td>\n",
       "      <td>0</td>\n",
       "      <td>Geschiedenis: Tijdens een routine controle bij...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "      <td>Het is mogelijk dat de biologische grootvader ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id  synth_num                                               text\n",
       "0     133          0  De broer van #Name# is in een ander ziekenhuis...\n",
       "1     335          0  In de familiegeschiedenis is geen sprake van |...\n",
       "2     338          0  Geschiedenis: Tijdens een routine controle bij...\n",
       "3     363          0  Het is mogelijk dat de biologische grootvader ..."
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(nieuwe_zinnen_experiencer, columns=['doc_id', 'synth_num', 'text'])\n",
    "res.to_parquet('../data/synth_experiencer.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the spans from the synthetic set and add them to the original dataset with an additional label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write new samples to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate English corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* English -- BioScope; [HF](https://huggingface.co/datasets/bigbio/bioscope), [src](https://rgai.inf.u-szeged.hu/downloads)\n",
    "* English -- [Genia](http://www.geniaproject.org/genia-corpus/term-corpus)\n",
    "* English -- Sherlock, SFU review corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
