{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a dataset (DCC) with a shortage of certain labels. We want to generate \n",
    "new samples synthetically using GPT-4. We will use the following approach:\n",
    "1. We take the existing samples for each document type and present these to GPT-4\n",
    "2. we ask to generate new sentences like it, where the token labels are provided in the BIO format\n",
    "\n",
    "We care specifically about the following labels:\n",
    "* Experiencer: Other\n",
    "* Historical: Hypothetical\n",
    "\n",
    "The task of the GPT model is to generate new sentences that are similar to the input sentences but with variations of the medical concepts. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions\n",
    "The definitions are taken from the ConText/ConTextD papers:\n",
    "\n",
    "## Negation\n",
    "\n",
    "This property has two values, ‘Negated’ or ‘Not negated’. A clinical condition or term is labeled as ‘Negated’ if there is evidence in the text suggesting that the condition does not occur or exist, e.g., ‘There was no sign of sinus infection’, otherwise it is ‘Not negated’.\n",
    "\n",
    "## Temporality\n",
    "\n",
    "The temporality property places a condition along a time line. There are three possible values for this property: ‘Recent’, ‘Historical’, and ‘Hypothetical’. A condition is considered ‘Recent’ if it is maximally 2 weeks old. Conditions that developed more than 2 weeks ago are labeled as ‘Historical’. A condition is labeled as ‘Hypothetical’ if it is not ‘Recent’ or ‘Historical’, e.g., ‘patient should return if she develops fever’ [13].\n",
    "\n",
    "**Adaptation**: *'Hypothetical' is specifically about (theoretical) concepts, concepts that are not (yet) realized, i.e. concepts that may materialize in the future. 'Historical' and 'Recent' can be used for realized concepts, in which we also include their negations. I.e. if a concept is explicitly denied historically or recently, we can label it as 'Historical' or 'Recent' respectively.*\n",
    "\n",
    "## Experiencer\n",
    "\n",
    "Clinical text may refer to subjects other than the actual patient. The experiencer property describes whether the patient experienced the condition or someone else. For simplicity, we have defined only two possible values for this property: ‘Patient’ or ‘Other’, where ‘Other’ refers to anyone but the actual patient, e.g., ‘Mother is recently diagnosed with cancer’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re\n",
    "import json, dotenv\n",
    "import pprint\n",
    "\n",
    "import openai\n",
    "import asyncio\n",
    "from openai import AsyncOpenAI, OpenAI\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_temporality = True\n",
    "run_experiencer = False \n",
    "experiencer_file = '../data/synth_experiencer_gpt_4_1106_preview.parquet'\n",
    "hypothetical_file = '../data/synth_hypothetical_gpt_4_1106_preview.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCC = json.load(open('../data/emc-dcc_ann.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_dcc = DCC.copy()\n",
    "for c in update_dcc['projects'][0]['documents']:\n",
    "    c['source'] = 'EMC_DCC_ORIGINAL'\n",
    "with open('../data/emc-dcc_ann_ORIGNAL.json', 'w') as f:\n",
    "    json.dump(update_dcc, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = update_dcc['projects'][0]['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = {'Negation': defaultdict(int),\n",
    "                'Temporality': defaultdict(int),\n",
    "                'Experiencer': defaultdict(int)}\n",
    "\n",
    "for doc in docs:\n",
    "    for ann in doc['annotations']:\n",
    "        for _class, val in ann['meta_anns'].items():\n",
    "            class_counts[_class][val['value']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'Experiencer': defaultdict(<class 'int'>, {'patient': 12451, 'other': 100}),\n",
      "  'Negation': defaultdict(<class 'int'>,\n",
      "                          { 'negated': 1760,\n",
      "                            'not negated': 10791}),\n",
      "  'Temporality': defaultdict(<class 'int'>,\n",
      "                             { 'historical': 511,\n",
      "                               'hypothetical': 109,\n",
      "                               'recent': 11931})}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(class_counts, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(relevant_docs_hypothetical), len(relevant_docs_experiencer)\n",
    "#relevant_docs_hypothetical[0]['text'][0:110]\n",
    "#[(d['start'],d['end'], d['id']) for d in relevant_docs_hypothetical[0]['annotations'] \n",
    "#        if d['meta_anns']['Temporality']['value']=='hypothetical']\n",
    "#relevant_docs_hypothetical[0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections = [\n",
    "    {'doc_id': 'DL1616', 'annotation_id': 1873, 'meta': 'Experiencer', 'value': 'patient'},\n",
    "    {'doc_id': 'DL1139', 'annotation_id': 108, 'meta': 'Experiencer', 'value': 'patient'},\n",
    "    {'doc_id': 'GP2799', 'annotation_id': 8210, 'meta': 'Experiencer', 'value': 'patient'},\n",
    "    {'doc_id': 'SP1476', 'annotation_id': 15532, 'meta': 'Experiencer', 'value': 'patient'},\n",
    "    {'doc_id': 'DL1567', 'annotation_id': 1694, 'meta': 'Temporality', 'value': 'historical'},\n",
    "    {'doc_id': 'DL1711', 'annotation_id': 2232, 'meta': 'Temporality', 'value': 'recent'},\n",
    "    {'doc_id': 'DL1812', 'annotation_id': 2232, 'meta': 'Temporality', 'value': 'historical'},\n",
    "    {'doc_id': 'DL1814', 'annotation_id': 2703, 'meta': 'Temporality', 'value': 'historical'},\n",
    "    {'doc_id': 'GP1395', 'annotation_id': 4538, 'meta': 'Temporality', 'value': 'recent'},\n",
    "    {'doc_id': 'DL2111', 'annotation_id': 3779, 'meta': 'Temporality', 'value': 'historical'},\n",
    "    {'doc_id': 'DL2100', 'annotation_id': 3716, 'meta': 'Temporality', 'value': 'historical'},  \n",
    "    {'doc_id': 'DL2100', 'annotation_id': 3716, 'meta': 'Temporality', 'value': 'historical'},  \n",
    "    {'doc_id': 'DL2072', 'annotation_id': 3627, 'meta': 'Temporality', 'value': 'historical'},    \n",
    "    {'doc_id': 'DL2067', 'annotation_id': 3606, 'meta': 'Temporality', 'value': 'historical'},\n",
    "    {'doc_id': 'DL1931', 'annotation_id': 3113, 'meta': 'Temporality', 'value': 'historical'},\n",
    "    {'doc_id': 'DL1812', 'annotation_id': 2689, 'meta': 'Temporality', 'value': 'historical'},\n",
    "    {'doc_id': 'DL1507', 'annotation_id': 1467, 'meta': 'Temporality', 'value': 'historical'},\n",
    "    {'doc_id': 'DL1167', 'annotation_id': 212, 'meta': 'Temporality', 'value': 'historical'},\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the docs\n",
    "update_docs = docs.copy()\n",
    "for c in corrections:\n",
    "    for d in update_docs:        \n",
    "        if d['name']==c['doc_id']:\n",
    "            d['source'] = 'EMC_DCC_ORIGINAL_ADJUSTED'\n",
    "            for a in d['annotations']:\n",
    "                if a['id']==c['annotation_id']:\n",
    "                    a['meta_anns'][c['meta']]['value'] = c['value']\n",
    "# put updated docs in DCC\n",
    "DCC['projects'][0]['documents'] = update_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write DCC back to json \n",
    "with open('../data/emc-dcc_ann_ADJ.json', 'w') as f:\n",
    "    json.dump(DCC, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_docs_hypothetical = []\n",
    "for i, doc in enumerate(docs):\n",
    "    for concept in doc['annotations']:\n",
    "        if (concept['meta_anns']['Temporality']['value']=='hypothetical'):\n",
    "            doc['index'] = i\n",
    "            relevant_docs_hypothetical.append(doc)\n",
    "            break\n",
    "        \n",
    "relevant_docs_experiencer = []\n",
    "for i, doc in enumerate(docs):\n",
    "    for concept in doc['annotations']:\n",
    "        if (concept['meta_anns']['Experiencer']['value']=='other'):\n",
    "            doc['index'] = i\n",
    "            relevant_docs_experiencer.append(doc)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OAI_ASYNC_CLIENT = AsyncOpenAI(api_key=os.getenv(\"OPENAI_KEY\"), max_retries=2)\n",
    "OAI_CLIENT = OpenAI(api_key=os.getenv(\"OPENAI_KEY\"), max_retries=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_HYPOTHETICAL = \"\"\"\n",
    "    Je bent een kritische assistent die mij helpt om nieuwe tekst te bedenken.\n",
    "    De tekst moeten voldoen aan de volgende eisen:\n",
    "    - ze moeten semantisch correct zijn en vergelijkbaar zijn met de voorbeeltekst die ik je geef.\n",
    "    - de voorbeeltekst wordt voorafgegaan door de term VOORBEELDTEKST\n",
    "    - in de voorbeeldzin worden 1 of meer concepten benoemd die hypothethisch zijn, het is belangrijk\n",
    "    dat deze concepten in de nieuwe zin ook hypothetisch zijn, het mogen ook andere concepten zijn. \n",
    "    Een voorbeeld van een hypothetische concept = 'een voorafgaand trauma kan niet worden herinnerd', waarin 'trauma' het concept is.\n",
    "    Een ander voorbeeld = 'ter uitsluiting van epifysaire dysplasie' waarin 'epifysaire dysplasie' het concept is.\n",
    "    - de concepten die je moet vervangen zijn aangegeven met verticale streepjes, dus |concept|.\n",
    "    - het domein is medisch dus gebruik medische concepten.\n",
    "    - probeer de medische concepten te varieren, dus gebruik niet steeds dezelfde concepten.\n",
    "    - geef als antwoord ALLEEN de nieuw gegenereerde zinnen, voorafgaand met de term NIEUWE_TEKST\n",
    "    - in de NIEUWE_TEKST, plaats de concepten die hypothetisch zijn tussen verticale streepjes, dus '|', \n",
    "    dus bijvoorbeeld: 'ter uitsluiting van |epifysaire dysplasie|'\n",
    "    \n",
    "In case you have doubts:\n",
    "'Hypothetical' is specifically about (theoretical) concepts, which means concepts that are not (yet) realized OR\n",
    "concepts that may have occurred in the past. 'Historical' and 'Recent' can be used for realized concepts, in which we also include their negations. \n",
    "I.e. if a concept is explicitly denied historically or recently, we can label it as 'Historical' or 'Recent' respectively.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "SYSTEM_PROMPT_EXPERIENCER = \"\"\"\n",
    "    Je bent een kritische assistent die mij helpt om nieuwe text te bedenken.\n",
    "    Deze text moeten voldoen aan de volgende eisen:\n",
    "    - het moet semantisch correct zijn en vergelijkbaar zijn met de text die ik je geef.\n",
    "    - de voorbeeldtext wordt voorafgegaan door de term VOORBEELDTEKST\n",
    "    - in de voorbeeldtext worden 1 of meer concepten benoemd die verwijzen naar een persoon anders dan de patient, het is belangrijk\n",
    "    dat deze concepten in de nieuwe zin ook verwijzen naar iemand anders dan de patient (zoals een familielid), \n",
    "    het mogen ook andere medische concepten zijn.\n",
    "    - de concepten die je moet vervangen zijn aangegeven met verticale streepjes, dus |concept|.\n",
    "    - Een voorbeeld van een concept wat verwijst naar een ander persoon dan de patient =\n",
    "    'Een zusje van #Name# is elders operatief behandeld in verband met recidiverende patella luxaties', waarin 'luxaties' het concept is, en er \n",
    "    wordt verwezen naar de zus van de patient.    \n",
    "    - het domein is medisch dus gebruik medische concepten.\n",
    "    - probeer de medische concepten te varieren, dus gebruik niet steeds dezelfde concepten.\n",
    "    - varieer de ziektebeelden\n",
    "    - varieer de opmaak van de text, dus gebruik niet steeds dezelfde opmaak.\n",
    "    - geef als antwoord ALLEEN de nieuw gegenereerde text, voorafgaand met de term NIEUWE_TEKST\n",
    "    - in de NIEUWE_TEKST, plaats alleen de concepten die verwijzen naar een ander persoon dan de patient tussen tussen verticale streepjes |, \n",
    "    dus bijvoorbeeld: 'Een zusje van #Name# is elders operatief behandeld in verband met recidiverende patella |luxaties|'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_res(USER_TEXT='Good day', \n",
    "                 SYSTEM_PROMPT=SYSTEM_PROMPT_HYPOTHETICAL, \n",
    "                 n = 10,\n",
    "                 MODEL=\"gpt-4\"):\n",
    "    return OAI_CLIENT.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            n = n,\n",
    "            messages=[\n",
    "                        {\"role\": \"system\",\n",
    "                        \"content\": SYSTEM_PROMPT\n",
    "                        },\n",
    "                        {\"role\": \"user\", \n",
    "                        \"content\": USER_TEXT\n",
    "                        }],\n",
    "            stream=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_VERSION = 'gpt-4-1106-preview'\n",
    "CURRENT_DATE = datetime.datetime.now().strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re_extract = re.compile(r'NIEUWE_ZIN\\:(.*)')\n",
    "if run_temporality:\n",
    "    nieuwe_zinnen_hypothetisch = []\n",
    "    for i, doc in tqdm(enumerate(relevant_docs_hypothetical)):\n",
    "        EXAMPLE = doc['text'].replace('|', ' ')\n",
    "        # add | vertical bars around the concept that needs to be replaced\n",
    "        LOCS = [(d['start'],d['end']) for d in doc['annotations'] \n",
    "                    if d['meta_anns']['Temporality']['value']=='hypothetical']\n",
    "        for loc in LOCS:\n",
    "            EXAMPLE = EXAMPLE[:loc[0]] + '|' + EXAMPLE[loc[0]:loc[1]] + '|' + EXAMPLE[loc[1]:]\n",
    "        \n",
    "        res = get_chat_res(SYSTEM_PROMPT=SYSTEM_PROMPT_HYPOTHETICAL, \n",
    "                        n=10,\n",
    "                        MODEL=GPT_VERSION, # gpt-3.5-turbo-instruct-0914\n",
    "                        USER_TEXT=\"VOORBEELDTEKST: \" + EXAMPLE)\n",
    "\n",
    "        for j, _res in enumerate(res.choices):\n",
    "            txt = _res.message.content\n",
    "            nieuwe_zinnen_hypothetisch.append((\n",
    "                doc['name'],\n",
    "                'hypothetical',\n",
    "                j,\n",
    "                txt[txt.find('NIEUWE_TEKST')+12:].strip()))    \n",
    "    \n",
    "    hypothetical_df = pd.DataFrame(nieuwe_zinnen_hypothetisch, columns=['doc_id', 'class_value', 'synth_num', 'text'])\n",
    "    hypothetical_df.to_parquet(f'../data/synth_temporality_{GPT_VERSION.replace(\"-\", \"_\")}_{CURRENT_DATE}.parquet')\n",
    "else:\n",
    "    hypothetical_df = pd.read_parquet(hypothetical_file)\n",
    "    hypothetical_df['class_value'] = 'hypothetical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re_extract = re.compile(r'NIEUWE_ZIN\\:(.*)')\n",
    "if run_experiencer:\n",
    "    nieuwe_zinnen_experiencer = []\n",
    "    for i, doc in tqdm(enumerate(relevant_docs_experiencer)):\n",
    "        EXAMPLE = doc['text'].replace('|', ' ')\n",
    "        # add | vertical bars around the concept that needs to be replaced\n",
    "        LOCS = [(d['start'],d['end']) for d in doc['annotations'] \n",
    "                    if d['meta_anns']['Experiencer']['value']=='other']\n",
    "        for loc in LOCS:\n",
    "            EXAMPLE = EXAMPLE[:loc[0]] + '|' + EXAMPLE[loc[0]:loc[1]] + '|' + EXAMPLE[loc[1]:]\n",
    "        \n",
    "        res = get_chat_res(SYSTEM_PROMPT=SYSTEM_PROMPT_EXPERIENCER, \n",
    "                        n=10,\n",
    "                        MODEL=GPT_VERSION, # gpt-3.5-turbo-instruct-0914\n",
    "                        USER_TEXT=\"VOORBEELDTEKST: \" + EXAMPLE)\n",
    "\n",
    "        for j, _res in enumerate(res.choices):\n",
    "            txt = _res.message.content\n",
    "            nieuwe_zinnen_experiencer.append((\n",
    "                doc['name'],\n",
    "                'other',\n",
    "                j,\n",
    "                txt[txt.find('NIEUWE_TEKST')+12:].strip()))\n",
    "    experiencer_df = pd.DataFrame(nieuwe_zinnen_experiencer, columns=['doc_id', 'class_value', 'synth_num', 'text'])\n",
    "    experiencer_df.to_parquet(f'../data/synth_experiencer_{GPT_VERSION.replace(\"-\", \"_\")}.parquet')\n",
    "else:\n",
    "    experiencer_df = pd.read_parquet(experiencer_file)\n",
    "    experiencer_df['class_value'] = 'other'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the spans from the synthetic set and add them to the original dataset with an additional label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_in_dict(data, original_documents, Class_name='Experiencer', Class_value=None):\n",
    "    new_documents = original_documents.copy()\n",
    "    \n",
    "    if type(data)==pd.DataFrame:\n",
    "        data = [(r.doc_id, r.class_value, r.synth_num, r.text)  for r in data.itertuples()]\n",
    "    \n",
    "    for i, (name, Class_value_spec, subid, text) in enumerate(data):\n",
    "        Class_value_spec = Class_value_spec if Class_value_spec is not None else Class_value\n",
    "        \n",
    "        _doc = {\n",
    "            'id': i,\n",
    "            'source': 'synthetic',\n",
    "            'source_version': f\"{GPT_VERSION}|{CURRENT_DATE}\",     \n",
    "            'name': f\"{name}|synth|{subid}\",\n",
    "            'text': text.replace('|', ''),\n",
    "            'annotations' : []\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            for match in re.finditer('\\|[A-zÀ-ÿ\\s]+\\|', text):\n",
    "                start, end = match.span()\n",
    "                start += 1\n",
    "                end -= 1\n",
    "                _doc['annotations'].append(\n",
    "                            {\n",
    "                                'id': 1,\n",
    "                                'user': 'emc_dcc_synth',\n",
    "                                'cui': 1,\n",
    "                                'start': start,\n",
    "                                'end': end,\n",
    "                                'value': text[start:end],\n",
    "                                'validated': False,\n",
    "                                'correct': True,\n",
    "                                'alternative': False,\n",
    "                                'killed': False,\n",
    "                                'meta_anns': {\n",
    "                                    Class_name: {'value': Class_value_spec,\n",
    "                                                    'name': Class_name,\n",
    "                                                    'validated': False,\n",
    "                                                    'acc': 1.0\n",
    "                                                    },\n",
    "                                }            \n",
    "                            }\n",
    "                        )         \n",
    "        except:\n",
    "            print(i, text)\n",
    "        new_documents.append(_doc)\n",
    "    return new_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiencer_df = experiencer_df[['doc_id', 'class_value', 'synth_num', 'text']]\n",
    "hypothetical_df = hypothetical_df[['doc_id', 'class_value', 'synth_num', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_docs_experiencer = put_in_dict(experiencer_df, update_docs, Class_name='Experiencer', Class_value='other')\n",
    "new_docs_temporality = put_in_dict(hypothetical_df, new_docs_experiencer, Class_name='Temporality', Class_value='hypothetical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 689,\n",
       " 'source': 'synthetic',\n",
       " 'source_version': 'gpt-4-1106-preview|20231218',\n",
       " 'name': 'SP2114|synth|9',\n",
       " 'text': ': Geen symptomen die duiden op colitis ulcerosa of intestinale metaplasie.\\nGeen tekenen van colitis ulcerosa waargenomen. Advies: Bij aanhoudende onzekerheid over de intestinale metaplasie een elektieve gastroscopie overwegen na overleg.',\n",
       " 'annotations': [{'id': 1,\n",
       "   'user': 'emc_dcc_synth',\n",
       "   'cui': 1,\n",
       "   'start': 32,\n",
       "   'end': 48,\n",
       "   'value': 'colitis ulcerosa',\n",
       "   'validated': False,\n",
       "   'correct': True,\n",
       "   'alternative': False,\n",
       "   'killed': False,\n",
       "   'meta_anns': {'Temporality': {'value': 'hypothetical',\n",
       "     'name': 'Temporality',\n",
       "     'validated': False,\n",
       "     'acc': 1.0}}},\n",
       "  {'id': 1,\n",
       "   'user': 'emc_dcc_synth',\n",
       "   'cui': 1,\n",
       "   'start': 54,\n",
       "   'end': 76,\n",
       "   'value': 'intestinale metaplasie',\n",
       "   'validated': False,\n",
       "   'correct': True,\n",
       "   'alternative': False,\n",
       "   'killed': False,\n",
       "   'meta_anns': {'Temporality': {'value': 'hypothetical',\n",
       "     'name': 'Temporality',\n",
       "     'validated': False,\n",
       "     'acc': 1.0}}},\n",
       "  {'id': 1,\n",
       "   'user': 'emc_dcc_synth',\n",
       "   'cui': 1,\n",
       "   'start': 97,\n",
       "   'end': 113,\n",
       "   'value': 'colitis ulcerosa',\n",
       "   'validated': False,\n",
       "   'correct': True,\n",
       "   'alternative': False,\n",
       "   'killed': False,\n",
       "   'meta_anns': {'Temporality': {'value': 'hypothetical',\n",
       "     'name': 'Temporality',\n",
       "     'validated': False,\n",
       "     'acc': 1.0}}},\n",
       "  {'id': 1,\n",
       "   'user': 'emc_dcc_synth',\n",
       "   'cui': 1,\n",
       "   'start': 173,\n",
       "   'end': 195,\n",
       "   'value': 'intestinale metaplasie',\n",
       "   'validated': False,\n",
       "   'correct': True,\n",
       "   'alternative': False,\n",
       "   'killed': False,\n",
       "   'meta_anns': {'Temporality': {'value': 'hypothetical',\n",
       "     'name': 'Temporality',\n",
       "     'validated': False,\n",
       "     'acc': 1.0}}}]}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_docs_temporality[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write new samples to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCC['projects'][0]['documents'] = new_docs_temporality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write DCC back to json \n",
    "with open('../data/emc-dcc_ann_Augmented.json', 'w') as f:\n",
    "    json.dump(DCC, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate English corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* English -- BioScope; [HF](https://huggingface.co/datasets/bigbio/bioscope), [src](https://rgai.inf.u-szeged.hu/downloads)\n",
    "* English -- [Genia](http://www.geniaproject.org/genia-corpus/term-corpus)\n",
    "* English -- Sherlock, SFU review corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
