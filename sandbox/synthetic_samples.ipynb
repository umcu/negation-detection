{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a dataset (DCC) with a shortage of certain labels. We want to generate \n",
    "new samples synthetically using GPT-4. We will use the following approach:\n",
    "1. We take the existing samples for each document type and present these to GPT-4\n",
    "2. we ask to generate new sentences like it, where the token labels are provided in the BIO format\n",
    "\n",
    "We care specifically about the following labels:\n",
    "* Experiencer: Other\n",
    "* Historical: Hypothetical\n",
    "\n",
    "The task of the GPT model is to generate new sentences that are similar to the input sentences but with variations of the medical concepts. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions\n",
    "The definitions are taken from the ConText/ConTextD papers:\n",
    "\n",
    "## Negation\n",
    "\n",
    "This property has two values, ‘Negated’ or ‘Not negated’. A clinical condition or term is labeled as ‘Negated’ if there is evidence in the text suggesting that the condition does not occur or exist, e.g., ‘There was no sign of sinus infection’, otherwise it is ‘Not negated’.\n",
    "\n",
    "## Temporality\n",
    "\n",
    "The temporality property places a condition along a time line. There are three possible values for this property: ‘Recent’, ‘Historical’, and ‘Hypothetical’. A condition is considered ‘Recent’ if it is maximally 2 weeks old. Conditions that developed more than 2 weeks ago are labeled as ‘Historical’. A condition is labeled as ‘Hypothetical’ if it is not ‘Recent’ or ‘Historical’, e.g., ‘patient should return if she develops fever’ [13].\n",
    "\n",
    "**Adaptation**: *'Hypothetical' is specifically about (theoretical) concepts, concepts that are not (yet) realized, i.e. concepts that may materialize in the future. 'Historical' and 'Recent' can be used for realized concepts, in which we also include their negations. I.e. if a concept is explicitly denied historically or recently, we can label it as 'Historical' or 'Recent' respectively.*\n",
    "\n",
    "## Experiencer\n",
    "\n",
    "Clinical text may refer to subjects other than the actual patient. The experiencer property describes whether the patient experienced the condition or someone else. For simplicity, we have defined only two possible values for this property: ‘Patient’ or ‘Other’, where ‘Other’ refers to anyone but the actual patient, e.g., ‘Mother is recently diagnosed with cancer’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, re\n",
    "import json, dotenv\n",
    "import pprint\n",
    "\n",
    "import openai\n",
    "import asyncio\n",
    "from openai import AsyncOpenAI, OpenAI\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from utils import preprocess_dcc_for_robbert\n",
    "from utils import active_synthesis\n",
    "from utils import synthesis_prompts\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_temporality = True\n",
    "run_experiencer = True\n",
    "#run_historical = True\n",
    "experiencer_file = '../data/synth_experiencer_gpt_4_1106_preview_20231214.parquet'\n",
    "hypothetical_file = '../data/synth_temporality_gpt_4_1106_preview_20231218.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCC = json.load(open('../data/emc-dcc_ann.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_dcc = DCC.copy()\n",
    "for c in update_dcc['projects'][0]['documents']:\n",
    "    c['source'] = 'EMC_DCC_ORIGINAL'\n",
    "with open('../data/emc-dcc_ann_ORIGNAL.json', 'w') as f:\n",
    "    json.dump(update_dcc, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = update_dcc['projects'][0]['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_counts(docs: dict):\n",
    "    class_counts = {'Negation': defaultdict(int),\n",
    "                'Temporality': defaultdict(int),\n",
    "                'Experiencer': defaultdict(int)}\n",
    "\n",
    "    for doc in docs:\n",
    "        for ann in doc['annotations']:\n",
    "            for _class, val in ann['meta_anns'].items():\n",
    "                class_counts[_class][val['value']] += 1\n",
    "    return class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'Experiencer': defaultdict(<class 'int'>,\n",
      "                             { None: 5,\n",
      "                               'other': 97,\n",
      "                               'patient': 12449}),\n",
      "  'Negation': defaultdict(<class 'int'>,\n",
      "                          { 'negated': 1760,\n",
      "                            'not negated': 10791}),\n",
      "  'Temporality': defaultdict(<class 'int'>,\n",
      "                             { 'historical': 521,\n",
      "                               'hypothetical': 98,\n",
      "                               'recent': 11932})}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(get_class_counts(docs), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(relevant_docs_hypothetical), len(relevant_docs_experiencer)\n",
    "#relevant_docs_hypothetical[0]['text'][0:110]\n",
    "#[(d['start'],d['end'], d['id']) for d in relevant_docs_hypothetical[0]['annotations'] \n",
    "#        if d['meta_anns']['Temporality']['value']=='hypothetical']\n",
    "#relevant_docs_hypothetical[0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "Correction_of_original = active_synthesis.Annotation_correction_original\n",
    "Correction_of_synthetic = active_synthesis.Annotation_correction_synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the docs\n",
    "update_docs = docs.copy()\n",
    "for c in Correction_of_original:\n",
    "    for d in update_docs:        \n",
    "        if d['name']==c['doc_id']:\n",
    "            d['source'] = 'EMC_DCC_ORIGINAL_ADJUSTED'\n",
    "            for a in d['annotations']:\n",
    "                if a['id']==c['annotation_id']:\n",
    "                    a['meta_anns'][c['meta']]['value'] = c['value']\n",
    "# put updated docs in DCC\n",
    "DCC['projects'][0]['documents'] = update_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'Experiencer': defaultdict(<class 'int'>,\n",
      "                             { None: 5,\n",
      "                               'other': 97,\n",
      "                               'patient': 12449}),\n",
      "  'Negation': defaultdict(<class 'int'>,\n",
      "                          { 'negated': 1760,\n",
      "                            'not negated': 10791}),\n",
      "  'Temporality': defaultdict(<class 'int'>,\n",
      "                             { 'historical': 521,\n",
      "                               'hypothetical': 98,\n",
      "                               'recent': 11932})}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(get_class_counts(update_docs), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write DCC back to json \n",
    "with open('../data/emc-dcc_ann_ADJ.json', 'w') as f:\n",
    "    json.dump(DCC, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minority classes\n",
    "relevant_docs_hypothetical = []\n",
    "for i, doc in enumerate(update_docs):\n",
    "    for concept in doc['annotations']:\n",
    "        if (concept['meta_anns']['Temporality']['value']=='hypothetical'):\n",
    "            doc['index'] = i\n",
    "            relevant_docs_hypothetical.append(doc)\n",
    "            break\n",
    "        \n",
    "relevant_docs_other = []\n",
    "for i, doc in enumerate(update_docs):\n",
    "    for concept in doc['annotations']:\n",
    "        if (concept['meta_anns']['Experiencer']['value']=='other'):\n",
    "            doc['index'] = i\n",
    "            relevant_docs_other.append(doc)\n",
    "            break\n",
    "        \n",
    "relevant_docs_historical = []\n",
    "for i, doc in enumerate(update_docs):\n",
    "    for concept in doc['annotations']:\n",
    "        if (concept['meta_anns']['Temporality']['value']=='historical'):\n",
    "            doc['index'] = i\n",
    "            relevant_docs_historical.append(doc)\n",
    "            break\n",
    "\n",
    "relevant_docs_patient_names = [d.split(\"_\")[0] for d in active_synthesis.Experiencer_patient_ASL1]\n",
    "\n",
    "relevant_docs_patient = []\n",
    "\n",
    "for i, doc in enumerate(update_docs):\n",
    "    if doc['name'] in relevant_docs_patient_names:\n",
    "        relevant_docs_patient.append(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OAI_ASYNC_CLIENT = AsyncOpenAI(api_key=os.getenv(\"OPENAI_KEY\"), max_retries=2)\n",
    "OAI_CLIENT = OpenAI(api_key=os.getenv(\"OPENAI_KEY\"), max_retries=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_HYPOTHETICAL = synthesis_prompts.SYSTEM_PROMPT_HYPOTHETICAL\n",
    "SYSTEM_PROMPT_HYPOTHETICAL_CHECK = synthesis_prompts.SYSTEM_PROMPT_HYPOTHETICAL_CHECK\n",
    "\n",
    "SYSTEM_PROMPT_EXPERIENCER = synthesis_prompts.SYSTEM_PROMPT_EXPERIENCER\n",
    "SYSTEN_PROMPT_EXPERIENCER_CHECK = synthesis_prompts.SYSTEM_PROMPT_EXPERIENCER_CHECK\n",
    "\n",
    "SYSTEM_PROMPT_HISTORICAL = synthesis_prompts.SYSTEM_PROMPT_HISTORICAL\n",
    "SYSTEM_PROMPT_HISTORICAL_CHECK = synthesis_prompts.SYSTEM_PROMPT_HISTORICAL_CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_res(USER_TEXT='Good day', \n",
    "                 SYSTEM_PROMPT=\"Please be kind in 20 years\", \n",
    "                 n = 10,\n",
    "                 MODEL=\"gpt-4\"):\n",
    "    return OAI_CLIENT.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            n = n,\n",
    "            temperature=0.,\n",
    "            messages=[\n",
    "                        {\"role\": \"system\",\n",
    "                        \"content\": SYSTEM_PROMPT\n",
    "                        },\n",
    "                        {\"role\": \"user\", \n",
    "                        \"content\": USER_TEXT\n",
    "                        }],\n",
    "            stream=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_VERSION = 'gpt-4-1106-preview'\n",
    "CURRENT_DATE = datetime.datetime.now().strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re_extract = re.compile(r'NIEUWE_ZIN\\:(.*)')\n",
    "if run_temporality:\n",
    "    nieuwe_zinnen_hypothetisch = []\n",
    "    for i, doc in tqdm(enumerate(relevant_docs_hypothetical)):\n",
    "        EXAMPLE = doc['text'].replace('|', ' ')\n",
    "        # add | vertical bars around the concept that needs to be replaced\n",
    "        LOCS = [(d['start'],d['end']) for d in doc['annotations'] \n",
    "                    if d['meta_anns']['Temporality']['value']=='hypothetical']\n",
    "        for loc in LOCS:\n",
    "            EXAMPLE = EXAMPLE[:loc[0]] + '|' + EXAMPLE[loc[0]:loc[1]] + '|' + EXAMPLE[loc[1]:]\n",
    "        \n",
    "        res = get_chat_res(SYSTEM_PROMPT=SYSTEM_PROMPT_HYPOTHETICAL, \n",
    "                        n=10,\n",
    "                        MODEL=GPT_VERSION, # gpt-3.5-turbo-instruct-0914\n",
    "                        USER_TEXT=\"VOORBEELDTEKST: \" + EXAMPLE)\n",
    "\n",
    "        for j, _res in enumerate(res.choices):\n",
    "            txt = _res.message.content\n",
    "            nieuwe_zinnen_hypothetisch.append((\n",
    "                doc['name'],\n",
    "                'hypothetical',\n",
    "                j,\n",
    "                txt[txt.find('NIEUWE_TEKST')+12:].strip()))    \n",
    "    \n",
    "    hypothetical_df = pd.DataFrame(nieuwe_zinnen_hypothetisch, columns=['doc_id', 'class_value', 'synth_num', 'text'])\n",
    "    hypothetical_df.to_parquet(f'../data/synth_temporality_{GPT_VERSION.replace(\"-\", \"_\")}_{CURRENT_DATE}.parquet')\n",
    "else:\n",
    "    hypothetical_df = pd.read_parquet(hypothetical_file)\n",
    "    hypothetical_df['class_value'] = 'hypothetical'\n",
    "    hypothetical_df = hypothetical_df.assign(text=hypothetical_df.text.str.lstrip(to_strip=':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re_extract = re.compile(r'NIEUWE_ZIN\\:(.*)')\n",
    "if run_experiencer:\n",
    "    nieuwe_zinnen_experiencer = []\n",
    "    for i, doc in tqdm(enumerate(relevant_docs_other)):\n",
    "        EXAMPLE = doc['text'].replace('|', ' ')\n",
    "        # add | vertical bars around the concept that needs to be replaced\n",
    "        LOCS = [(d['start'],d['end']) for d in doc['annotations'] \n",
    "                    if d['meta_anns']['Experiencer']['value']=='other']\n",
    "        for loc in LOCS:\n",
    "            EXAMPLE = EXAMPLE[:loc[0]] + '|' + EXAMPLE[loc[0]:loc[1]] + '|' + EXAMPLE[loc[1]:]\n",
    "        \n",
    "        res = get_chat_res(SYSTEM_PROMPT=SYSTEM_PROMPT_EXPERIENCER, \n",
    "                        n=10,\n",
    "                        MODEL=GPT_VERSION, # gpt-3.5-turbo-instruct-0914\n",
    "                        USER_TEXT=\"VOORBEELDTEKST: \" + EXAMPLE)\n",
    "\n",
    "        for j, _res in enumerate(res.choices):\n",
    "            txt = _res.message.content\n",
    "            nieuwe_zinnen_experiencer.append((\n",
    "                doc['name'],\n",
    "                'other',\n",
    "                j,\n",
    "                txt[txt.find('NIEUWE_TEKST')+12:].strip()))\n",
    "    experiencer_df = pd.DataFrame(nieuwe_zinnen_experiencer, columns=['doc_id', 'class_value', 'synth_num', 'text'])\n",
    "    experiencer_df.to_parquet(f'../data/synth_experiencer_{GPT_VERSION.replace(\"-\", \"_\")}_{CURRENT_DATE}.parquet')\n",
    "else:\n",
    "    experiencer_df = pd.read_parquet(experiencer_file)\n",
    "    experiencer_df['class_value'] = 'other'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the checks\n",
    "def check_by_gpt(TXT: str='', \n",
    "                 N_checks: int=7,\n",
    "                 SYSTEM_PROMPT: str=\"Respect humans\"\n",
    "                 )->str:\n",
    "    N_checks = 7\n",
    "    maj_vote = N_checks//2\n",
    "\n",
    "    RES = get_chat_res(SYSTEM_PROMPT=SYSTEM_PROMPT,\n",
    "                        USER_TEXT=\"VOORBEELDTEKST: \" + TXT,\n",
    "                        n=N_checks,\n",
    "                        MODEL=GPT_VERSION)\n",
    "\n",
    "    RES_sel = []\n",
    "    no_count = defaultdict(int)\n",
    "    for j, _res in enumerate(RES.choices):\n",
    "        txt = _res.message.content\n",
    "        _d = eval(txt)\n",
    "        RES_sel.append((j, _d))\n",
    "        \n",
    "        list_lens = []\n",
    "        for k, v in _d.items():\n",
    "            if v=='nee':\n",
    "                no_count[k] += 1\n",
    "        \n",
    "        list_lens.append(len(_d.keys())) \n",
    "\n",
    "    if len(set(list_lens))>1:\n",
    "        return 'ERROR-checker concept count mismatch'\n",
    "    else:\n",
    "        if len(no_count.values())>0:    \n",
    "            # approach: if any of the concept is deemed incorrect we flag the TXT for removal \n",
    "            num_exc = sum([_v>maj_vote for _v in no_count.values()])\n",
    "            if num_exc>0:\n",
    "                if num_exc == len(_d.keys()):\n",
    "                    return False\n",
    "                else:\n",
    "                    spans = []                    \n",
    "                    for r in re.finditer(r'(\\|.*?\\|)', TXT):\n",
    "                        spans.append(r.span())  \n",
    "                    if len(spans)<max(_d.keys()):\n",
    "                        return 'ERROR-checker concept count mismatch'              \n",
    "                    rem = []\n",
    "                    for k, v in no_count.items():\n",
    "                        if v>maj_vote:\n",
    "                            print(spans, no_count)\n",
    "                            rem.append(spans[k])\n",
    "                    if len(rem)>0:\n",
    "                        for rcount, r in enumerate(rem):\n",
    "                            TXT = TXT[:r[0]-rcount*2]+\\\n",
    "                                TXT[r[0]+1-rcount*2:r[1]-1-rcount*2]+\\\n",
    "                                TXT[r[1]-rcount*2:]\n",
    "    return TXT\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_checked = [None]*experiencer_df.shape[0]\n",
    "texts = experiencer_df['text'].values\n",
    "for k, text in tqdm(enumerate(texts), total=len(texts)):\n",
    "    if texts_checked[k] is None:\n",
    "        texts_checked[k]=check_by_gpt(text, \n",
    "                                    N_checks=7, \n",
    "                                    SYSTEM_PROMPT=SYSTEM_PROMPT_EXPERIENCER_CHECK)\n",
    "experiencer_df['checked_text'] = texts_checked\n",
    "\n",
    "c1 = experiencer_df['checked_text']!=False \n",
    "c2 = experiencer_df['checked_text']!='ERROR-checker concept count mismatch'\n",
    "\n",
    "experiencer_df = experiencer_df[c1 & c2]\n",
    "\n",
    "# check token length\n",
    "experiencer_df['token_len'] = experiencer_df['checked_text'].astype(str)\\\n",
    "                            .progress_apply(lambda x: len(x.split()))\n",
    "\n",
    "# check number of r'\\|.*?\\|' in the text\n",
    "experiencer_df['n_concepts'] = experiencer_df['checked_text'].astype(str)\\\n",
    "                            .progress_apply(lambda x: len(re.findall(r'\\|.*?\\|', x)))\n",
    "                            \n",
    "c = experiencer_df['n_concepts']>0\n",
    "experiencer_df = experiencer_df[c]\n",
    "\n",
    "experiencer_df = experiencer_df.drop(['text'], axis=1)\n",
    "experiencer_df = experiencer_df.rename(columns={'checked_text': 'text'})\n",
    "experiencer_df.to_parquet(f'../data/synth_experiencer_{GPT_VERSION.replace(\"-\", \"_\")}_{CURRENT_DATE}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#texts_checked = [None]*hypothetical_df.shape[0]\n",
    "texts = hypothetical_df['text'].values\n",
    "for k, text in tqdm(enumerate(texts), total=len(texts)):\n",
    "    if texts_checked[k] is None:\n",
    "        texts_checked[k]=check_by_gpt(text, \n",
    "                                    N_checks=3, \n",
    "                                    SYSTEM_PROMPT=SYSTEM_PROMPT_HYPOTHETICAL_CHECK)\n",
    "hypothetical_df['checked_text'] = texts_checked\n",
    "\n",
    "c1 = hypothetical_df['checked_text']!=False \n",
    "c2 = hypothetical_df['checked_text']!='ERROR-checker concept count mismatch'\n",
    "\n",
    "hypothetical_df = hypothetical_df[c1 & c2]\n",
    "\n",
    "# check token length\n",
    "hypothetical_df['token_len'] = hypothetical_df['checked_text'].astype(str)\\\n",
    "                            .progress_apply(lambda x: len(x.split()))\n",
    "\n",
    "# check number of r'\\|.*?\\|' in the text\n",
    "hypothetical_df['n_concepts'] = hypothetical_df['checked_text'].astype(str)\\\n",
    "                            .progress_apply(lambda x: len(re.findall(r'\\|.*?\\|', x)))\n",
    "                            \n",
    "c = hypothetical_df['n_concepts']>0\n",
    "hypothetical_df = hypothetical_df[c]\n",
    "\n",
    "hypothetical_df = hypothetical_df.drop(['text'], axis=1)\n",
    "hypothetical_df = hypothetical_df.rename(columns={'checked_text': 'text'})\n",
    "hypothetical_df.to_parquet(f'../data/synth_hypothetical_{GPT_VERSION.replace(\"-\", \"_\")}_{CURRENT_DATE}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the spans from the synthetic set and add them to the original dataset with an additional label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_in_dict(data, original_documents, Class_name='Experiencer', Class_value=None):\n",
    "    max_id = max([int(k['id']) for d in update_docs\n",
    "                           for k in d['annotations'] if k['id'] is not None])\n",
    "    \n",
    "    new_documents = original_documents.copy()\n",
    "    \n",
    "    if type(data)==pd.DataFrame:\n",
    "        data = [(r.doc_id, r.class_value, r.synth_num, r.text)  for r in data.itertuples()]\n",
    "    \n",
    "    for i, (name, Class_value_spec, subid, text) in enumerate(data): # start=max_id+1\n",
    "        Class_value_spec = Class_value_spec if Class_value_spec is not None else Class_value\n",
    "        \n",
    "        if i == 0:\n",
    "            true_i = i + max_id + 1\n",
    "        else:\n",
    "            true_i = true_i + 1\n",
    "        \n",
    "        clean_text = text.replace('|', '')\n",
    "        _doc = {\n",
    "            'id': true_i,\n",
    "            'source': 'synthetic',\n",
    "            'source_version': f\"{GPT_VERSION}|{CURRENT_DATE}\",     \n",
    "            'name': f\"{name}|synth|{Class_name}|{subid}|{CURRENT_DATE}\",\n",
    "            'text': clean_text,\n",
    "            'annotations' : []\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            for concept_count, match in enumerate(re.finditer('\\|[A-zÀ-ÿ\\s]+\\|', text)):\n",
    "                start, end = match.span()\n",
    "                start_clean = start + 1 -1-concept_count*2 #  (+1,-1)  (+1,-3), (+1,-5), (+1,-7)...\n",
    "                end_clean = end - 1 -1-concept_count*2 # (-1,-1), (-1,-3), (-1,-5), (-1,-7)...\n",
    "                true_i = true_i + 1\n",
    "                _doc['annotations'].append(\n",
    "                            {\n",
    "                                'id': true_i,\n",
    "                                'user': 'emc_dcc_synth',\n",
    "                                'cui': 1,\n",
    "                                'start': start_clean,\n",
    "                                'end': end_clean,\n",
    "                                'value': text[start+1:end-1],\n",
    "                                'validated': False,\n",
    "                                'correct': True,\n",
    "                                'alternative': False,\n",
    "                                'killed': False,\n",
    "                                'meta_anns': {\n",
    "                                    Class_name: {'value': Class_value_spec,\n",
    "                                                    'name': Class_name,\n",
    "                                                    'validated': False,\n",
    "                                                    'acc': 1.0\n",
    "                                                    },\n",
    "                                }            \n",
    "                            }\n",
    "                        )         \n",
    "        except:\n",
    "            print(i, text)\n",
    "        new_documents.append(_doc)\n",
    "    return new_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiencer_df = pd.read_parquet('../data/synth_experiencer_gpt_4_1106_preview_20231214.parquet')\n",
    "#hypothetical_df = pd.read_parquet('../data/synth_temporality_gpt_4_1106_preview_20231218.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiencer_df = experiencer_df[['doc_id', 'class_value', 'synth_num', 'text']]\n",
    "hypothetical_df = hypothetical_df[['doc_id', 'class_value', 'synth_num', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_docs_experiencer = put_in_dict(experiencer_df, update_docs, \n",
    "                                   Class_name='Experiencer', \n",
    "                                   Class_value='other')\n",
    "new_docs_temporality = put_in_dict(hypothetical_df, new_docs_experiencer,\n",
    "                                   Class_name='Temporality', \n",
    "                                   Class_value='hypothetical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Negation': defaultdict(int, {'not negated': 10791, 'negated': 1760}),\n",
       " 'Temporality': defaultdict(int,\n",
       "             {'recent': 11932, 'historical': 521, 'hypothetical': 159}),\n",
       " 'Experiencer': defaultdict(int, {'patient': 12449, 'other': 773, None: 5})}"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_class_counts(new_docs_temporality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 150\n",
      "143 143\n"
     ]
    }
   ],
   "source": [
    "new_docs_temporality_copy = new_docs_temporality.copy()\n",
    "for c in Correction_of_synthetic:\n",
    "    for d in new_docs_temporality_copy:        \n",
    "        if c['doc_id'] in d['name']:\n",
    "            d['source'] = 'synthetic_ADJUSTED'\n",
    "            for a in d['annotations']:\n",
    "                if a['start']==c['start']:\n",
    "                    print(a['start'], c['start'])\n",
    "                    a['meta_anns'][c['meta']]['value'] = c['value']\n",
    "# put updated docs in DCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of annotations in original DCC: 17915\n",
      "Number of annotations in synthetic augmented DCC: 19219\n"
     ]
    }
   ],
   "source": [
    "max_id = max([int(k['id']) for d in update_docs\n",
    "                           for k in d['annotations'] if k['id'] is not None])\n",
    "\n",
    "print(f\"Number of annotations in original DCC: {max_id}\") \n",
    "\n",
    "max_id = max([int(k['id']) for d in new_docs_temporality_copy\n",
    "                           for k in d['annotations'] if k['id'] is not None])\n",
    "\n",
    "print(f\"Number of annotations in synthetic augmented DCC: {max_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write new samples to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCC['projects'][0]['documents'] = new_docs_temporality_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write DCC back to json \n",
    "with open('../data/emc-dcc_ann_Augmented_ASL1_Experiencer.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(DCC, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to DCC_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6045/6045 [00:00<00:00, 82810.71it/s]\n"
     ]
    }
   ],
   "source": [
    "texts, labels, ids = preprocess_dcc_for_robbert.get_tuples_from_medcat_json('../data/emc-dcc_ann_Augmented_ASL1_Experiencer.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Error, in GP1650|synth|Experiencer|4|20240207, for line:['T1', 'Other 126 135', 'hemofilie']\n",
      "Index Error, in GP1905|synth|Experiencer|1|20240207, for line:['T1', 'Other 162 191', 'chronische nierinsufficiëntie']\n",
      "Index Error, in GP1905|synth|Experiencer|3|20240207, for line:['T1', 'Other 146 157', 'osteoporose']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset, errors = preprocess_dcc_for_robbert.get_dataset(texts, labels, ids)\n",
    "\n",
    "# index error:\n",
    "# only one label, label for word at the end\n",
    "\n",
    "# Mismatch:\n",
    "# \\# preceding, part of compound\n",
    "\n",
    "len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tProcessed 6045 files\n"
     ]
    }
   ],
   "source": [
    "df, ids = preprocess_dcc_for_robbert.get_dataframe(dataset)\n",
    "print(f\"\\tProcessed {len(set(ids))} files\")\n",
    "df.to_csv(\"../data/DCC_df_ASL1_experiencer.csv\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Experiencer\n",
       "O          184116\n",
       "Patient     19676\n",
       "Other        1425\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Experiencer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Temporality\n",
       "O               185268\n",
       "Recent           18860\n",
       "Historical         822\n",
       "Hypothetical       267\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Temporality.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negation\n",
       "O             185378\n",
       "NotNegated     16781\n",
       "Negated         3058\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Negation.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate English corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* English -- BioScope; [HF](https://huggingface.co/datasets/bigbio/bioscope), [src](https://rgai.inf.u-szeged.hu/downloads)\n",
    "* English -- [Genia](http://www.geniaproject.org/genia-corpus/term-corpus)\n",
    "* English -- Sherlock, SFU review corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
