{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5fa31f8",
   "metadata": {},
   "source": [
    "Starting from a \n",
    "* pre-trained model with a \n",
    "* pre-trained tokenizer\n",
    "\n",
    "we perform finetuning on a negation task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "02705f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os \n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import device, cuda, version\n",
    "\n",
    "import apex\n",
    "\n",
    "import dcc_splitter as splitter\n",
    "import ner_training as trainer\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "from transformers import AutoTokenizer, RobertaTokenizer, AutoModelForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "67f132a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e2af5304",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = device(\"cuda:0\") if cuda.is_available() else device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "35e2d04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3fb57b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcc_dir = None\n",
    "output_dir = None\n",
    "skip_file = None\n",
    "n_splits = 2\n",
    "random_state = None\n",
    "base_folder = \"/media/koekiemonster/DATA-FAST/text_data/word_vectors_and_language_models/dutch/Medical/languagemodels\"\n",
    "output_folder = \"fine_tuned_token_classification\"\n",
    "mod_name = \"robbert-v2-dutch-base\" # \"robbert-v2-dutch-base\" # belabBERT_115k # bert-base-dutch\n",
    " \n",
    "\n",
    "args = namedtuple\n",
    "args.task = \"negation\" # experiencer, temporality\n",
    "args.model_path = os.path.join(base_folder, mod_name)\n",
    "args.model_type = \"roberta\" # bertje \n",
    "args.output_dir = os.path.join(base_folder, output_folder)\n",
    "args.num_epochs = 1\n",
    "args.eval_steps = 10 \n",
    "args.lr = 5e-5\n",
    "args.batch_size=16\n",
    "args.gradient_accumulation_steps=1\n",
    "args.block_size = 32 # block size determines inclusion \n",
    "args.save_model=False\n",
    "args.bio=True\n",
    "args.do_eval=False\n",
    "args.do_write=False\n",
    "args.bootstrap=False\n",
    "args.do_print_class_report=False\n",
    "\n",
    "random.seed(77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1c0ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.block_size determines how many text snippets are  used for training, see ner_training.py lines 118--141\n",
    "# obviously this is a code-design flaw that should be mended.\n",
    "# the dataset loader should  include the id_begin_end in the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5bafdb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dcc-splitter for folds\n",
    "dcc_splitter = splitter.DCCSplitter(dcc_dir, output_dir, skip_file, n_splits, random_state, write_to_file=False)\n",
    "splits = dcc_splitter.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4bcb19ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load NER DCC set\n",
    "dcc = pd.read_csv(\"../data/RobBERT/DCC_df.csv\", \n",
    "                  sep=\"\\t\", \n",
    "                  skip_blank_lines=True, \n",
    "                  engine=\"python\", \n",
    "                  encoding=\"latin-1\",\n",
    "                  on_bad_lines=\"warn\", \n",
    "                  keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ccc8b55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O             146395\n",
       "NotNegated     15713\n",
       "Negated         3017\n",
       "Name: Negation, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcc.Negation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3234908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Texts = dcc.groupby('Id').Word.apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "168c1938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Anamnese', 'O', 'O', 'O', 'O'],\n",
       "       [':', 'O', 'O', 'O', 'O'],\n",
       "       ['Op', 'O', 'O', 'O', 'O'],\n",
       "       ['04', 'O', 'O', 'O', 'O'],\n",
       "       ['.', 'O', 'O', 'O', 'O'],\n",
       "       ['03', 'O', 'O', 'O', 'O'],\n",
       "       ['.', 'O', 'O', 'O', 'O'],\n",
       "       ['95', 'O', 'O', 'O', 'O'],\n",
       "       ['liep', 'O', 'O', 'O', 'O'],\n",
       "       ['patient', 'O', 'O', 'O', 'O'],\n",
       "       ['een', 'O', 'O', 'O', 'O'],\n",
       "       ['enkelletsel', 'B', 'NotNegated', 'Patient', 'Recent'],\n",
       "       ['links', 'O', 'O', 'O', 'O'],\n",
       "       ['op', 'O', 'O', 'O', 'O'],\n",
       "       ['toen', 'O', 'O', 'O', 'O'],\n",
       "       ['hij', 'O', 'O', 'O', 'O'],\n",
       "       ['bij', 'O', 'O', 'O', 'O'],\n",
       "       ['het', 'O', 'O', 'O', 'O'],\n",
       "       ['korfballen', 'O', 'O', 'O', 'O'],\n",
       "       ['na', 'O', 'O', 'O', 'O'],\n",
       "       ['een', 'O', 'O', 'O', 'O'],\n",
       "       ['sprong', 'O', 'O', 'O', 'O'],\n",
       "       ['verkeerd', 'O', 'O', 'O', 'O'],\n",
       "       ['neerkwam', 'O', 'O', 'O', 'O'],\n",
       "       ['.', 'O', 'O', 'O', 'O'],\n",
       "       ['Het', 'O', 'O', 'O', 'O'],\n",
       "       ['letsel', 'B', 'NotNegated', 'Patient', 'Recent'],\n",
       "       ['was', 'O', 'O', 'O', 'O'],\n",
       "       ['hevig', 'O', 'O', 'O', 'O'],\n",
       "       ['pijnlijk', 'O', 'O', 'O', 'O'],\n",
       "       ['en', 'O', 'O', 'O', 'O'],\n",
       "       ['werd', 'O', 'O', 'O', 'O'],\n",
       "       ['conservatief', 'O', 'O', 'O', 'O'],\n",
       "       ['behandeld', 'O', 'O', 'O', 'O'],\n",
       "       ['4', 'O', 'O', 'O', 'O'],\n",
       "       ['weken', 'O', 'O', 'O', 'O'],\n",
       "       ['gipsimmobilisatie', 'O', 'O', 'O', 'O'],\n",
       "       [')', 'O', 'O', 'O', 'O'],\n",
       "       ['Na', 'O', 'O', 'O', 'O'],\n",
       "       ['dit', 'O', 'O', 'O', 'O'],\n",
       "       ['letsel', 'B', 'NotNegated', 'Patient', 'Recent'],\n",
       "       ['hield', 'O', 'O', 'O', 'O'],\n",
       "       ['patient', 'O', 'O', 'O', 'O'],\n",
       "       ['een', 'O', 'O', 'O', 'O'],\n",
       "       ['ernstige', 'O', 'O', 'O', 'O'],\n",
       "       ['dorsiflexiebeperking', 'O', 'O', 'O', 'O'],\n",
       "       ['.', 'O', 'O', 'O', 'O'],\n",
       "       ['Daarbij', 'O', 'O', 'O', 'O'],\n",
       "       ['werd', 'O', 'O', 'O', 'O'],\n",
       "       ['intra', 'O', 'O', 'O', 'O'],\n",
       "       ['-', 'O', 'O', 'O', 'O'],\n",
       "       ['articulaire', 'O', 'O', 'O', 'O'],\n",
       "       ['fibrose', 'B', 'NotNegated', 'Patient', 'Recent'],\n",
       "       ['gevonden', 'O', 'O', 'O', 'O'],\n",
       "       ['.', 'O', 'O', 'O', 'O'],\n",
       "       ['Onder', 'O', 'O', 'O', 'O'],\n",
       "       ['algehele', 'O', 'O', 'O', 'O'],\n",
       "       ['narcose', 'B', 'NotNegated', 'Patient', 'Recent'],\n",
       "       ['bleek', 'I', 'NotNegated', 'Patient', 'Recent'],\n",
       "       ['het', 'O', 'O', 'O', 'O'],\n",
       "       ['wel', 'O', 'O', 'O', 'O'],\n",
       "       ['mogelijk', 'O', 'O', 'O', 'O'],\n",
       "       ['15`', 'O', 'O', 'O', 'O'],\n",
       "       ['dorsaalflexie', 'O', 'O', 'O', 'O'],\n",
       "       ['te', 'O', 'O', 'O', 'O'],\n",
       "       ['bereiken', 'O', 'O', 'O', 'O'],\n",
       "       ['.', 'O', 'O', 'O', 'O'],\n",
       "       ['Er', 'O', 'O', 'O', 'O'],\n",
       "       ['zijn', 'O', 'O', 'O', 'O'],\n",
       "       ['duidelijke', 'O', 'O', 'O', 'O'],\n",
       "       ['startklachten', 'O', 'O', 'O', 'O'],\n",
       "       ['in', 'O', 'O', 'O', 'O'],\n",
       "       ['de', 'O', 'O', 'O', 'O'],\n",
       "       ['vorm', 'O', 'O', 'O', 'O'],\n",
       "       ['van', 'O', 'O', 'O', 'O'],\n",
       "       ['pijn', 'O', 'O', 'O', 'O'],\n",
       "       ['en', 'O', 'O', 'O', 'O'],\n",
       "       ['stijfheid', 'B', 'NotNegated', 'Patient', 'Recent'],\n",
       "       ['.', 'I', 'NotNegated', 'Patient', 'Recent'],\n",
       "       ['Revisie', 'O', 'O', 'O', 'O'],\n",
       "       ['CT', 'O', 'O', 'O', 'O'],\n",
       "       ['en', 'O', 'O', 'O', 'O'],\n",
       "       ['MRI', 'O', 'O', 'O', 'O'],\n",
       "       ['onderzoek', 'O', 'O', 'O', 'O'],\n",
       "       ['City', 'O', 'O', 'O', 'O'],\n",
       "       ['#', 'O', 'O', 'O', 'O'],\n",
       "       ['er', 'O', 'O', 'O', 'O'],\n",
       "       ['zijn', 'O', 'O', 'O', 'O'],\n",
       "       ['met', 'O', 'O', 'O', 'O'],\n",
       "       ['5', 'O', 'O', 'O', 'O'],\n",
       "       ['mm', 'O', 'O', 'O', 'O'],\n",
       "       ['coupes', 'O', 'O', 'O', 'O'],\n",
       "       ['vrij', 'O', 'O', 'O', 'O'],\n",
       "       ['grote', 'O', 'O', 'O', 'O'],\n",
       "       ['stappen', 'B', 'NotNegated', 'Patient', 'Recent'],\n",
       "       ['genomen', 'O', 'O', 'O', 'O'],\n",
       "       ['.', 'O', 'O', 'O', 'O'],\n",
       "       ['Conclusie', 'O', 'O', 'O', 'O'],\n",
       "       [':', 'O', 'O', 'O', 'O'],\n",
       "       ['Pijnklachten', 'O', 'O', 'O', 'O'],\n",
       "       ['linker', 'O', 'O', 'O', 'O'],\n",
       "       ['enkel', 'O', 'O', 'O', 'O'],\n",
       "       ['en', 'O', 'O', 'O', 'O'],\n",
       "       ['dorsiflexiebeperking', 'O', 'O', 'O', 'O'],\n",
       "       ['na', 'O', 'O', 'O', 'O'],\n",
       "       ['voorafgaand', 'O', 'O', 'O', 'O'],\n",
       "       ['trauma', 'B', 'NotNegated', 'Patient', 'Recent'],\n",
       "       ['.', 'I', 'NotNegated', 'Patient', 'Recent'],\n",
       "       ['Bespreking', 'O', 'O', 'O', 'O'],\n",
       "       [':', 'O', 'O', 'O', 'O'],\n",
       "       ['Samen', 'O', 'O', 'O', 'O'],\n",
       "       ['met', 'O', 'O', 'O', 'O'],\n",
       "       ['een', 'O', 'O', 'O', 'O'],\n",
       "       ['letsel', 'B', 'NotNegated', 'Patient', 'Recent'],\n",
       "       ['van', 'O', 'O', 'O', 'O'],\n",
       "       ['het', 'O', 'O', 'O', 'O'],\n",
       "       ['ligamentum', 'O', 'O', 'O', 'O'],\n",
       "       ['deltoideum', 'O', 'O', 'O', 'O'],\n",
       "       ['bestaat', 'O', 'O', 'O', 'O'],\n",
       "       ['ook', 'O', 'O', 'O', 'O'],\n",
       "       ['vaak', 'O', 'O', 'O', 'O'],\n",
       "       ['letsel', 'B', 'NotNegated', 'Patient', 'Recent'],\n",
       "       ['van', 'O', 'O', 'O', 'O'],\n",
       "       ['de', 'O', 'O', 'O', 'O'],\n",
       "       ['syndesmose', 'O', 'O', 'O', 'O'],\n",
       "       ['.', 'O', 'O', 'O', 'O']], dtype=object)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcc.loc[dcc.Id=='DL1795'][['Word', 'BIO', 'Negation', 'Experiencer', 'Temporality']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "52a64c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_ids = {'negation':{'B-Negated':0,'B-NotNegated':1,'I-Negated':2,'I-NotNegated':3},\n",
    "          'temporality':{'B-Recent':0,'B-Historical':1,'B-Hypothetical':2,'I-Recent':3,'I-Historical':4,'I-Hypothetical':5},\n",
    "          'experiencer':{'B-Patient':0,'B-Other':1,'I-Patient':2,'I-Other':3}}\n",
    "\n",
    "tag2id = tag_ids[args.task]\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017aa7e5",
   "metadata": {},
   "source": [
    "## Over all document sources\n",
    "\n",
    "improvement: only output best model based on validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2865323a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Some weights of the model checkpoint at /media/koekiemonster/DATA-FAST/text_data/word_vectors_and_language_models/dutch/Medical/languagemodels/robbert-v2-dutch-base were not used when initializing RobertaForTokenClassification: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at /media/koekiemonster/DATA-FAST/text_data/word_vectors_and_language_models/dutch/Medical/languagemodels/robbert-v2-dutch-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaConfig {\n",
      "  \"_name_or_path\": \"/media/koekiemonster/DATA-FAST/text_data/word_vectors_and_language_models/dutch/Medical/languagemodels/robbert-v2-dutch-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 40000\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 168/168 [03:33<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished, best model f = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [04:51, 291.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.853 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negated       0.88      0.87      0.88       477\n",
      "  NotNegated       0.81      0.89      0.85      2836\n",
      "\n",
      "   micro avg       0.82      0.89      0.85      3313\n",
      "   macro avg       0.85      0.88      0.86      3313\n",
      "weighted avg       0.82      0.89      0.85      3313\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /media/koekiemonster/DATA-FAST/text_data/word_vectors_and_language_models/dutch/Medical/languagemodels/robbert-v2-dutch-base were not used when initializing RobertaForTokenClassification: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at /media/koekiemonster/DATA-FAST/text_data/word_vectors_and_language_models/dutch/Medical/languagemodels/robbert-v2-dutch-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaConfig {\n",
      "  \"_name_or_path\": \"/media/koekiemonster/DATA-FAST/text_data/word_vectors_and_language_models/dutch/Medical/languagemodels/robbert-v2-dutch-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 40000\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 168/168 [03:33<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished, best model f = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [09:42, 291.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.845 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negated       0.83      0.86      0.85       480\n",
      "  NotNegated       0.81      0.89      0.85      2889\n",
      "\n",
      "   micro avg       0.81      0.88      0.85      3369\n",
      "   macro avg       0.82      0.87      0.85      3369\n",
      "weighted avg       0.81      0.88      0.85      3369\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# cycle through folds\n",
    "scores = []\n",
    "predlist = []\n",
    "test_lists = []\n",
    "loss_history = {}\n",
    "for idx, fold in tqdm(enumerate(splits)):\n",
    "    # re-init model for each fold, otherwise it keeps on training the same throughout all folds..\n",
    "    token_model = AutoModelForTokenClassification.from_pretrained(args.model_path, num_labels = len(tag2id))\n",
    "    \n",
    "    train_list, test_list = fold['train'], fold['test']\n",
    "    \n",
    "    ## eval is optional (to gauge the best number of steps/epochs)\n",
    "    eval_list = random.choices(train_list,k=int(len(train_list)/10)) if args.do_eval else []\n",
    "    eval_dcc = dcc.loc[dcc.Id.isin(eval_list)]\n",
    "    test_dcc = dcc.loc[dcc.Id.isin(test_list)]\n",
    "    train_dcc = dcc.loc[(dcc.Id.isin(train_list)) & (~dcc.Id.isin(eval_list))]\n",
    "    \n",
    "    test_list = test_dcc.Id.tolist()\n",
    "    eval_list = eval_dcc.Id.tolist()\n",
    "\n",
    "    ###\n",
    "    train_dataset = trainer.TextDatasetFromDataFrame(train_dcc, tokenizer, args) \n",
    "    test_dataset = trainer.TextDatasetFromDataFrame(test_dcc, tokenizer, args)\n",
    "    eval_dataset = trainer.TextDatasetFromDataFrame(eval_dcc, tokenizer, args)\n",
    "    \n",
    "    args.do_print_class_report=False\n",
    "    # Train on all document sources\n",
    "    trained_model, eval_loss_history = trainer.train_model(model=token_model.to(device), \n",
    "                                                            tokenizer=tokenizer, \n",
    "                                                            train_dataset=train_dataset, \n",
    "                                                            eval_dataset=eval_dataset, \n",
    "                                                            tag2id=tag2id,\n",
    "                                                            device=device, \n",
    "                                                            args=args,\n",
    "                                                            max_grad_norm=1.0,\n",
    "                                                            amp=False)\n",
    "    args.do_print_class_report=True\n",
    "    # Evaluate on all document sources\n",
    "    f1, prec, rec, preds, truth = trainer.eval_model(model=trained_model, \n",
    "                                       tokenizer=tokenizer, \n",
    "                                       eval_dataset=test_dataset, \n",
    "                                       tag2id=tag2id, \n",
    "                                       device=device, \n",
    "                                       args=args, \n",
    "                                       return_pred=True)\n",
    "    \n",
    "    loss_history[idx]=eval_loss_history\n",
    "    \n",
    "    test_ids = [\"_\".join(t) for t in zip(test_dcc.Id, test_dcc.Begin, test_dcc.End)]\n",
    "    scores.append({'fold': idx, 'f1': f1, 'precision': prec, 'recall': rec})\n",
    "    predlist.append({'fold': idx, 'prediction': preds, 'truth': truth, 'ids': test_ids})\n",
    "    test_lists.append(test_ids)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "466041d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predlist_prep = []\n",
    "for foldnum, foldres in enumerate(predlist):\n",
    "    cdx = 0\n",
    "    ids = foldres['ids']\n",
    "    for prs, trs in zip(foldres['prediction'], foldres['truth']):        \n",
    "        for pr, tr in zip(prs, trs):\n",
    "            tmp_dict={}\n",
    "            if len(pr)==len(tr)==0:\n",
    "                tmp_dict['fold'] = foldnum\n",
    "                tmp_dict['entity_id'] = ids[cdx]\n",
    "                tmp_dict['label'] = \"n/a\"\n",
    "                tmp_dict['robbert'] = \"n/a\"\n",
    "            elif len(pr)>0:\n",
    "                tmp_dict['fold'] = foldnum\n",
    "                tmp_dict['entity_id'] = ids[cdx]\n",
    "                tmp_dict['label'] = tr\n",
    "                tmp_dict['robbert'] = pr                \n",
    "            else:\n",
    "                raise ValueError(\"predictions are empty while truth is not\")    \n",
    "            cdx += 1\n",
    "            predlist_prep.append(tmp_dict)\n",
    "predlist_df = pd.DataFrame(predlist_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0bf603dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>entity_id</th>\n",
       "      <th>label</th>\n",
       "      <th>robbert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>DL1667_O_O</td>\n",
       "      <td>B-NotNegated</td>\n",
       "      <td>B-NotNegated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>DL1667_O_O</td>\n",
       "      <td>B-NotNegated</td>\n",
       "      <td>B-NotNegated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>DL1667_O_O</td>\n",
       "      <td>B-NotNegated</td>\n",
       "      <td>B-NotNegated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>DL1667_O_O</td>\n",
       "      <td>B-NotNegated</td>\n",
       "      <td>B-NotNegated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>DL1667_O_O</td>\n",
       "      <td>B-Negated</td>\n",
       "      <td>B-Negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10955</th>\n",
       "      <td>1</td>\n",
       "      <td>DL1448_O_O</td>\n",
       "      <td>B-NotNegated</td>\n",
       "      <td>B-NotNegated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10956</th>\n",
       "      <td>1</td>\n",
       "      <td>DL1448_O_O</td>\n",
       "      <td>B-Negated</td>\n",
       "      <td>B-Negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10957</th>\n",
       "      <td>1</td>\n",
       "      <td>DL1448_O_O</td>\n",
       "      <td>I-Negated</td>\n",
       "      <td>I-Negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10958</th>\n",
       "      <td>1</td>\n",
       "      <td>DL1448_O_O</td>\n",
       "      <td>B-NotNegated</td>\n",
       "      <td>B-NotNegated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10959</th>\n",
       "      <td>1</td>\n",
       "      <td>DL1448_O_O</td>\n",
       "      <td>I-NotNegated</td>\n",
       "      <td>I-NotNegated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10960 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fold   entity_id         label       robbert\n",
       "0         0  DL1667_O_O  B-NotNegated  B-NotNegated\n",
       "1         0  DL1667_O_O  B-NotNegated  B-NotNegated\n",
       "2         0  DL1667_O_O  B-NotNegated  B-NotNegated\n",
       "3         0  DL1667_O_O  B-NotNegated  B-NotNegated\n",
       "4         0  DL1667_O_O     B-Negated     B-Negated\n",
       "...     ...         ...           ...           ...\n",
       "10955     1  DL1448_O_O  B-NotNegated  B-NotNegated\n",
       "10956     1  DL1448_O_O     B-Negated     B-Negated\n",
       "10957     1  DL1448_O_O     I-Negated     I-Negated\n",
       "10958     1  DL1448_O_O  B-NotNegated  B-NotNegated\n",
       "10959     1  DL1448_O_O  I-NotNegated  I-NotNegated\n",
       "\n",
       "[10960 rows x 4 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predlist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ff4f85e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8ac68a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.do_eval:\n",
    "    dfl = []\n",
    "    for i in range(2):\n",
    "        df = pd.DataFrame(loss_history[i])\n",
    "        df['fold']=i\n",
    "        dfl.append(df)\n",
    "    eval_history = pd.concat(dfl).reset_index()\n",
    "    eval_history['step'] = eval_history['step'].astype(int)\n",
    "    eval_history['fold'] = eval_history['fold'].astype(int)\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=3, figsize=(18,5))\n",
    "    seaborn.lineplot(data=eval_history, x='step', y='f1', hue='epoch', ax=ax[0])\n",
    "    seaborn.lineplot(data=eval_history, x='step', y='recall', hue='epoch', ax=ax[1])\n",
    "    seaborn.lineplot(data=eval_history, x='step', y='precision', hue='epoch', ax=ax[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "85b6d764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold    f1  precision  recall\n",
       "0     0  0.78       0.73    0.82\n",
       "1     1  0.77       0.73    0.81"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# micro-averaged scores\n",
    "test_scores.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5fabec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "909081f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B-NotNegated, B-Negated\n",
    "labmap = {'B-NotNegated': False, 'B-Negated': True, 'I-NotNegated': False, 'I-Negated': True}\n",
    "\n",
    "manual_scores = []\n",
    "confusion_matrix = []\n",
    "for i in range(len(predlist)):\n",
    "    # accuracy over all documents, flattened\n",
    "    _predlist = [(labmap[t], 'B' if 'B-' in t else 'I') for l in predlist[i]['prediction'] for t in l if len(l)>0]\n",
    "    _truthlist = [(labmap[t], 'B' if 'B-' in t else 'I') for l in predlist[i]['truth'] for t in l if len(l)>0]\n",
    "\n",
    "    tr_c = []\n",
    "    pr_c = []\n",
    "    tr_r = []\n",
    "    pr_r = []\n",
    "\n",
    "    b_truth = []\n",
    "    b_pred = []\n",
    "    for _t,_p in zip(_truthlist, _predlist):\n",
    "        if _t[1]==_p[1]=='B':\n",
    "            tr_c.append(_t[0])\n",
    "            pr_c.append(_p[0])\n",
    "        tr_r.append(_t[0])\n",
    "        pr_r.append(_p[0])\n",
    "\n",
    "        b_truth.append(_t[1]=='B')\n",
    "        b_pred.append(_p[1]=='B')\n",
    "\n",
    "    tr_c, pr_c, tr_r, pr_r = np.array(tr_c), np.array(pr_c), np.array(tr_r), np.array(pr_r)\n",
    "    b_truth, b_pred = np.array(b_truth), np.array(b_pred)\n",
    "\n",
    "    TN_c = np.sum((pr_c==tr_c) & (pr_c==False))\n",
    "    TP_c = np.sum((pr_c==tr_c) & (pr_c==True))\n",
    "    FP_c = np.sum((pr_c!=tr_c) & (pr_c==True))\n",
    "    FN_c = np.sum((pr_c!=tr_c) & (pr_c==False))\n",
    "\n",
    "    TN_r = np.sum((pr_r==tr_r) & (pr_r==False))\n",
    "    TP_r = np.sum((pr_r==tr_r) & (pr_r==True))\n",
    "    FP_r = np.sum((pr_r!=tr_r) & (pr_r==True))\n",
    "    FN_r = np.sum((pr_r!=tr_r) & (pr_r==False))\n",
    "\n",
    "    TN_b = np.sum((b_pred==b_truth) & (b_pred==False))\n",
    "    TP_b = np.sum((b_pred==b_truth) & (b_pred==True))\n",
    "    FP_b = np.sum((b_pred!=b_truth) & (b_pred==True))\n",
    "    FN_b = np.sum((b_pred!=b_truth) & (b_pred==False))\n",
    "\n",
    "\n",
    "    # micro\n",
    "    f1 = f1_score(tr_r, pr_r, average='micro')\n",
    "    precision = precision_score(tr_r, pr_r, average='micro')\n",
    "    recall = recall_score(tr_r, pr_r, average='micro')\n",
    "    manual_scores.append({'list': 'raw', \n",
    "                          'fold': i, \n",
    "                          'focus': 'micro', \n",
    "                          'f1': f1, \n",
    "                          'precision': precision, \n",
    "                          'recall': recall})\n",
    "\n",
    "    # macro\n",
    "    f1 = f1_score(tr_r, pr_r, average='macro')\n",
    "    precision = precision_score(tr_r, pr_r, average='macro')\n",
    "    recall = recall_score(tr_r, pr_r, average='macro')\n",
    "    manual_scores.append({'list': 'raw', \n",
    "                          'fold': i, \n",
    "                          'focus': 'macro', \n",
    "                          'f1': f1, \n",
    "                          'precision': precision, \n",
    "                          'recall': recall})\n",
    "\n",
    "    # Negated\n",
    "    f1 = f1_score(tr_r, pr_r)\n",
    "    precision = precision_score(tr_r, pr_r)\n",
    "    recall = recall_score(tr_r, pr_r)\n",
    "    manual_scores.append({'list': 'raw', \n",
    "                          'fold': i, \n",
    "                          'focus': 'negated', \n",
    "                          'f1': f1, \n",
    "                          'precision': precision, \n",
    "                          'recall': recall})\n",
    "\n",
    "    # NotNegated\n",
    "    f1 = f1_score(~tr_r, ~pr_r)\n",
    "    precision = precision_score(~tr_r, ~pr_r)\n",
    "    recall = recall_score(~tr_r, ~pr_r)\n",
    "    manual_scores.append({'list': 'raw',\n",
    "                          'fold': i,\n",
    "                          'focus': 'notnegated', \n",
    "                          'f1': f1,\n",
    "                          'precision': precision,\n",
    "                          'recall': recall})\n",
    "    \n",
    "    confusion_matrix.append({'list': 'raw', 'fold': i, 'TN': TN_r, 'TP': TP_r, 'FN': FN_r, 'FP': FP_r})    \n",
    "    ######################################\n",
    "    # micro\n",
    "    f1 = f1_score(tr_c, pr_c, average='micro')\n",
    "    precision = precision_score(tr_c, pr_c, average='micro')\n",
    "    recall = recall_score(tr_c, pr_c, average='micro')\n",
    "    manual_scores.append({'list': 'clean', \n",
    "                          'fold': i, \n",
    "                          'focus': 'micro', \n",
    "                          'f1': f1, \n",
    "                          'precision': precision, \n",
    "                          'recall': recall})\n",
    "\n",
    "    # macro\n",
    "    f1 = f1_score(tr_c, pr_c, average='macro')\n",
    "    precision = precision_score(tr_c, pr_c, average='macro')\n",
    "    recall = recall_score(tr_c, pr_c, average='macro')\n",
    "    manual_scores.append({'list': 'clean', \n",
    "                          'fold': i, \n",
    "                          'focus': 'macro', \n",
    "                          'f1': f1, \n",
    "                          'precision': precision, \n",
    "                          'recall': recall})\n",
    "\n",
    "    # Negated\n",
    "    f1 = f1_score(tr_c, pr_c)\n",
    "    precision = precision_score(tr_c, pr_c)\n",
    "    recall = recall_score(tr_c, pr_c)\n",
    "    manual_scores.append({'list': 'clean', \n",
    "                          'fold': i, \n",
    "                          'focus': 'negated', \n",
    "                          'f1': f1, \n",
    "                          'precision': precision, \n",
    "                          'recall': recall})\n",
    "\n",
    "    # NotNegated\n",
    "    f1 = f1_score(~tr_c, ~pr_c)\n",
    "    precision = precision_score(~tr_c, ~pr_c)\n",
    "    recall = recall_score(~tr_c, ~pr_c)\n",
    "    manual_scores.append({'list': 'clean',\n",
    "                          'fold': i,\n",
    "                          'focus': 'notnegated', \n",
    "                          'f1': f1,\n",
    "                          'precision': precision,\n",
    "                          'recall': recall})\n",
    "    \n",
    "    confusion_matrix.append({'list': 'clean', 'fold': i, 'TN': TN_c, 'TP': TP_c, 'FN': FN_c, 'FP': FP_c})    \n",
    "    ######################################\n",
    "    # micro\n",
    "    f1 = f1_score(b_truth, b_pred, average='micro')\n",
    "    precision = precision_score(b_truth, b_pred, average='micro')\n",
    "    recall = recall_score(b_truth, b_pred, average='micro')\n",
    "    manual_scores.append({'list': 'B_I', \n",
    "                          'fold': i, \n",
    "                          'focus': 'micro', \n",
    "                          'f1': f1, \n",
    "                          'precision': precision, \n",
    "                          'recall': recall})\n",
    "\n",
    "    # macro\n",
    "    f1 = f1_score(b_truth, b_pred, average='macro')\n",
    "    precision = precision_score(b_truth, b_pred, average='macro')\n",
    "    recall = recall_score(b_truth, b_pred, average='macro')\n",
    "    manual_scores.append({'list': 'B_I', \n",
    "                          'fold': i, \n",
    "                          'focus': 'macro', \n",
    "                          'f1': f1, \n",
    "                          'precision': precision, \n",
    "                          'recall': recall})\n",
    "\n",
    "    # Negated\n",
    "    f1 = f1_score(b_truth, b_pred)\n",
    "    precision = precision_score(b_truth, b_pred)\n",
    "    recall = recall_score(b_truth, b_pred)\n",
    "    manual_scores.append({'list': 'B_I', \n",
    "                          'fold': i, \n",
    "                          'focus': 'negated', \n",
    "                          'f1': f1, \n",
    "                          'precision': precision, \n",
    "                          'recall': recall})\n",
    "\n",
    "    # NotNegated\n",
    "    f1 = f1_score(~b_truth, ~b_pred)\n",
    "    precision = precision_score(~b_truth, ~b_pred)\n",
    "    recall = recall_score(~b_truth, ~b_pred)\n",
    "    manual_scores.append({'list': 'B_I',\n",
    "                          'fold': i,\n",
    "                          'focus': 'notnegated', \n",
    "                          'f1': f1,\n",
    "                          'precision': precision,\n",
    "                          'recall': recall})\n",
    "    \n",
    "    confusion_matrix.append({'list': 'B_I', 'fold': i, 'TN': TN_b, 'TP': TP_b, 'FN': FN_b, 'FP': FP_b})    \n",
    "    \n",
    "manual_scores_df = pd.DataFrame(data=manual_scores)\n",
    "confusion_matrix_df = pd.DataFrame(data=confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6fe90a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>list</th>\n",
       "      <th>focus</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">B_I</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.877621</td>\n",
       "      <td>0.946072</td>\n",
       "      <td>0.842040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.912538</td>\n",
       "      <td>0.912538</td>\n",
       "      <td>0.912538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negated</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.942962</td>\n",
       "      <td>0.892145</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notnegated</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.812281</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.684080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">clean</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.679240</td>\n",
       "      <td>0.943027</td>\n",
       "      <td>0.635483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.890426</td>\n",
       "      <td>0.890426</td>\n",
       "      <td>0.890426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negated</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.418976</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.270966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notnegated</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.939503</td>\n",
       "      <td>0.886054</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">raw</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.739898</td>\n",
       "      <td>0.934662</td>\n",
       "      <td>0.685291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.897227</td>\n",
       "      <td>0.897227</td>\n",
       "      <td>0.897227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negated</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.537619</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.372170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notnegated</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.942176</td>\n",
       "      <td>0.892052</td>\n",
       "      <td>0.998413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fold        f1  precision    recall\n",
       "list  focus                                          \n",
       "B_I   macro        0.5  0.877621   0.946072  0.842040\n",
       "      micro        0.5  0.912538   0.912538  0.912538\n",
       "      negated      0.5  0.942962   0.892145  1.000000\n",
       "      notnegated   0.5  0.812281   1.000000  0.684080\n",
       "clean macro        0.5  0.679240   0.943027  0.635483\n",
       "      micro        0.5  0.890426   0.890426  0.890426\n",
       "      negated      0.5  0.418976   1.000000  0.270966\n",
       "      notnegated   0.5  0.939503   0.886054  1.000000\n",
       "raw   macro        0.5  0.739898   0.934662  0.685291\n",
       "      micro        0.5  0.897227   0.897227  0.897227\n",
       "      negated      0.5  0.537619   0.977273  0.372170\n",
       "      notnegated   0.5  0.942176   0.892052  0.998413"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_scores_df.groupby(['list', 'focus']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "085803fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Diagnose : status na glasverwonding in de linkerpols met uitval van de nervus ulnaris . Er bleek toen sprake van een doorsnijding van de arteria ulnaris , de nervus ulnaris , de flexor carpi ulnaris en van beide flexoren van de pink , allen aan de linkerzijde . Bij onderzoek is er sprake van een litteken aan de ulnovolaire zijde van de pols , verlengd naar de onderarm . Er is ook duidelijk sprake van een atrofie van de abductor pollicis met een krachtsvermindering tot 1 / 5 van de normale kracht . De abductor digiti quinti heeft ook een duidelijk krachtsverlies . Van de atrofie van de kleine handspieren is met name die van de adductor pollicis het meest opvallend .'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Texts['DL1932']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c16f81",
   "metadata": {},
   "source": [
    "## Append to other results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3909f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_result_file = '../results/merged_results.csv.gz'\n",
    "results = pd.read_csv(merged_result_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0d2b801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_498924/2061256545.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  entities = results.entity_id.str.replace(r\"\\_[0-9]+\\_[0-9]+\", \"\").unique()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5365"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = results.entity_id.str.replace(r\"\\_[0-9]+\\_[0-9]+\", \"\").unique()\n",
    "len(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d67edca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_id</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>bilstm</th>\n",
       "      <th>bilstm_cv</th>\n",
       "      <th>rule_based</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DL1111_32_46</td>\n",
       "      <td>DL</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DL1111_272_280</td>\n",
       "      <td>DL</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DL1111_363_377</td>\n",
       "      <td>DL</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DL1112_22_28</td>\n",
       "      <td>DL</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DL1113_59_67</td>\n",
       "      <td>DL</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12546</th>\n",
       "      <td>SP2118_862_876</td>\n",
       "      <td>SP</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12547</th>\n",
       "      <td>SP2119_23_45</td>\n",
       "      <td>SP</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12548</th>\n",
       "      <td>SP2120_3_23</td>\n",
       "      <td>SP</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12549</th>\n",
       "      <td>SP2121_73_85</td>\n",
       "      <td>SP</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12550</th>\n",
       "      <td>SP2122_0_19</td>\n",
       "      <td>SP</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12551 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            entity_id category        label       bilstm    bilstm_cv  \\\n",
       "0        DL1111_32_46       DL  not negated  not negated  not negated   \n",
       "1      DL1111_272_280       DL  not negated  not negated  not negated   \n",
       "2      DL1111_363_377       DL  not negated  not negated  not negated   \n",
       "3        DL1112_22_28       DL      negated      negated      negated   \n",
       "4        DL1113_59_67       DL  not negated  not negated  not negated   \n",
       "...               ...      ...          ...          ...          ...   \n",
       "12546  SP2118_862_876       SP  not negated  not negated  not negated   \n",
       "12547    SP2119_23_45       SP      negated      negated      negated   \n",
       "12548     SP2120_3_23       SP  not negated  not negated  not negated   \n",
       "12549    SP2121_73_85       SP  not negated  not negated  not negated   \n",
       "12550     SP2122_0_19       SP  not negated  not negated  not negated   \n",
       "\n",
       "        rule_based  \n",
       "0      not negated  \n",
       "1      not negated  \n",
       "2      not negated  \n",
       "3          negated  \n",
       "4      not negated  \n",
       "...            ...  \n",
       "12546  not negated  \n",
       "12547      negated  \n",
       "12548  not negated  \n",
       "12549  not negated  \n",
       "12550  not negated  \n",
       "\n",
       "[12551 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
