{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5fa31f8",
   "metadata": {},
   "source": [
    "Starting from a \n",
    "* pre-trained model with a \n",
    "* pre-trained tokenizer\n",
    "\n",
    "we perform finetuning on a negation task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02705f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os \n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import device, cuda, version\n",
    "\n",
    "import apex\n",
    "\n",
    "import dcc_splitter as splitter\n",
    "import ner_training as trainer\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "from transformers import AutoTokenizer, RobertaTokenizer, AutoModelForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67f132a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2af5304",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koekiemonster/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:115.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "device = device(\"cuda:0\") if cuda.is_available() else device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35e2d04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fb57b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcc_dir = None\n",
    "output_dir = None\n",
    "skip_file = None\n",
    "n_splits = 10\n",
    "random_state = None\n",
    "base_folder = \"/media/koekiemonster/DATA-FAST/text_data/word_vectors_and_language_models/dutch/Medical/languagemodels\"\n",
    "output_folder = \"fine_tuned_token_classification\"\n",
    "mod_name = \"robbert-v2-dutch-base\" # \"robbert-v2-dutch-base\" # belabBERT_115k # bert-base-dutch\n",
    " \n",
    "\n",
    "args = namedtuple\n",
    "args.task = \"negation\" # experiencer, temporality\n",
    "args.model_path = os.path.join(base_folder, mod_name)\n",
    "args.model_type = \"roberta\" # bertje \n",
    "args.output_dir = os.path.join(base_folder, output_folder)\n",
    "args.num_epochs = 4\n",
    "args.eval_steps = 10 \n",
    "args.lr = 5e-5\n",
    "args.batch_size= 16\n",
    "args.gradient_accumulation_steps=1\n",
    "args.block_size = 512 # block size determines inclusion \n",
    "args.save_model=False\n",
    "args.bio=True\n",
    "args.do_eval=False\n",
    "args.do_write=False\n",
    "args.bootstrap=False\n",
    "args.do_print_class_report=False\n",
    "\n",
    "random.seed(77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb1c0ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.block_size determines how many text snippets are  used for training, see ner_training.py lines 118--141\n",
    "# obviously this is a code-design flaw that should be mended.\n",
    "# the dataset loader should  include the id_begin_end in the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bafdb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dcc-splitter for folds\n",
    "dcc_splitter = splitter.DCCSplitter(dcc_dir, output_dir, skip_file, n_splits, random_state, write_to_file=False)\n",
    "splits = dcc_splitter.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bcb19ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load NER DCC set\n",
    "dcc = pd.read_csv(\"../data/RobBERT/DCC_df.csv\", \n",
    "                  sep=\"\\t\", \n",
    "                  skip_blank_lines=True, \n",
    "                  engine=\"python\", \n",
    "                  encoding=\"latin-1\",\n",
    "                  on_bad_lines=\"warn\", \n",
    "                  keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccc8b55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O             146395\n",
       "NotNegated     15713\n",
       "Negated         3017\n",
       "Name: Negation, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcc.Negation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d71ec0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11882"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcc.loc[dcc.BIO!='O'][['Id', 'Begin', 'End']].apply(lambda x: \"_\".join(x), axis=1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3234908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Texts = dcc.groupby('Id').Word.apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52a64c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_ids = {'negation':{'B-Negated':0,'B-NotNegated':1,'I-Negated':2,'I-NotNegated':3},\n",
    "          'temporality':{'B-Recent':0,'B-Historical':1,'B-Hypothetical':2,'I-Recent':3,\n",
    "                         'I-Historical':4,'I-Hypothetical':5},\n",
    "          'experiencer':{'B-Patient':0,'B-Other':1,'I-Patient':2,'I-Other':3}}\n",
    "\n",
    "tag2id = tag_ids[args.task]\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017aa7e5",
   "metadata": {},
   "source": [
    "## Over all document sources\n",
    "\n",
    "improvement: only output best model based on validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2865323a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Some weights of the model checkpoint at /media/koekiemonster/DATA-FAST/text_data/word_vectors_and_language_models/dutch/Medical/languagemodels/robbert-v2-dutch-base were not used when initializing RobertaForTokenClassification: ['lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at /media/koekiemonster/DATA-FAST/text_data/word_vectors_and_language_models/dutch/Medical/languagemodels/robbert-v2-dutch-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaConfig {\n",
      "  \"_name_or_path\": \"/media/koekiemonster/DATA-FAST/text_data/word_vectors_and_language_models/dutch/Medical/languagemodels/robbert-v2-dutch-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 40000\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|████████████████████████████████| 168/168 [48:45<00:00, 17.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished, best model f = 0.000\n",
      "F1: 0.856 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [1:03:31, 3811.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negated       0.85      0.84      0.84       858\n",
      "  NotNegated       0.83      0.89      0.86      4793\n",
      "\n",
      "   micro avg       0.83      0.88      0.86      5651\n",
      "   macro avg       0.84      0.86      0.85      5651\n",
      "weighted avg       0.83      0.88      0.86      5651\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /media/koekiemonster/DATA-FAST/text_data/word_vectors_and_language_models/dutch/Medical/languagemodels/robbert-v2-dutch-base were not used when initializing RobertaForTokenClassification: ['lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at /media/koekiemonster/DATA-FAST/text_data/word_vectors_and_language_models/dutch/Medical/languagemodels/robbert-v2-dutch-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaConfig {\n",
      "  \"_name_or_path\": \"/media/koekiemonster/DATA-FAST/text_data/word_vectors_and_language_models/dutch/Medical/languagemodels/robbert-v2-dutch-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 40000\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|████████████████████████████████| 168/168 [49:08<00:00, 17.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished, best model f = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [2:07:00, 3810.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.861 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negated       0.81      0.83      0.82       846\n",
      "  NotNegated       0.84      0.89      0.87      4894\n",
      "\n",
      "   micro avg       0.84      0.88      0.86      5740\n",
      "   macro avg       0.83      0.86      0.84      5740\n",
      "weighted avg       0.84      0.88      0.86      5740\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# cycle through folds\n",
    "scores = []\n",
    "predlist = []\n",
    "test_lists = []\n",
    "loss_history = {}\n",
    "for idx, fold in tqdm(enumerate(splits)):\n",
    "    # re-init model for each fold, otherwise it keeps on training the same throughout all folds..\n",
    "    token_model = AutoModelForTokenClassification.from_pretrained(args.model_path, num_labels = len(tag2id))\n",
    "    \n",
    "    train_list, test_list = fold['train'], fold['test']\n",
    "    \n",
    "    ## eval is optional (to gauge the best number of steps/epochs)\n",
    "    eval_list = random.choices(train_list,k=int(len(train_list)/10)) if args.do_eval else []\n",
    "    eval_dcc = dcc.loc[dcc.Id.isin(eval_list)]\n",
    "    test_dcc = dcc.loc[dcc.Id.isin(test_list)]\n",
    "    train_dcc = dcc.loc[(dcc.Id.isin(train_list)) & (~dcc.Id.isin(eval_list))]\n",
    "    \n",
    "    test_list = test_dcc.Id.tolist()\n",
    "    eval_list = eval_dcc.Id.tolist()\n",
    "\n",
    "    ###\n",
    "    train_dataset = trainer.TextDatasetFromDataFrame(train_dcc, tokenizer, args) \n",
    "    test_dataset = trainer.TextDatasetFromDataFrame(test_dcc, tokenizer, args)\n",
    "    eval_dataset = trainer.TextDatasetFromDataFrame(eval_dcc, tokenizer, args)\n",
    "    \n",
    "    args.do_print_class_report=False\n",
    "    # Train on all document sources\n",
    "    trained_model, eval_loss_history = trainer.train_model(model=token_model.to(device), \n",
    "                                                            tokenizer=tokenizer, \n",
    "                                                            train_dataset=train_dataset, \n",
    "                                                            eval_dataset=eval_dataset, \n",
    "                                                            tag2id=tag2id,\n",
    "                                                            device=device, \n",
    "                                                            args=args,\n",
    "                                                            max_grad_norm=1.0,\n",
    "                                                            amp=False)\n",
    "    args.do_print_class_report=True\n",
    "    # Evaluate on all document sources\n",
    "    f1, prec, rec, preds, truth, test_ids = trainer.eval_model(model=trained_model, \n",
    "                                       tokenizer=tokenizer, \n",
    "                                       eval_dataset=test_dataset, \n",
    "                                       tag2id=tag2id, \n",
    "                                       device=device, \n",
    "                                       args=args, \n",
    "                                       return_pred=True)\n",
    "    \n",
    "    loss_history[idx]=eval_loss_history\n",
    "    \n",
    "    #test_ids = [\"_\".join(t) for t in zip(test_dcc.Id, test_dcc.Begin, test_dcc.End)]\n",
    "    scores.append({'fold': idx, 'f1': f1, 'precision': prec, 'recall': rec})\n",
    "    predlist.append({'fold': idx, 'prediction': preds, 'truth': truth, 'ids': test_ids})\n",
    "    test_lists.append(test_ids)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "466041d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predlist_prep = []\n",
    "for foldnum, foldres in enumerate(predlist):\n",
    "    ids = foldres['ids']\n",
    "    for prs, trs, ids in zip(foldres['prediction'], foldres['truth'], foldres['ids']):\n",
    "        for pr, tr, _id in zip(prs, trs, ids):\n",
    "            tmp_dict={}\n",
    "            if len(pr)==len(tr)==0:\n",
    "                tmp_dict['fold'] = foldnum\n",
    "                tmp_dict['entity_id'] = _id\n",
    "                tmp_dict['label'] = \"n/a\"\n",
    "                tmp_dict['robbert'] = \"n/a\"\n",
    "            elif len(pr)>0:\n",
    "                tmp_dict['fold'] = foldnum\n",
    "                tmp_dict['entity_id'] = _id\n",
    "                tmp_dict['label'] = tr\n",
    "                tmp_dict['robbert'] = pr                \n",
    "            else:\n",
    "                raise ValueError(\"predictions are empty while truth is not\")    \n",
    "            predlist_prep.append(tmp_dict)\n",
    "predlist_df = pd.DataFrame(predlist_prep)\n",
    "predlist_df['bio_label'] = predlist_df['label'].str.replace(r\"([BI])\\-[A-z]+\", \"\\\\1\", \n",
    "                                                        regex=True, case=True).str.strip()\n",
    "predlist_df['bio_robbert'] = predlist_df['robbert'].str.replace(r\"([BI])\\-[A-z]+\", \"\\\\1\", \n",
    "                                                        regex=True, case=True).str.strip()\n",
    "\n",
    "bio_pred = predlist_df[['entity_id', 'bio_label', 'bio_robbert']]\n",
    "predlist_df = predlist_df.loc[predlist_df.bio_label=='B']\n",
    "predlist_df.drop(['bio_label', 'bio_robbert', 'fold'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4c94104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predlist_df['label'] = predlist_df.label.map({'B-NotNegated': 'not negated', 'B-Negated': 'negated'})\n",
    "predlist_df['robbert'] = predlist_df.robbert.map({'B-NotNegated': 'not negated', 'B-Negated': 'negated'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2ce6e92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_id</th>\n",
       "      <th>label</th>\n",
       "      <th>robbert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DL1667_66_74</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DL1667_151_160</td>\n",
       "      <td>not negated</td>\n",
       "      <td>negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DL1667_207_213</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DL1866_88_99</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DL1716_40_51</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18700</th>\n",
       "      <td>SP1522_407_417</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18702</th>\n",
       "      <td>SP1591_39_50</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18703</th>\n",
       "      <td>SP1591_146_156</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18705</th>\n",
       "      <td>SP1877_21_31</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18707</th>\n",
       "      <td>SP1256_112_127</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11286 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            entity_id        label      robbert\n",
       "0        DL1667_66_74  not negated  not negated\n",
       "1      DL1667_151_160  not negated      negated\n",
       "2      DL1667_207_213  not negated  not negated\n",
       "3        DL1866_88_99  not negated  not negated\n",
       "4        DL1716_40_51  not negated  not negated\n",
       "...               ...          ...          ...\n",
       "18700  SP1522_407_417  not negated  not negated\n",
       "18702    SP1591_39_50  not negated  not negated\n",
       "18703  SP1591_146_156  not negated  not negated\n",
       "18705    SP1877_21_31      negated      negated\n",
       "18707  SP1256_112_127  not negated  not negated\n",
       "\n",
       "[11286 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predlist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ff4f85e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8ac68a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.do_eval:\n",
    "    dfl = []\n",
    "    for i in range(2):\n",
    "        df = pd.DataFrame(loss_history[i])\n",
    "        df['fold']=i\n",
    "        dfl.append(df)\n",
    "    eval_history = pd.concat(dfl).reset_index()\n",
    "    eval_history['step'] = eval_history['step'].astype(int)\n",
    "    eval_history['fold'] = eval_history['fold'].astype(int)\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=3, figsize=(18,5))\n",
    "    seaborn.lineplot(data=eval_history, x='step', y='f1', hue='epoch', ax=ax[0])\n",
    "    seaborn.lineplot(data=eval_history, x='step', y='recall', hue='epoch', ax=ax[1])\n",
    "    seaborn.lineplot(data=eval_history, x='step', y='precision', hue='epoch', ax=ax[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "85b6d764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.856088</td>\n",
       "      <td>0.831526</td>\n",
       "      <td>0.882145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.860540</td>\n",
       "      <td>0.839576</td>\n",
       "      <td>0.882578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold        f1  precision    recall\n",
       "0     0  0.856088   0.831526  0.882145\n",
       "1     1  0.860540   0.839576  0.882578"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# micro-averaged scores\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5fabec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "909081f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B-NotNegated, B-Negated\n",
    "labmap = {'B-NotNegated': False, 'B-Negated': True, 'I-NotNegated': False, 'I-Negated': True}\n",
    "\n",
    "manual_scores = []\n",
    "confusion_matrix = []\n",
    "for i in range(len(predlist)):\n",
    "    # accuracy over all documents, flattened\n",
    "    _predlist = [(labmap[t], 'B' if 'B-' in t else 'I') for l in predlist[i]['prediction'] for t in l if len(l)>0]\n",
    "    _truthlist = [(labmap[t], 'B' if 'B-' in t else 'I') for l in predlist[i]['truth'] for t in l if len(l)>0]\n",
    "\n",
    "    tr_c = []\n",
    "    pr_c = []\n",
    "    tr_r = []\n",
    "    pr_r = []\n",
    "\n",
    "    b_truth = []\n",
    "    b_pred = []\n",
    "    for _t,_p in zip(_truthlist, _predlist):\n",
    "        if _t[1]==_p[1]=='B':\n",
    "            tr_c.append(_t[0])\n",
    "            pr_c.append(_p[0])\n",
    "        tr_r.append(_t[0])\n",
    "        pr_r.append(_p[0])\n",
    "\n",
    "        b_truth.append(_t[1]=='B')\n",
    "        b_pred.append(_p[1]=='B')\n",
    "\n",
    "    tr_c, pr_c, tr_r, pr_r = np.array(tr_c), np.array(pr_c), np.array(tr_r), np.array(pr_r)\n",
    "    b_truth, b_pred = np.array(b_truth), np.array(b_pred)\n",
    "\n",
    "    TN_c = np.sum((pr_c==tr_c) & (pr_c==False))\n",
    "    TP_c = np.sum((pr_c==tr_c) & (pr_c==True))\n",
    "    FP_c = np.sum((pr_c!=tr_c) & (pr_c==True))\n",
    "    FN_c = np.sum((pr_c!=tr_c) & (pr_c==False))\n",
    "\n",
    "    TN_r = np.sum((pr_r==tr_r) & (pr_r==False))\n",
    "    TP_r = np.sum((pr_r==tr_r) & (pr_r==True))\n",
    "    FP_r = np.sum((pr_r!=tr_r) & (pr_r==True))\n",
    "    FN_r = np.sum((pr_r!=tr_r) & (pr_r==False))\n",
    "\n",
    "    TN_b = np.sum((b_pred==b_truth) & (b_pred==False))\n",
    "    TP_b = np.sum((b_pred==b_truth) & (b_pred==True))\n",
    "    FP_b = np.sum((b_pred!=b_truth) & (b_pred==True))\n",
    "    FN_b = np.sum((b_pred!=b_truth) & (b_pred==False))\n",
    "\n",
    "\n",
    "    # micro\n",
    "    f1 = f1_score(tr_r, pr_r, average='micro')\n",
    "    precision = precision_score(tr_r, pr_r, average='micro')\n",
    "    recall = recall_score(tr_r, pr_r, average='micro')\n",
    "    manual_scores.append({'list': 'raw', \n",
    "                          'fold': i, \n",
    "                          'focus': 'micro', \n",
    "                          'f1': f1, \n",
    "                          'precision': precision, \n",
    "                          'recall': recall})\n",
    "\n",
    "    # macro\n",
    "    f1 = f1_score(tr_r, pr_r, average='macro')\n",
    "    precision = precision_score(tr_r, pr_r, average='macro')\n",
    "    recall = recall_score(tr_r, pr_r, average='macro')\n",
    "    manual_scores.append({'list': 'raw', \n",
    "                          'fold': i, \n",
    "                          'focus': 'macro', \n",
    "                          'f1': f1, \n",
    "                          'precision': precision, \n",
    "                          'recall': recall})\n",
    "\n",
    "    # Negated\n",
    "    f1 = f1_score(tr_r, pr_r)\n",
    "    precision = precision_score(tr_r, pr_r)\n",
    "    recall = recall_score(tr_r, pr_r)\n",
    "    manual_scores.append({'list': 'raw', \n",
    "                          'fold': i, \n",
    "                          'focus': 'negated', \n",
    "                          'f1': f1, \n",
    "                          'precision': precision, \n",
    "                          'recall': recall})\n",
    "\n",
    "    # NotNegated\n",
    "    f1 = f1_score(~tr_r, ~pr_r)\n",
    "    precision = precision_score(~tr_r, ~pr_r)\n",
    "    recall = recall_score(~tr_r, ~pr_r)\n",
    "    manual_scores.append({'list': 'raw',\n",
    "                          'fold': i,\n",
    "                          'focus': 'notnegated', \n",
    "                          'f1': f1,\n",
    "                          'precision': precision,\n",
    "                          'recall': recall})\n",
    "    \n",
    "    confusion_matrix.append({'list': 'raw', 'fold': i, 'TN': TN_r, 'TP': TP_r, 'FN': FN_r, 'FP': FP_r})    \n",
    "    ######################################\n",
    "    # micro\n",
    "    f1 = f1_score(tr_c, pr_c, average='micro')\n",
    "    precision = precision_score(tr_c, pr_c, average='micro')\n",
    "    recall = recall_score(tr_c, pr_c, average='micro')\n",
    "    manual_scores.append({'list': 'clean', \n",
    "                          'fold': i, \n",
    "                          'focus': 'micro', \n",
    "                          'f1': f1, \n",
    "                          'precision': precision, \n",
    "                          'recall': recall})\n",
    "\n",
    "    # macro\n",
    "    f1 = f1_score(tr_c, pr_c, average='macro')\n",
    "    precision = precision_score(tr_c, pr_c, average='macro')\n",
    "    recall = recall_score(tr_c, pr_c, average='macro')\n",
    "    manual_scores.append({'list': 'clean', \n",
    "                          'fold': i, \n",
    "                          'focus': 'macro', \n",
    "                          'f1': f1, \n",
    "                          'precision': precision, \n",
    "                          'recall': recall})\n",
    "\n",
    "    # Negated\n",
    "    f1 = f1_score(tr_c, pr_c)\n",
    "    precision = precision_score(tr_c, pr_c)\n",
    "    recall = recall_score(tr_c, pr_c)\n",
    "    manual_scores.append({'list': 'clean', \n",
    "                          'fold': i, \n",
    "                          'focus': 'negated', \n",
    "                          'f1': f1, \n",
    "                          'precision': precision, \n",
    "                          'recall': recall})\n",
    "\n",
    "    # NotNegated\n",
    "    f1 = f1_score(~tr_c, ~pr_c)\n",
    "    precision = precision_score(~tr_c, ~pr_c)\n",
    "    recall = recall_score(~tr_c, ~pr_c)\n",
    "    manual_scores.append({'list': 'clean',\n",
    "                          'fold': i,\n",
    "                          'focus': 'notnegated', \n",
    "                          'f1': f1,\n",
    "                          'precision': precision,\n",
    "                          'recall': recall})\n",
    "    \n",
    "    confusion_matrix.append({'list': 'clean', 'fold': i, 'TN': TN_c, 'TP': TP_c, 'FN': FN_c, 'FP': FP_c})    \n",
    "    ######################################\n",
    "    # micro\n",
    "    f1 = f1_score(b_truth, b_pred, average='micro')\n",
    "    precision = precision_score(b_truth, b_pred, average='micro')\n",
    "    recall = recall_score(b_truth, b_pred, average='micro')\n",
    "    manual_scores.append({'list': 'B_I', \n",
    "                          'fold': i, \n",
    "                          'focus': 'micro', \n",
    "                          'f1': f1, \n",
    "                          'precision': precision, \n",
    "                          'recall': recall})\n",
    "\n",
    "    # macro\n",
    "    f1 = f1_score(b_truth, b_pred, average='macro')\n",
    "    precision = precision_score(b_truth, b_pred, average='macro')\n",
    "    recall = recall_score(b_truth, b_pred, average='macro')\n",
    "    manual_scores.append({'list': 'B_I', \n",
    "                          'fold': i, \n",
    "                          'focus': 'macro', \n",
    "                          'f1': f1, \n",
    "                          'precision': precision, \n",
    "                          'recall': recall})\n",
    "\n",
    "    # Negated\n",
    "    f1 = f1_score(b_truth, b_pred)\n",
    "    precision = precision_score(b_truth, b_pred)\n",
    "    recall = recall_score(b_truth, b_pred)\n",
    "    manual_scores.append({'list': 'B_I', \n",
    "                          'fold': i, \n",
    "                          'focus': 'negated', \n",
    "                          'f1': f1, \n",
    "                          'precision': precision, \n",
    "                          'recall': recall})\n",
    "\n",
    "    # NotNegated\n",
    "    f1 = f1_score(~b_truth, ~b_pred)\n",
    "    precision = precision_score(~b_truth, ~b_pred)\n",
    "    recall = recall_score(~b_truth, ~b_pred)\n",
    "    manual_scores.append({'list': 'B_I',\n",
    "                          'fold': i,\n",
    "                          'focus': 'notnegated', \n",
    "                          'f1': f1,\n",
    "                          'precision': precision,\n",
    "                          'recall': recall})\n",
    "    \n",
    "    confusion_matrix.append({'list': 'B_I', 'fold': i, 'TN': TN_b, 'TP': TP_b, 'FN': FN_b, 'FP': FP_b})    \n",
    "    \n",
    "manual_scores_df = pd.DataFrame(data=manual_scores)\n",
    "confusion_matrix_df = pd.DataFrame(data=confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6fe90a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>list</th>\n",
       "      <th>focus</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">B_I</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.931249</td>\n",
       "      <td>0.937388</td>\n",
       "      <td>0.926587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.934947</td>\n",
       "      <td>0.934947</td>\n",
       "      <td>0.934947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negated</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.947193</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>0.967163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notnegated</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.915306</td>\n",
       "      <td>0.946709</td>\n",
       "      <td>0.886011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">clean</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.957296</td>\n",
       "      <td>0.967843</td>\n",
       "      <td>0.947453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.978474</td>\n",
       "      <td>0.978474</td>\n",
       "      <td>0.978474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negated</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.927223</td>\n",
       "      <td>0.952916</td>\n",
       "      <td>0.902893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notnegated</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.987369</td>\n",
       "      <td>0.982770</td>\n",
       "      <td>0.992012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">raw</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.950238</td>\n",
       "      <td>0.961279</td>\n",
       "      <td>0.939999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.973703</td>\n",
       "      <td>0.973703</td>\n",
       "      <td>0.973703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negated</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.916067</td>\n",
       "      <td>0.943428</td>\n",
       "      <td>0.890254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notnegated</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.984409</td>\n",
       "      <td>0.979131</td>\n",
       "      <td>0.989744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fold        f1  precision    recall\n",
       "list  focus                                          \n",
       "B_I   macro        0.5  0.931249   0.937388  0.926587\n",
       "      micro        0.5  0.934947   0.934947  0.934947\n",
       "      negated      0.5  0.947193   0.928068  0.967163\n",
       "      notnegated   0.5  0.915306   0.946709  0.886011\n",
       "clean macro        0.5  0.957296   0.967843  0.947453\n",
       "      micro        0.5  0.978474   0.978474  0.978474\n",
       "      negated      0.5  0.927223   0.952916  0.902893\n",
       "      notnegated   0.5  0.987369   0.982770  0.992012\n",
       "raw   macro        0.5  0.950238   0.961279  0.939999\n",
       "      micro        0.5  0.973703   0.973703  0.973703\n",
       "      negated      0.5  0.916067   0.943428  0.890254\n",
       "      notnegated   0.5  0.984409   0.979131  0.989744"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_scores_df.groupby(['list', 'focus']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "085803fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Diagnose : status na glasverwonding in de linkerpols met uitval van de nervus ulnaris . Er bleek toen sprake van een doorsnijding van de arteria ulnaris , de nervus ulnaris , de flexor carpi ulnaris en van beide flexoren van de pink , allen aan de linkerzijde . Bij onderzoek is er sprake van een litteken aan de ulnovolaire zijde van de pols , verlengd naar de onderarm . Er is ook duidelijk sprake van een atrofie van de abductor pollicis met een krachtsvermindering tot 1 / 5 van de normale kracht . De abductor digiti quinti heeft ook een duidelijk krachtsverlies . Van de atrofie van de kleine handspieren is met name die van de adductor pollicis het meest opvallend .'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Texts['DL1932']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c16f81",
   "metadata": {},
   "source": [
    "## Append to other results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3909f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_result_file = '../results/merged_results.csv.gz'\n",
    "results = pd.read_csv(merged_result_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0d2b801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29247/2061256545.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  entities = results.entity_id.str.replace(r\"\\_[0-9]+\\_[0-9]+\", \"\").unique()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5365"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = results.entity_id.str.replace(r\"\\_[0-9]+\\_[0-9]+\", \"\").unique()\n",
    "len(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8d67edca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanity_check = predlist_df[['entity_id', 'label']].set_index('entity_id').join(results[['entity_id', 'label']].set_index('entity_id'),\n",
    "                                                                how='inner',rsuffix='_or')\n",
    "\n",
    "(sanity_check['label'] == sanity_check['label_or']).sum()==sanity_check.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "24902256",
   "metadata": {},
   "outputs": [],
   "source": [
    "predlist_df.set_index('entity_id', inplace=True)\n",
    "results.set_index('entity_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "25a51680",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_results = results.join(predlist_df[['robbert']], how='left')\n",
    "total_results.to_csv(\"../results/merged_results_new.csv.gz\", index=True, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cf0bdad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unanimous = total_results.loc[total_results.robbert.isna()==False,\n",
    "                  ['label', 'bilstm_cv', 'rule_based', 'robbert']].apply(lambda x: x[0]==x[1]==x[2]==x[3], \n",
    "                                                                         axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d141936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_dissenters(x):\n",
    "    return int(x[0] != x[1])+\\\n",
    "           int(x[0] != x[2])+\\\n",
    "           int(x[0] != x[3])+\\\n",
    "           int(x[0] != x[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "cb370354",
   "metadata": {},
   "outputs": [],
   "source": [
    "dissenters = total_results.loc[total_results.robbert.isna()==False,['label', 'bilstm', 'bilstm_cv', 'rule_based', 'robbert']]\\\n",
    "                            .apply(number_of_dissenters, axis=1)\n",
    "total_results.loc[total_results.robbert.isna()==False, 'dissenters'] = dissenters.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "fe2bd558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>bilstm</th>\n",
       "      <th>bilstm_cv</th>\n",
       "      <th>rule_based</th>\n",
       "      <th>robbert</th>\n",
       "      <th>dissenters</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DL1775_454_461</th>\n",
       "      <td>DL</td>\n",
       "      <td>not negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP1191_121_127</th>\n",
       "      <td>GP</td>\n",
       "      <td>negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP1601_67_74</th>\n",
       "      <td>GP</td>\n",
       "      <td>negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP1729_162_169</th>\n",
       "      <td>GP</td>\n",
       "      <td>not negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP2796_56_63</th>\n",
       "      <td>GP</td>\n",
       "      <td>negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RD1338_114_126</th>\n",
       "      <td>RD</td>\n",
       "      <td>not negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RD2031_132_137</th>\n",
       "      <td>RD</td>\n",
       "      <td>not negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RD2200_75_85</th>\n",
       "      <td>RD</td>\n",
       "      <td>not negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RD2557_205_216</th>\n",
       "      <td>RD</td>\n",
       "      <td>not negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP1201_156_171</th>\n",
       "      <td>SP</td>\n",
       "      <td>not negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP1283_35_45</th>\n",
       "      <td>SP</td>\n",
       "      <td>not negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP1317_10_18</th>\n",
       "      <td>SP</td>\n",
       "      <td>negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP1350_515_526</th>\n",
       "      <td>SP</td>\n",
       "      <td>negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP1410_34_39</th>\n",
       "      <td>SP</td>\n",
       "      <td>negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP1944_41_51</th>\n",
       "      <td>SP</td>\n",
       "      <td>not negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               category        label       bilstm    bilstm_cv   rule_based  \\\n",
       "entity_id                                                                     \n",
       "DL1775_454_461       DL  not negated      negated      negated      negated   \n",
       "GP1191_121_127       GP      negated  not negated  not negated  not negated   \n",
       "GP1601_67_74         GP      negated  not negated  not negated  not negated   \n",
       "GP1729_162_169       GP  not negated      negated      negated      negated   \n",
       "GP2796_56_63         GP      negated  not negated  not negated  not negated   \n",
       "RD1338_114_126       RD  not negated      negated      negated      negated   \n",
       "RD2031_132_137       RD  not negated      negated      negated      negated   \n",
       "RD2200_75_85         RD  not negated      negated      negated      negated   \n",
       "RD2557_205_216       RD  not negated      negated      negated      negated   \n",
       "SP1201_156_171       SP  not negated      negated      negated      negated   \n",
       "SP1283_35_45         SP  not negated      negated      negated      negated   \n",
       "SP1317_10_18         SP      negated  not negated  not negated  not negated   \n",
       "SP1350_515_526       SP      negated  not negated  not negated  not negated   \n",
       "SP1410_34_39         SP      negated  not negated  not negated  not negated   \n",
       "SP1944_41_51         SP  not negated      negated      negated      negated   \n",
       "\n",
       "                    robbert  dissenters  \n",
       "entity_id                                \n",
       "DL1775_454_461      negated         4.0  \n",
       "GP1191_121_127  not negated         4.0  \n",
       "GP1601_67_74    not negated         4.0  \n",
       "GP1729_162_169      negated         4.0  \n",
       "GP2796_56_63    not negated         4.0  \n",
       "RD1338_114_126      negated         4.0  \n",
       "RD2031_132_137      negated         4.0  \n",
       "RD2200_75_85        negated         4.0  \n",
       "RD2557_205_216      negated         4.0  \n",
       "SP1201_156_171      negated         4.0  \n",
       "SP1283_35_45        negated         4.0  \n",
       "SP1317_10_18    not negated         4.0  \n",
       "SP1350_515_526  not negated         4.0  \n",
       "SP1410_34_39    not negated         4.0  \n",
       "SP1944_41_51        negated         4.0  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_results.loc[total_results.dissenters==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "acfa41c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vanaf oktober 1994 heb ik de behandeling van dit crushletsel van de rechter hand met luxaties op carpometacarpaal niveau en een fractuur van de basisphalanx van de wijsvinger en van metacarpale III overgenomen . Hij werd op 25 juli 1995 opnieuw geopereerd , waarbij de loop via het oude litteken werd opgelicht en van het surplus subcutaan vet werd ontdaan . Tenslotte werd ter hoogte van de aangegeven neuroomklachten geexploreerd , waarbij geen duidelijke neuroom aangetroffen werd . Er blijkt een ruptuur te zijn ontstaan van de extensor van de vijfde straal , zodat reexploratie noodzakelijk is op 29 juli 1995 .'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Texts['DL1775']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
