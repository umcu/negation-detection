{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MetaCAT - BiLSTM for negations of Dutch Clinical Corpus\n",
    "\n",
    "Based on https://colab.research.google.com/drive/1rxzBZCTDcqsIjRXZ3u4yRZFOkUCCuwyy#scrollTo=dukwUnN1TPCg\n",
    "and https://colab.research.google.com/drive/1zzV3XzFJ9ihhCJ680DaQV2QZ5XnHa06X#scrollTo=Sj29auXV8iPZ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stan3/Data/MedCAT/medcat/cat.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from medcat.cat import CAT\n",
    "from medcat.vocab import Vocab\n",
    "from medcat.cdb import CDB\n",
    "from medcat.config import Config\n",
    "from medcat.meta_cat import MetaCAT\n",
    "from medcat.preprocessing.tokenizers import TokenizerWrapperBPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "data_dir = os.path.join('..', 'data')\n",
    "cdb_file = os.path.join(data_dir, 'cdb.dat')\n",
    "vocab_file = os.path.join(data_dir, 'vocab.dat')\n",
    "json_file_all = os.path.join(data_dir, 'emc-dcc_ann.json')\n",
    "text_file = os.path.join(data_dir, 'data.txt')\n",
    "\n",
    "# Output\n",
    "output_dir = 'output'\n",
    "\n",
    "# Name should contain 'bbpe' for ByteLevelBPETokenizer or 'bert' for BertTokenizerFast\n",
    "# This name is saved in the model_config dict and subssequently in vars.dat on disk.\n",
    "tokenizer_name = 'bbpe_dutch-wikipedia'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create, train and save the tokenizer\n",
    "tokenizer = ByteLevelBPETokenizer()\n",
    "tokenizer.train(text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output/bbpe_dutch-wikipedia-vocab.json',\n",
       " 'output/bbpe_dutch-wikipedia-merges.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the tokenizer\n",
    "tokenizer.save_model(output_dir, tokenizer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tokenize text and train with Word2Vec\n",
    "text_data = []\n",
    "with open(text_file, encoding='utf-8') as text:\n",
    "    for line in text:\n",
    "        text_data.append(tokenizer.encode(line).tokens)\n",
    "w2v = Word2Vec(text_data, size=300, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ġniezen', 0.9076570272445679),\n",
       " ('Ġkortademigheid', 0.9037686586380005),\n",
       " ('Ġjeuk', 0.8884788751602173),\n",
       " ('Ġbraken', 0.8784409761428833),\n",
       " ('Ġdiarree', 0.8775287866592407),\n",
       " ('Ġmisselijkheid', 0.847364604473114),\n",
       " ('Ġovergeven', 0.8446534872055054),\n",
       " ('Ġschokken', 0.8427244424819946),\n",
       " ('Ġbenauwdheid', 0.8399103879928589),\n",
       " ('Ġademhalingsproblemen', 0.8391226530075073)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check trained word2vec model\n",
    "# Ġ denotes start of word (a space)\n",
    "w2v.wv.most_similar('Ġhoesten')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings matrix\n",
    "embeddings = []\n",
    "for i in range(tokenizer.get_vocab_size()):\n",
    "    word = tokenizer.id_to_token(i)\n",
    "    if word in w2v.wv:\n",
    "        embeddings.append(w2v.wv[word])\n",
    "    else:\n",
    "        # Assign a random vector if the word was not frequent enough to receive an embedding\n",
    "        embeddings.append(np.random.rand(300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the embeddings\n",
    "embeddings_file = os.path.join(output_dir, \"embeddings.npy\")\n",
    "np.save(open(embeddings_file, 'wb'), np.array(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change tokenizer to MedCAT's TokenizerWrapperBPE\n",
    "tokenizer = TokenizerWrapperBPE(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MetaCAT on all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.69      0.77      1591\n",
      "           1       0.95      0.98      0.97      9758\n",
      "\n",
      "    accuracy                           0.94     11349\n",
      "   macro avg       0.91      0.83      0.87     11349\n",
      "weighted avg       0.94      0.94      0.94     11349\n",
      "\n",
      "Epoch: 0 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.78      0.83       182\n",
      "           1       0.96      0.98      0.97      1080\n",
      "\n",
      "    accuracy                           0.95      1262\n",
      "   macro avg       0.92      0.88      0.90      1262\n",
      "weighted avg       0.95      0.95      0.95      1262\n",
      "\n",
      "Train Loss: 0.20137218964732134\n",
      "Test Loss:  0.16563032631529495\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 0 and f1: 0.9512924273465027\n",
      "[[ 142   40]\n",
      " [  20 1060]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 1 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.76      0.83      1591\n",
      "           1       0.96      0.99      0.97      9758\n",
      "\n",
      "    accuracy                           0.96     11349\n",
      "   macro avg       0.94      0.87      0.90     11349\n",
      "weighted avg       0.95      0.96      0.95     11349\n",
      "\n",
      "Epoch: 1 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.75      0.82       182\n",
      "           1       0.96      0.98      0.97      1080\n",
      "\n",
      "    accuracy                           0.95      1262\n",
      "   macro avg       0.92      0.87      0.89      1262\n",
      "weighted avg       0.95      0.95      0.95      1262\n",
      "\n",
      "Train Loss: 0.1525022756951061\n",
      "Test Loss:  0.17251864913851023\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 2 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.78      0.84      1591\n",
      "           1       0.96      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.96     11349\n",
      "   macro avg       0.94      0.88      0.91     11349\n",
      "weighted avg       0.96      0.96      0.96     11349\n",
      "\n",
      "Epoch: 2 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.77      0.83       182\n",
      "           1       0.96      0.98      0.97      1080\n",
      "\n",
      "    accuracy                           0.95      1262\n",
      "   macro avg       0.93      0.88      0.90      1262\n",
      "weighted avg       0.95      0.95      0.95      1262\n",
      "\n",
      "Train Loss: 0.14781719792804773\n",
      "Test Loss:  0.1529155226307921\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 2 and f1: 0.9517924028367117\n",
      "[[ 140   42]\n",
      " [  17 1063]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 3 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.80      0.85      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.96     11349\n",
      "   macro avg       0.94      0.89      0.91     11349\n",
      "weighted avg       0.96      0.96      0.96     11349\n",
      "\n",
      "Epoch: 3 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.77      0.82       182\n",
      "           1       0.96      0.98      0.97      1080\n",
      "\n",
      "    accuracy                           0.95      1262\n",
      "   macro avg       0.91      0.88      0.89      1262\n",
      "weighted avg       0.95      0.95      0.95      1262\n",
      "\n",
      "Train Loss: 0.13643574397551866\n",
      "Test Loss:  0.18527982573141344\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 4 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.86      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.96     11349\n",
      "   macro avg       0.94      0.90      0.92     11349\n",
      "weighted avg       0.96      0.96      0.96     11349\n",
      "\n",
      "Epoch: 4 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.76      0.81       182\n",
      "           1       0.96      0.98      0.97      1080\n",
      "\n",
      "    accuracy                           0.95      1262\n",
      "   macro avg       0.92      0.87      0.89      1262\n",
      "weighted avg       0.95      0.95      0.95      1262\n",
      "\n",
      "Train Loss: 0.133764175712918\n",
      "Test Loss:  0.17869831828284077\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 5 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.86      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.96     11349\n",
      "   macro avg       0.95      0.90      0.92     11349\n",
      "weighted avg       0.96      0.96      0.96     11349\n",
      "\n",
      "Epoch: 5 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.83       182\n",
      "           1       0.97      0.98      0.97      1080\n",
      "\n",
      "    accuracy                           0.95      1262\n",
      "   macro avg       0.92      0.89      0.90      1262\n",
      "weighted avg       0.95      0.95      0.95      1262\n",
      "\n",
      "Train Loss: 0.1291353378500658\n",
      "Test Loss:  0.16875737061491236\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 5 and f1: 0.9537868013254688\n",
      "[[ 144   38]\n",
      " [  19 1061]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 6 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.86      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.96     11349\n",
      "   macro avg       0.94      0.90      0.92     11349\n",
      "weighted avg       0.96      0.96      0.96     11349\n",
      "\n",
      "Epoch: 6 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.79      0.85       182\n",
      "           1       0.97      0.99      0.98      1080\n",
      "\n",
      "    accuracy                           0.96      1262\n",
      "   macro avg       0.94      0.89      0.91      1262\n",
      "weighted avg       0.96      0.96      0.96      1262\n",
      "\n",
      "Train Loss: 0.12329725554035845\n",
      "Test Loss:  0.14978704732493497\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 6 and f1: 0.9575676863455367\n",
      "[[ 144   38]\n",
      " [  14 1066]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 7 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.97     11349\n",
      "   macro avg       0.95      0.90      0.92     11349\n",
      "weighted avg       0.96      0.97      0.96     11349\n",
      "\n",
      "Epoch: 7 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85       182\n",
      "           1       0.97      0.99      0.98      1080\n",
      "\n",
      "    accuracy                           0.96      1262\n",
      "   macro avg       0.94      0.89      0.91      1262\n",
      "weighted avg       0.96      0.96      0.96      1262\n",
      "\n",
      "Train Loss: 0.12199881381656923\n",
      "Test Loss:  0.15298844885546714\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 7 and f1: 0.9583290261808863\n",
      "[[ 144   38]\n",
      " [  13 1067]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 8 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.97     11349\n",
      "   macro avg       0.95      0.90      0.92     11349\n",
      "weighted avg       0.96      0.97      0.96     11349\n",
      "\n",
      "Epoch: 8 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.77      0.84       182\n",
      "           1       0.96      0.99      0.97      1080\n",
      "\n",
      "    accuracy                           0.96      1262\n",
      "   macro avg       0.94      0.88      0.91      1262\n",
      "weighted avg       0.96      0.96      0.95      1262\n",
      "\n",
      "Train Loss: 0.12352403459667137\n",
      "Test Loss:  0.15889994395547546\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.97     11349\n",
      "   macro avg       0.95      0.91      0.93     11349\n",
      "weighted avg       0.97      0.97      0.97     11349\n",
      "\n",
      "Epoch: 9 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.78      0.84       182\n",
      "           1       0.96      0.99      0.97      1080\n",
      "\n",
      "    accuracy                           0.96      1262\n",
      "   macro avg       0.93      0.88      0.91      1262\n",
      "weighted avg       0.96      0.96      0.96      1262\n",
      "\n",
      "Train Loss: 0.12445199813260893\n",
      "Test Loss:  0.14788185196812265\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Best/Average scores: F1: 0.9583290261808863, P: 0.9586288944631696, R: 0.9595879556259905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.9583290261808863,\n",
       " 'p': 0.9586288944631696,\n",
       " 'r': 0.9595879556259905,\n",
       " 'cls_report': {'0': {'precision': 0.9171974522292994,\n",
       "   'recall': 0.7912087912087912,\n",
       "   'f1-score': 0.8495575221238937,\n",
       "   'support': 182},\n",
       "  '1': {'precision': 0.9656108597285068,\n",
       "   'recall': 0.9879629629629629,\n",
       "   'f1-score': 0.9766590389016019,\n",
       "   'support': 1080},\n",
       "  'accuracy': 0.9595879556259905,\n",
       "  'macro avg': {'precision': 0.941404155978903,\n",
       "   'recall': 0.8895858770858771,\n",
       "   'f1-score': 0.9131082805127477,\n",
       "   'support': 1262},\n",
       "  'weighted avg': {'precision': 0.9586288944631696,\n",
       "   'recall': 0.9595879556259905,\n",
       "   'f1-score': 0.9583290261808863,\n",
       "   'support': 1262}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate MetaCAT\n",
    "mc_negation = MetaCAT(tokenizer=tokenizer,\n",
    "                      embeddings=embeddings,\n",
    "                      pad_id=len(embeddings)-1,\n",
    "                      save_dir=output_dir,\n",
    "                      device='cpu')\n",
    "\n",
    "# Train model\n",
    "mc_negation.train(json_file_all, \n",
    "                  'Negation',\n",
    "                  model_config={'tokenizer_name': tokenizer_name},\n",
    "                  nepochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model config\n",
    "mc_negation.save(full_save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cdb and vocab \n",
    "config = Config()\n",
    "\n",
    "vocab = Vocab.load(vocab_file)\n",
    "cdb = CDB.load(cdb_file)\n",
    "\n",
    "# Create MedCAT pipeline\n",
    "cat = CAT(cdb=cdb, vocab=vocab, config=config, meta_cats=[mc_negation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: heup\n",
      "Meta Annotations: {'Negation': {'value': 'not negated', 'confidence': 0.99413735, 'name': 'Negation'}}\n",
      "\n",
      "\n",
      "Entity: heupdysplasie\n",
      "Meta Annotations: {'Negation': {'value': 'negated', 'confidence': 0.99721986, 'name': 'Negation'}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test on DL1114 from DCC with negation\n",
    "text = 'Echo- en rontgenonderzoek van de heup toont geen evidente heupdysplasie.'\n",
    "doc = cat(text)\n",
    "for ent in doc.ents:\n",
    "    print(\"Entity: \" + ent.text)\n",
    "    print(\"Meta Annotations: \" + str(ent._.meta_anns))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: heup\n",
      "Meta Annotations: {'Negation': {'value': 'not negated', 'confidence': 0.99924016, 'name': 'Negation'}}\n",
      "\n",
      "\n",
      "Entity: heupdysplasie\n",
      "Meta Annotations: {'Negation': {'value': 'not negated', 'confidence': 0.9917353, 'name': 'Negation'}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test on DL1114 from DCC without negation\n",
    "text = 'Echo- en rontgenonderzoek van de heup toont evidente heupdysplasie.'\n",
    "doc = cat(text)\n",
    "for ent in doc.ents:\n",
    "    print(\"Entity: \" + ent.text)\n",
    "    print(\"Meta Annotations: \" + str(ent._.meta_anns))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional testing and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More tests and evaluation can be found in the evaluation notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
