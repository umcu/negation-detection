{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MetaCAT - BiLSTM for negations of Dutch Clinical Corpus\n",
    "\n",
    "Based on https://colab.research.google.com/drive/1rxzBZCTDcqsIjRXZ3u4yRZFOkUCCuwyy#scrollTo=dukwUnN1TPCg\n",
    "and https://colab.research.google.com/drive/1zzV3XzFJ9ihhCJ680DaQV2QZ5XnHa06X#scrollTo=Sj29auXV8iPZ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from medcat.cat import CAT\n",
    "from medcat.vocab import Vocab\n",
    "from medcat.cdb import CDB\n",
    "from medcat.config import Config\n",
    "from medcat.meta_cat import MetaCAT\n",
    "from medcat.preprocessing.tokenizers import TokenizerWrapperBPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "data_dir = os.path.join('..', 'data')\n",
    "cdb_file = os.path.join(data_dir, 'cdb.dat')\n",
    "vocab_file = os.path.join(data_dir, 'vocab.dat')\n",
    "json_file_all = os.path.join(data_dir, 'emc-dcc_ann.json')\n",
    "text_file = os.path.join(data_dir, 'data.txt')\n",
    "\n",
    "# Output\n",
    "output_dir = 'output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create, train and save the tokenizer\n",
    "tokenizer = ByteLevelBPETokenizer()\n",
    "tokenizer.train(text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output/emc_dcc-vocab.json', 'output/emc_dcc-merges.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the tokenizer\n",
    "tokenizer.save_model(output_dir, 'emc_dcc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tokenize text and train with Word2Vec\n",
    "text_data = []\n",
    "with open(text_file, encoding='utf-8') as text:\n",
    "    for line in text:\n",
    "        text_data.append(tokenizer.encode(line).tokens)\n",
    "w2v = Word2Vec(text_data, size=300, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ġdiarree', 0.9048820734024048),\n",
       " ('Ġkortademigheid', 0.9036903381347656),\n",
       " ('Ġbenauwdheid', 0.8889886140823364),\n",
       " ('Ġbraken', 0.8872215747833252),\n",
       " ('Ġjeuk', 0.8864785432815552),\n",
       " ('Ġniezen', 0.8711977005004883),\n",
       " ('Ġovergeven', 0.8703508973121643),\n",
       " ('Ġmisselijkheid', 0.8701860308647156),\n",
       " ('Ġspierpijn', 0.8695064187049866),\n",
       " ('Ġaanhoudende', 0.8685997724533081)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check trained word2vec model\n",
    "# Ġ denotes start of word (a space)\n",
    "w2v.wv.most_similar('Ġhoesten')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings matrix\n",
    "embeddings = []\n",
    "for i in range(tokenizer.get_vocab_size()):\n",
    "    word = tokenizer.id_to_token(i)\n",
    "    if word in w2v.wv:\n",
    "        embeddings.append(w2v.wv[word])\n",
    "    else:\n",
    "        # Assign a random vector if the word was not frequent enough to receive an embedding\n",
    "        embeddings.append(np.random.rand(300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the embeddings\n",
    "embeddings_file = os.path.join(output_dir, \"embeddings.npy\")\n",
    "np.save(open(embeddings_file, 'wb'), np.array(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change tokenizer to MedCAT's TokenizerWrapperBPE\n",
    "tokenizer = TokenizerWrapperBPE(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MetaCAT on all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.71      0.79      1591\n",
      "           1       0.95      0.98      0.97      9758\n",
      "\n",
      "    accuracy                           0.95     11349\n",
      "   macro avg       0.92      0.85      0.88     11349\n",
      "weighted avg       0.94      0.95      0.94     11349\n",
      "\n",
      "Epoch: 0 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.76      0.83       182\n",
      "           1       0.96      0.99      0.97      1080\n",
      "\n",
      "    accuracy                           0.95      1262\n",
      "   macro avg       0.93      0.87      0.90      1262\n",
      "weighted avg       0.95      0.95      0.95      1262\n",
      "\n",
      "Train Loss: 0.18915263238415436\n",
      "Test Loss:  0.1524209578637965\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 0 and f1: 0.9522919729435904\n",
      "[[ 138   44]\n",
      " [  14 1066]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 1 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.78      0.84      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.96     11349\n",
      "   macro avg       0.94      0.88      0.91     11349\n",
      "weighted avg       0.96      0.96      0.96     11349\n",
      "\n",
      "Epoch: 1 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82       182\n",
      "           1       0.96      0.98      0.97      1080\n",
      "\n",
      "    accuracy                           0.95      1262\n",
      "   macro avg       0.92      0.87      0.89      1262\n",
      "weighted avg       0.95      0.95      0.95      1262\n",
      "\n",
      "Train Loss: 0.15358426871473416\n",
      "Test Loss:  0.1567249231156893\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 2 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.85      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.96     11349\n",
      "   macro avg       0.94      0.89      0.92     11349\n",
      "weighted avg       0.96      0.96      0.96     11349\n",
      "\n",
      "Epoch: 2 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.80      0.85       182\n",
      "           1       0.97      0.99      0.98      1080\n",
      "\n",
      "    accuracy                           0.96      1262\n",
      "   macro avg       0.94      0.89      0.91      1262\n",
      "weighted avg       0.96      0.96      0.96      1262\n",
      "\n",
      "Train Loss: 0.1482321753209247\n",
      "Test Loss:  0.15656039663008414\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 2 and f1: 0.9576779954052154\n",
      "[[ 145   37]\n",
      " [  15 1065]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 3 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.85      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.96     11349\n",
      "   macro avg       0.94      0.89      0.91     11349\n",
      "weighted avg       0.96      0.96      0.96     11349\n",
      "\n",
      "Epoch: 3 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.76      0.83       182\n",
      "           1       0.96      0.99      0.97      1080\n",
      "\n",
      "    accuracy                           0.96      1262\n",
      "   macro avg       0.94      0.88      0.90      1262\n",
      "weighted avg       0.95      0.96      0.95      1262\n",
      "\n",
      "Train Loss: 0.1427657306768184\n",
      "Test Loss:  0.16949523065704852\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 4 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.86      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.96     11349\n",
      "   macro avg       0.95      0.90      0.92     11349\n",
      "weighted avg       0.96      0.96      0.96     11349\n",
      "\n",
      "Epoch: 4 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.77      0.84       182\n",
      "           1       0.96      0.99      0.98      1080\n",
      "\n",
      "    accuracy                           0.96      1262\n",
      "   macro avg       0.94      0.88      0.91      1262\n",
      "weighted avg       0.96      0.96      0.96      1262\n",
      "\n",
      "Train Loss: 0.13383261024669915\n",
      "Test Loss:  0.1412649496924132\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 5 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.96     11349\n",
      "   macro avg       0.95      0.90      0.92     11349\n",
      "weighted avg       0.96      0.96      0.96     11349\n",
      "\n",
      "Epoch: 5 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.74      0.83       182\n",
      "           1       0.96      0.99      0.97      1080\n",
      "\n",
      "    accuracy                           0.96      1262\n",
      "   macro avg       0.95      0.86      0.90      1262\n",
      "weighted avg       0.96      0.96      0.95      1262\n",
      "\n",
      "Train Loss: 0.12475908256929473\n",
      "Test Loss:  0.15459665132220834\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 6 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.83      0.88      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.97     11349\n",
      "   macro avg       0.95      0.91      0.93     11349\n",
      "weighted avg       0.97      0.97      0.97     11349\n",
      "\n",
      "Epoch: 6 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.77      0.83       182\n",
      "           1       0.96      0.98      0.97      1080\n",
      "\n",
      "    accuracy                           0.95      1262\n",
      "   macro avg       0.92      0.88      0.90      1262\n",
      "weighted avg       0.95      0.95      0.95      1262\n",
      "\n",
      "Train Loss: 0.1224618570429837\n",
      "Test Loss:  0.15570296440273523\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 7 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.86      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.96     11349\n",
      "   macro avg       0.95      0.90      0.92     11349\n",
      "weighted avg       0.96      0.96      0.96     11349\n",
      "\n",
      "Epoch: 7 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.77      0.82       182\n",
      "           1       0.96      0.98      0.97      1080\n",
      "\n",
      "    accuracy                           0.95      1262\n",
      "   macro avg       0.92      0.88      0.90      1262\n",
      "weighted avg       0.95      0.95      0.95      1262\n",
      "\n",
      "Train Loss: 0.12867042470008502\n",
      "Test Loss:  0.17150844060233794\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 8 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.97     11349\n",
      "   macro avg       0.95      0.91      0.93     11349\n",
      "weighted avg       0.97      0.97      0.97     11349\n",
      "\n",
      "Epoch: 8 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.80      0.85       182\n",
      "           1       0.97      0.99      0.98      1080\n",
      "\n",
      "    accuracy                           0.96      1262\n",
      "   macro avg       0.94      0.89      0.92      1262\n",
      "weighted avg       0.96      0.96      0.96      1262\n",
      "\n",
      "Train Loss: 0.12481776859716211\n",
      "Test Loss:  0.14474868008983321\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Model saved at epoch: 8 and f1: 0.9593057648127071\n",
      "[[ 146   36]\n",
      " [  14 1066]]\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 9 **************************************************  Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.83      0.87      1591\n",
      "           1       0.97      0.99      0.98      9758\n",
      "\n",
      "    accuracy                           0.97     11349\n",
      "   macro avg       0.95      0.91      0.93     11349\n",
      "weighted avg       0.97      0.97      0.97     11349\n",
      "\n",
      "Epoch: 9 **************************************************  Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84       182\n",
      "           1       0.97      0.98      0.97      1080\n",
      "\n",
      "    accuracy                           0.96      1262\n",
      "   macro avg       0.92      0.89      0.91      1262\n",
      "weighted avg       0.96      0.96      0.96      1262\n",
      "\n",
      "Train Loss: 0.12069803015755254\n",
      "Test Loss:  0.1609563951205928\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Best/Average scores: F1: 0.9593057648127071, P: 0.959424479623563, R: 0.9603803486529319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.9593057648127071,\n",
       " 'p': 0.959424479623563,\n",
       " 'r': 0.9603803486529319,\n",
       " 'cls_report': {'0': {'precision': 0.9125,\n",
       "   'recall': 0.8021978021978022,\n",
       "   'f1-score': 0.8538011695906434,\n",
       "   'support': 182},\n",
       "  '1': {'precision': 0.9673321234119783,\n",
       "   'recall': 0.987037037037037,\n",
       "   'f1-score': 0.9770852428964254,\n",
       "   'support': 1080},\n",
       "  'accuracy': 0.9603803486529319,\n",
       "  'macro avg': {'precision': 0.9399160617059892,\n",
       "   'recall': 0.8946174196174197,\n",
       "   'f1-score': 0.9154432062435345,\n",
       "   'support': 1262},\n",
       "  'weighted avg': {'precision': 0.959424479623563,\n",
       "   'recall': 0.9603803486529319,\n",
       "   'f1-score': 0.9593057648127071,\n",
       "   'support': 1262}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and evaluate MetaCAT on all negations of the EMC DCC dataset\n",
    "mc_negation = MetaCAT(tokenizer=tokenizer, embeddings=embeddings, pad_id=len(embeddings) -1, save_dir=output_dir, device='cpu')\n",
    "mc_negation.train(json_file_all, 'Negation', nepochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cdb and vocab \n",
    "config = Config()\n",
    "\n",
    "vocab = Vocab.load(vocab_file)\n",
    "cdb = CDB.load(cdb_file)\n",
    "\n",
    "# Create MedCAT pipeline\n",
    "cat = CAT(cdb=cdb, vocab=vocab, config=config, meta_cats=[mc_negation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: longkanker\n",
      "Meta Annotations: {'Negation': {'value': 'negated', 'confidence': 0.9952809, 'name': 'Negation'}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = 'De patient heeft geen longkanker.'\n",
    "doc = cat(text)\n",
    "for ent in doc.ents:\n",
    "    print(\"Entity: \" + ent.text)\n",
    "    print(\"Meta Annotations: \" + str(ent._.meta_anns))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MetaCat on subsets of the data\n",
    "The ContextD paper calculates precision, recall and F1-score on subsets of the data. In this section we calculate the same scores with the just created model. Note that this results in a calculation on a set of data that was included during the training phase. For proper score calculations, we will do cross validation at a later stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_DL = os.path.join(data_dir, 'emc-dcc_ann_DL.json')\n",
    "json_file_GP = os.path.join(data_dir, 'emc-dcc_ann_GP.json')\n",
    "json_file_RD = os.path.join(data_dir, 'emc-dcc_ann_RD.json')\n",
    "json_file_SP = os.path.join(data_dir, 'emc-dcc_ann_SP.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radiology letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "prepare_from_json() got an unexpected keyword argument 'lowercase'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6f695201586b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmc_negation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file_RD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Data/MedCAT/medcat/meta_cat.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, json_path, batch_size, lowercase, ignore_cpos, cui_filter, score_average, replace_center)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# Prepare the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         data = prepare_from_json(data, self.cntx_left, self.cntx_right, self.tokenizer, cui_filter=cui_filter,\n\u001b[0m\u001b[1;32m    145\u001b[0m                 replace_center=replace_center)\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: prepare_from_json() got an unexpected keyword argument 'lowercase'"
     ]
    }
   ],
   "source": [
    "mc_negation.eval(json_file_RD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specialist letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and evaluate MetaCAT on specialist letters\n",
    "mc_negation_SP = MetaCAT(tokenizer=tokenizer, embeddings=embeddings, pad_id=len(embeddings) -1, save_dir='data/output/mc_negation_SP', device='cpu')\n",
    "mc_negation_SP.train(json_file_SP, 'Negation', nepochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discharge letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and evaluate MetaCAT on discharge letters\n",
    "mc_negation_DL = MetaCAT(tokenizer=tokenizer, embeddings=embeddings, pad_id=len(embeddings) -1, save_dir='data/output/mc_negation_DL', device='cpu')\n",
    "mc_negation_DL.train(json_file_DL, 'Negation', nepochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GP entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and evaluate MetaCAT on GP entries\n",
    "mc_negation_GP = MetaCAT(tokenizer=tokenizer, embeddings=embeddings, pad_id=len(embeddings) -1, save_dir='data/output/mc_negation_GP', device='cpu')\n",
    "mc_negation_GP.train(json_file_GP, 'Negation', nepochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
