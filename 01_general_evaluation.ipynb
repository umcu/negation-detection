{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "271b4fe3",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c28e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from evaluation_utils import print_statistics, get_document_text\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "data_dir = Path('data')\n",
    "annotation_file = data_dir / 'emc-dcc_ann.json'\n",
    "dcc_dir = data_dir / 'EMCDutchClinicalCorpus'\n",
    "result_dir = Path('results')\n",
    "bilstm_predictions_file = result_dir / 'bilstm_predictions.csv.gz'\n",
    "bilstm_predictions_cv_file = result_dir / 'bilstm_predictions_cv.csv.gz'\n",
    "rule_based_predictions_file = result_dir / 'rule-based_predictions.csv.gz'\n",
    "merged_result_file = result_dir / 'merged_results.csv.gz'\n",
    "\n",
    "# Load annotated data\n",
    "with open(annotation_file) as f:\n",
    "    annotations = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cc0c13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12551, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_id</th>\n",
       "      <th>bilstm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DL1111_32_46</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DL1111_272_280</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DL1111_363_377</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DL1112_22_28</td>\n",
       "      <td>negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DL1113_59_67</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        entity_id       bilstm\n",
       "0    DL1111_32_46  not negated\n",
       "1  DL1111_272_280  not negated\n",
       "2  DL1111_363_377  not negated\n",
       "3    DL1112_22_28      negated\n",
       "4    DL1113_59_67  not negated"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load biLSTM results\n",
    "bilstm_predictions = pd.read_csv(bilstm_predictions_file, sep=',')\n",
    "print(bilstm_predictions.shape)\n",
    "bilstm_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a4da107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_id</th>\n",
       "      <th>bilstm_cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DL1111_32_46</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DL1111_272_280</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DL1111_363_377</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DL1116_32_41</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DL1116_137_148</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        entity_id    bilstm_cv\n",
       "0    DL1111_32_46  not negated\n",
       "1  DL1111_272_280  not negated\n",
       "2  DL1111_363_377  not negated\n",
       "3    DL1116_32_41  not negated\n",
       "4  DL1116_137_148  not negated"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilstm_predictions_cv = pd.read_csv(bilstm_predictions_cv_file)\n",
    "bilstm_predictions_cv.shape\n",
    "bilstm_predictions_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9f3ece5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_id</th>\n",
       "      <th>rule_based</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DL1111_32_46</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DL1111_272_280</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DL1111_363_377</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DL1112_22_28</td>\n",
       "      <td>negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DL1113_59_67</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        entity_id   rule_based\n",
       "0    DL1111_32_46  not negated\n",
       "1  DL1111_272_280  not negated\n",
       "2  DL1111_363_377  not negated\n",
       "3    DL1112_22_28      negated\n",
       "4    DL1113_59_67  not negated"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load rule based results\n",
    "ruled_based_predictions = pd.read_csv(rule_based_predictions_file)\n",
    "ruled_based_predictions.drop(['annotation'], axis=1, inplace=True)\n",
    "ruled_based_predictions.shape\n",
    "ruled_based_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d62d405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12551, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_id</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DL1111_32_46</td>\n",
       "      <td>DL</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DL1111_272_280</td>\n",
       "      <td>DL</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DL1111_363_377</td>\n",
       "      <td>DL</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DL1112_22_28</td>\n",
       "      <td>DL</td>\n",
       "      <td>negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DL1113_59_67</td>\n",
       "      <td>DL</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        entity_id category        label\n",
       "0    DL1111_32_46       DL  not negated\n",
       "1  DL1111_272_280       DL  not negated\n",
       "2  DL1111_363_377       DL  not negated\n",
       "3    DL1112_22_28       DL      negated\n",
       "4    DL1113_59_67       DL  not negated"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load annotated data\n",
    "annotated_records = []\n",
    "for document in annotations['projects'][0]['documents']:\n",
    "    document_name = document['name']\n",
    "    text = document['text']\n",
    "\n",
    "    for annotation in document['annotations']:\n",
    "\n",
    "        # Extract data\n",
    "        start_char = annotation['start']\n",
    "        end_char = annotation['end']\n",
    "        negation_value = annotation['meta_anns']['Negation']['value']\n",
    "\n",
    "        # Create custom ID\n",
    "        entity_id = f'{document_name}_{start_char}_{end_char}'\n",
    "        \n",
    "        # Extract category\n",
    "        if 'DL' in document_name:\n",
    "            category = 'DL'\n",
    "        elif 'GP' in document_name:\n",
    "            category = 'GP'\n",
    "        elif 'RD' in document_name:\n",
    "            category = 'RD'\n",
    "        else:\n",
    "            category = 'SP'\n",
    "        \n",
    "        # Create row\n",
    "        annotated_records.append([entity_id, category, negation_value])\n",
    "\n",
    "annotated_data = pd.DataFrame(annotated_records, columns=['entity_id', 'category', 'label'])\n",
    "print(annotated_data.shape)\n",
    "annotated_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fb1ee5",
   "metadata": {},
   "source": [
    "## Merge annotations from different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca76bfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12551, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_id</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>bilstm</th>\n",
       "      <th>bilstm_cv</th>\n",
       "      <th>rule_based</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DL1111_32_46</td>\n",
       "      <td>DL</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DL1111_272_280</td>\n",
       "      <td>DL</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DL1111_363_377</td>\n",
       "      <td>DL</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DL1112_22_28</td>\n",
       "      <td>DL</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "      <td>negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DL1113_59_67</td>\n",
       "      <td>DL</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "      <td>not negated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        entity_id category        label       bilstm    bilstm_cv   rule_based\n",
       "0    DL1111_32_46       DL  not negated  not negated  not negated  not negated\n",
       "1  DL1111_272_280       DL  not negated  not negated  not negated  not negated\n",
       "2  DL1111_363_377       DL  not negated  not negated  not negated  not negated\n",
       "3    DL1112_22_28       DL      negated      negated      negated      negated\n",
       "4    DL1113_59_67       DL  not negated  not negated  not negated  not negated"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.merge(left=annotated_data, right = bilstm_predictions, left_on='entity_id', right_on='entity_id')\n",
    "results = pd.merge(left=results, right = bilstm_predictions_cv, left_on='entity_id', right_on='entity_id')\n",
    "results = pd.merge(left=results, right = ruled_based_predictions, left_on='entity_id', right_on='entity_id')\n",
    "results.to_csv(merged_result_file, index=False, compression='gzip', line_terminator='\\n')\n",
    "print(results.shape)\n",
    "results.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aae6d6b",
   "metadata": {},
   "source": [
    "## Compare different ways of calculating scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2675385c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average</th>\n",
       "      <th>prediction_method</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>binary</td>\n",
       "      <td>bilstm_cv</td>\n",
       "      <td>0.925059</td>\n",
       "      <td>0.897727</td>\n",
       "      <td>0.911188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>micro</td>\n",
       "      <td>bilstm_cv</td>\n",
       "      <td>0.975460</td>\n",
       "      <td>0.975460</td>\n",
       "      <td>0.975460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>macro</td>\n",
       "      <td>bilstm_cv</td>\n",
       "      <td>0.954229</td>\n",
       "      <td>0.942933</td>\n",
       "      <td>0.948476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weighted</td>\n",
       "      <td>bilstm_cv</td>\n",
       "      <td>0.975218</td>\n",
       "      <td>0.975460</td>\n",
       "      <td>0.975306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    average prediction_method  precision    recall        f1\n",
       "0    binary         bilstm_cv   0.925059  0.897727  0.911188\n",
       "1     micro         bilstm_cv   0.975460  0.975460  0.975460\n",
       "2     macro         bilstm_cv   0.954229  0.942933  0.948476\n",
       "3  weighted         bilstm_cv   0.975218  0.975460  0.975306"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_score_record(prediction_method, average, pos_label=1, category=None):\n",
    "    if category is not None:\n",
    "        subset = results[results.category == category]\n",
    "        return [average, category, prediction_method] + (list(precision_recall_fscore_support(subset.label, subset[prediction_method], labels=['negated', 'not negated'], average = average, pos_label=pos_label))) \n",
    "    return [average, prediction_method] + (list(precision_recall_fscore_support(results.label, results[prediction_method], labels=['negated', 'not negated'], average = average, pos_label=pos_label))) \n",
    "\n",
    "score_list = []\n",
    "score_list.append(create_score_record('bilstm_cv', 'binary', pos_label='negated'))\n",
    "score_list.append(create_score_record('bilstm_cv', 'micro'))\n",
    "score_list.append(create_score_record('bilstm_cv', 'macro'))\n",
    "score_list.append(create_score_record('bilstm_cv', 'weighted'))\n",
    "scores = pd.DataFrame(score_list, columns=['average', 'prediction_method', 'precision', 'recall', 'f1', 'support'])\n",
    "scores.drop(['support'], axis=1, inplace=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f288d15",
   "metadata": {},
   "source": [
    "## Calculate scores using average: binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef8de822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>average</th>\n",
       "      <th>prediction_method</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>binary</td>\n",
       "      <td>DL</td>\n",
       "      <td>rule_based</td>\n",
       "      <td>0.892583</td>\n",
       "      <td>0.920844</td>\n",
       "      <td>0.906494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>binary</td>\n",
       "      <td>DL</td>\n",
       "      <td>bilstm_cv</td>\n",
       "      <td>0.956640</td>\n",
       "      <td>0.931398</td>\n",
       "      <td>0.943850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>binary</td>\n",
       "      <td>GP</td>\n",
       "      <td>rule_based</td>\n",
       "      <td>0.671024</td>\n",
       "      <td>0.804178</td>\n",
       "      <td>0.731591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>binary</td>\n",
       "      <td>GP</td>\n",
       "      <td>bilstm_cv</td>\n",
       "      <td>0.885117</td>\n",
       "      <td>0.885117</td>\n",
       "      <td>0.885117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>binary</td>\n",
       "      <td>RD</td>\n",
       "      <td>rule_based</td>\n",
       "      <td>0.901254</td>\n",
       "      <td>0.966387</td>\n",
       "      <td>0.932685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>binary</td>\n",
       "      <td>RD</td>\n",
       "      <td>bilstm_cv</td>\n",
       "      <td>0.932773</td>\n",
       "      <td>0.932773</td>\n",
       "      <td>0.932773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>binary</td>\n",
       "      <td>SP</td>\n",
       "      <td>rule_based</td>\n",
       "      <td>0.808153</td>\n",
       "      <td>0.836228</td>\n",
       "      <td>0.821951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>binary</td>\n",
       "      <td>SP</td>\n",
       "      <td>bilstm_cv</td>\n",
       "      <td>0.922438</td>\n",
       "      <td>0.826303</td>\n",
       "      <td>0.871728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category average prediction_method  precision    recall        f1\n",
       "0   binary      DL        rule_based   0.892583  0.920844  0.906494\n",
       "1   binary      DL         bilstm_cv   0.956640  0.931398  0.943850\n",
       "2   binary      GP        rule_based   0.671024  0.804178  0.731591\n",
       "3   binary      GP         bilstm_cv   0.885117  0.885117  0.885117\n",
       "4   binary      RD        rule_based   0.901254  0.966387  0.932685\n",
       "5   binary      RD         bilstm_cv   0.932773  0.932773  0.932773\n",
       "6   binary      SP        rule_based   0.808153  0.836228  0.821951\n",
       "7   binary      SP         bilstm_cv   0.922438  0.826303  0.871728"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_list = []\n",
    "score_list.append(create_score_record('rule_based', 'binary', pos_label='negated', category = 'DL'))\n",
    "score_list.append(create_score_record('bilstm_cv', 'binary', pos_label='negated', category = 'DL'))\n",
    "score_list.append(create_score_record('rule_based', 'binary', pos_label='negated', category = 'GP'))\n",
    "score_list.append(create_score_record('bilstm_cv', 'binary', pos_label='negated', category = 'GP'))\n",
    "score_list.append(create_score_record('rule_based', 'binary', pos_label='negated', category = 'RD'))\n",
    "score_list.append(create_score_record('bilstm_cv', 'binary', pos_label='negated', category = 'RD'))\n",
    "score_list.append(create_score_record('rule_based', 'binary', pos_label='negated', category = 'SP'))\n",
    "score_list.append(create_score_record('bilstm_cv', 'binary', pos_label='negated', category = 'SP'))\n",
    "scores_binary = pd.DataFrame(score_list, columns=['category', 'average', 'prediction_method', 'precision', 'recall', 'f1', 'support'])\n",
    "scores_binary.drop(['support'], axis=1, inplace=True)\n",
    "scores_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3985aad",
   "metadata": {},
   "source": [
    "## Calculate scores using average: micro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88c6c4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_method</th>\n",
       "      <th>category</th>\n",
       "      <th>average</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>micro</td>\n",
       "      <td>DL</td>\n",
       "      <td>rule_based</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.974249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>micro</td>\n",
       "      <td>DL</td>\n",
       "      <td>bilstm_cv</td>\n",
       "      <td>0.984979</td>\n",
       "      <td>0.984979</td>\n",
       "      <td>0.984979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>micro</td>\n",
       "      <td>GP</td>\n",
       "      <td>rule_based</td>\n",
       "      <td>0.933451</td>\n",
       "      <td>0.933451</td>\n",
       "      <td>0.933451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>micro</td>\n",
       "      <td>GP</td>\n",
       "      <td>bilstm_cv</td>\n",
       "      <td>0.974087</td>\n",
       "      <td>0.974087</td>\n",
       "      <td>0.974087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>micro</td>\n",
       "      <td>RD</td>\n",
       "      <td>rule_based</td>\n",
       "      <td>0.977464</td>\n",
       "      <td>0.977464</td>\n",
       "      <td>0.977464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>micro</td>\n",
       "      <td>RD</td>\n",
       "      <td>bilstm_cv</td>\n",
       "      <td>0.978279</td>\n",
       "      <td>0.978279</td>\n",
       "      <td>0.978279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>micro</td>\n",
       "      <td>SP</td>\n",
       "      <td>rule_based</td>\n",
       "      <td>0.945441</td>\n",
       "      <td>0.945441</td>\n",
       "      <td>0.945441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>micro</td>\n",
       "      <td>SP</td>\n",
       "      <td>bilstm_cv</td>\n",
       "      <td>0.963378</td>\n",
       "      <td>0.963378</td>\n",
       "      <td>0.963378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prediction_method category     average  precision    recall        f1\n",
       "0             micro       DL  rule_based   0.974249  0.974249  0.974249\n",
       "1             micro       DL   bilstm_cv   0.984979  0.984979  0.984979\n",
       "2             micro       GP  rule_based   0.933451  0.933451  0.933451\n",
       "3             micro       GP   bilstm_cv   0.974087  0.974087  0.974087\n",
       "4             micro       RD  rule_based   0.977464  0.977464  0.977464\n",
       "5             micro       RD   bilstm_cv   0.978279  0.978279  0.978279\n",
       "6             micro       SP  rule_based   0.945441  0.945441  0.945441\n",
       "7             micro       SP   bilstm_cv   0.963378  0.963378  0.963378"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_list = []\n",
    "score_list.append(create_score_record('rule_based', 'micro', category = 'DL'))\n",
    "score_list.append(create_score_record('bilstm_cv', 'micro', category = 'DL'))\n",
    "score_list.append(create_score_record('rule_based', 'micro', category = 'GP'))\n",
    "score_list.append(create_score_record('bilstm_cv', 'micro', category = 'GP'))\n",
    "score_list.append(create_score_record('rule_based', 'micro', category = 'RD'))\n",
    "score_list.append(create_score_record('bilstm_cv', 'micro', category = 'RD'))\n",
    "score_list.append(create_score_record('rule_based', 'micro', category = 'SP'))\n",
    "score_list.append(create_score_record('bilstm_cv', 'micro', category = 'SP'))\n",
    "scores_micro = pd.DataFrame(score_list, columns=['prediction_method', 'category', 'average', 'precision', 'recall', 'f1', 'support'])\n",
    "scores_micro.drop(['support'], axis=1, inplace=True)\n",
    "scores_micro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee30de",
   "metadata": {},
   "source": [
    "## Calculate scores using average: weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8df6c3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_method</th>\n",
       "      <th>category</th>\n",
       "      <th>average</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weighted</td>\n",
       "      <td>DL</td>\n",
       "      <td>rule_based</td>\n",
       "      <td>0.974656</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.974418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weighted</td>\n",
       "      <td>DL</td>\n",
       "      <td>bilstm_cv</td>\n",
       "      <td>0.984862</td>\n",
       "      <td>0.984979</td>\n",
       "      <td>0.984894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weighted</td>\n",
       "      <td>GP</td>\n",
       "      <td>rule_based</td>\n",
       "      <td>0.940242</td>\n",
       "      <td>0.933451</td>\n",
       "      <td>0.936029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weighted</td>\n",
       "      <td>GP</td>\n",
       "      <td>bilstm_cv</td>\n",
       "      <td>0.974087</td>\n",
       "      <td>0.974087</td>\n",
       "      <td>0.974087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted</td>\n",
       "      <td>RD</td>\n",
       "      <td>rule_based</td>\n",
       "      <td>0.978540</td>\n",
       "      <td>0.977464</td>\n",
       "      <td>0.977778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weighted</td>\n",
       "      <td>RD</td>\n",
       "      <td>bilstm_cv</td>\n",
       "      <td>0.978279</td>\n",
       "      <td>0.978279</td>\n",
       "      <td>0.978279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted</td>\n",
       "      <td>SP</td>\n",
       "      <td>rule_based</td>\n",
       "      <td>0.946292</td>\n",
       "      <td>0.945441</td>\n",
       "      <td>0.945822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>weighted</td>\n",
       "      <td>SP</td>\n",
       "      <td>bilstm_cv</td>\n",
       "      <td>0.962635</td>\n",
       "      <td>0.963378</td>\n",
       "      <td>0.962539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prediction_method category     average  precision    recall        f1\n",
       "0          weighted       DL  rule_based   0.974656  0.974249  0.974418\n",
       "1          weighted       DL   bilstm_cv   0.984862  0.984979  0.984894\n",
       "2          weighted       GP  rule_based   0.940242  0.933451  0.936029\n",
       "3          weighted       GP   bilstm_cv   0.974087  0.974087  0.974087\n",
       "4          weighted       RD  rule_based   0.978540  0.977464  0.977778\n",
       "5          weighted       RD   bilstm_cv   0.978279  0.978279  0.978279\n",
       "6          weighted       SP  rule_based   0.946292  0.945441  0.945822\n",
       "7          weighted       SP   bilstm_cv   0.962635  0.963378  0.962539"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_list = []\n",
    "score_list.append(create_score_record('rule_based', 'weighted', category = 'DL'))\n",
    "score_list.append(create_score_record('bilstm_cv', 'weighted', category = 'DL'))\n",
    "score_list.append(create_score_record('rule_based', 'weighted', category = 'GP'))\n",
    "score_list.append(create_score_record('bilstm_cv', 'weighted', category = 'GP'))\n",
    "score_list.append(create_score_record('rule_based', 'weighted', category = 'RD'))\n",
    "score_list.append(create_score_record('bilstm_cv', 'weighted', category = 'RD'))\n",
    "score_list.append(create_score_record('rule_based', 'weighted', category = 'SP'))\n",
    "score_list.append(create_score_record('bilstm_cv', 'weighted', category = 'SP'))\n",
    "scores_micro = pd.DataFrame(score_list, columns=['prediction_method', 'category', 'average', 'precision', 'recall', 'f1', 'support'])\n",
    "scores_micro.drop(['support'], axis=1, inplace=True)\n",
    "scores_micro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dbcab6",
   "metadata": {},
   "source": [
    "## Results biLSTM complete model\n",
    "Trained on all data, so it is overfitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67770731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average</th>\n",
       "      <th>prediction_method</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>binary</td>\n",
       "      <td>bilstm</td>\n",
       "      <td>0.974832</td>\n",
       "      <td>0.990341</td>\n",
       "      <td>0.982525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>micro</td>\n",
       "      <td>bilstm</td>\n",
       "      <td>0.995060</td>\n",
       "      <td>0.995060</td>\n",
       "      <td>0.995060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>macro</td>\n",
       "      <td>bilstm</td>\n",
       "      <td>0.986626</td>\n",
       "      <td>0.993085</td>\n",
       "      <td>0.989824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weighted</td>\n",
       "      <td>bilstm</td>\n",
       "      <td>0.995113</td>\n",
       "      <td>0.995060</td>\n",
       "      <td>0.995076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    average prediction_method  precision    recall        f1\n",
       "0    binary            bilstm   0.974832  0.990341  0.982525\n",
       "1     micro            bilstm   0.995060  0.995060  0.995060\n",
       "2     macro            bilstm   0.986626  0.993085  0.989824\n",
       "3  weighted            bilstm   0.995113  0.995060  0.995076"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_score_record(prediction_method, average, pos_label=1, category=None):\n",
    "    if category is not None:\n",
    "        subset = results[results.category == category]\n",
    "        return [average, category, prediction_method] + (list(precision_recall_fscore_support(subset.label, subset[prediction_method], labels=['negated', 'not negated'], average = average, pos_label=pos_label))) \n",
    "    return [average, prediction_method] + (list(precision_recall_fscore_support(results.label, results[prediction_method], labels=['negated', 'not negated'], average = average, pos_label=pos_label))) \n",
    "\n",
    "score_list = []\n",
    "score_list.append(create_score_record('bilstm', 'binary', pos_label='negated'))\n",
    "score_list.append(create_score_record('bilstm', 'micro'))\n",
    "score_list.append(create_score_record('bilstm', 'macro'))\n",
    "score_list.append(create_score_record('bilstm', 'weighted'))\n",
    "scores = pd.DataFrame(score_list, columns=['average', 'prediction_method', 'precision', 'recall', 'f1', 'support'])\n",
    "scores.drop(['support'], axis=1, inplace=True)\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
